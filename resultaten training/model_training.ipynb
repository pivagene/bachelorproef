{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246c5c7-69ad-42bb-baa7-f4e7cf113645",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m csv_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAMP_species_list_COX1.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(csv_file)\n\u001b[0;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCOX1_sequences.fasta\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fasta_file:\n\u001b[0;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\"{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe64437-6ee3-4124-89a7-314654986b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15d96a-fff8-4727-9228-2443ada628a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'], returncode=3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\"{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e01bfd-ee5e-4d0c-9b62-15258d825b01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "More than one record found in handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:80\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m feature, kmer_feature , blast_score\n\u001b[0;32m     79\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m---> 80\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(executor\u001b[39m.\u001b[39mmap(process_sequence, merged_df[\u001b[39m'\u001b[39m\u001b[39mFASTA\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     82\u001b[0m \u001b[39mfor\u001b[39;00m feature, kmer_feature,blast_score \u001b[39min\u001b[39;00m results: \u001b[39m# ,blast_scores kan ook nog toegevoegd worden\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     features\u001b[39m.\u001b[39mappend(feature)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop())\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39mresult(timeout)\n\u001b[0;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:76\u001b[0m\n\u001b[0;32m     74\u001b[0m feature \u001b[39m=\u001b[39m extract_features(sequence)\n\u001b[0;32m     75\u001b[0m kmer_feature \u001b[39m=\u001b[39m get_kmers(sequence)\n\u001b[1;32m---> 76\u001b[0m blast_score \u001b[39m=\u001b[39m get_blast_score(sequence)\n\u001b[0;32m     77\u001b[0m \u001b[39mreturn\u001b[39;00m feature, kmer_feature , blast_score\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:51\u001b[0m\n\u001b[0;32m     45\u001b[0m result \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mrun(\n\u001b[0;32m     46\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mblastn\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-query\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtemp_query.fasta\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-db\u001b[39m\u001b[39m'\u001b[39m, db, \u001b[39m'\u001b[39m\u001b[39m-outfmt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     47\u001b[0m     capture_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, text\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     50\u001b[0m \u001b[39m# Parse the BLAST XML output\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m blast_record \u001b[39m=\u001b[39m NCBIXML\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mStringIO(result\u001b[39m.\u001b[39mstdout))\n\u001b[0;32m     52\u001b[0m \u001b[39mif\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments:\n\u001b[0;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mhsps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mscore\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\Bio\\Blast\\NCBIXML.py:754\u001b[0m, in \u001b[0;36mread\u001b[1;34m(handle, debug)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m--> 754\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMore than one record found in handle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    755\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    756\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: More than one record found in handle"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\"{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open('temp_query.fasta', 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', 'temp_query.fasta', '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Parse the BLAST XML output\n",
    "    blast_record = NCBIXML.read(io.StringIO(result.stdout))\n",
    "    if blast_record.alignments:\n",
    "        return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Parallelize BLAST queries\n",
    "def process_sequence(fasta):\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score = get_blast_score(sequence)\n",
    "    return feature, kmer_feature , blast_score\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(process_sequence, merged_df['FASTA']))\n",
    "\n",
    "for feature, kmer_feature,blast_score in results: # ,blast_scores kan ook nog toegevoegd worden\n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content','blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, save the model for future use\n",
    "import joblib\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# save the blast scores for future use\n",
    "df.to_csv(features_df, 'blast scores.csv', index=False)\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('temp_query.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acf93f-d9c8-43ab-953f-70162dbdd181",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Your XML file was empty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:78\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m feature, kmer_feature, blast_score\n\u001b[0;32m     77\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor(max_workers\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m---> 78\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(executor\u001b[39m.\u001b[39mmap(process_sequence, df[\u001b[39m'\u001b[39m\u001b[39mFASTA\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m feature, kmer_feature, blast_score \u001b[39min\u001b[39;00m results:\n\u001b[0;32m     81\u001b[0m     features\u001b[39m.\u001b[39mappend(feature)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop())\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39mresult(timeout)\n\u001b[0;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:74\u001b[0m\n\u001b[0;32m     72\u001b[0m feature \u001b[39m=\u001b[39m extract_features(sequence)\n\u001b[0;32m     73\u001b[0m kmer_feature \u001b[39m=\u001b[39m get_kmers(sequence)\n\u001b[1;32m---> 74\u001b[0m blast_score \u001b[39m=\u001b[39m get_blast_score(sequence)\n\u001b[0;32m     75\u001b[0m \u001b[39mreturn\u001b[39;00m feature, kmer_feature, blast_score\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:52\u001b[0m\n\u001b[0;32m     46\u001b[0m result \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mrun(\n\u001b[0;32m     47\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mblastn\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-query\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtemp_query.fasta\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-db\u001b[39m\u001b[39m'\u001b[39m, db, \u001b[39m'\u001b[39m\u001b[39m-outfmt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     48\u001b[0m     capture_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, text\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[39m# Parse the BLAST XML output\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m blast_record \u001b[39m=\u001b[39m NCBIXML\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mStringIO(result\u001b[39m.\u001b[39mstdout))\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments:\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mhsps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mscore\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\Bio\\Blast\\NCBIXML.py:749\u001b[0m, in \u001b[0;36mread\u001b[1;34m(handle, debug)\u001b[0m\n\u001b[0;32m    747\u001b[0m iterator \u001b[39m=\u001b[39m parse(handle, debug)\n\u001b[0;32m    748\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 749\u001b[0m     record \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m    750\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    751\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo records found in handle\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\Bio\\Blast\\NCBIXML.py:800\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(handle, debug)\u001b[0m\n\u001b[0;32m    796\u001b[0m     pending \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    798\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m text:\n\u001b[0;32m    799\u001b[0m     \u001b[39m# NO DATA FOUND!\u001b[39;00m\n\u001b[1;32m--> 800\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYour XML file was empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    802\u001b[0m \u001b[39mwhile\u001b[39;00m text:\n\u001b[0;32m    803\u001b[0m     \u001b[39m# We are now starting a new XML file\u001b[39;00m\n\u001b[0;32m    804\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m text\u001b[39m.\u001b[39mstartswith(XML_START):\n",
      "\u001b[1;31mValueError\u001b[0m: Your XML file was empty"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open('temp_query.fasta', 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', 'temp_query.fasta', '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Parse the BLAST XML output\n",
    "    blast_record = NCBIXML.read(io.StringIO(result.stdout))\n",
    "    if blast_record.alignments:\n",
    "        return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "\n",
    "# Check if BLAST scores file exists\n",
    "blast_scores_file = 'blast_scores.csv'\n",
    "if os.path.exists(blast_scores_file):\n",
    "    # Load BLAST scores from file\n",
    "    blast_scores_df = pd.read_csv(blast_scores_file)\n",
    "    blast_scores = blast_scores_df['blast_score'].tolist()\n",
    "else:\n",
    "    # Compute BLAST scores\n",
    "    features = []\n",
    "    kmer_features = []\n",
    "    blast_scores = []\n",
    "\n",
    "    # Parallelize BLAST queries\n",
    "    def process_sequence(fasta):\n",
    "        sequence = str(Seq(fasta))\n",
    "        feature = extract_features(sequence)\n",
    "        kmer_feature = get_kmers(sequence)\n",
    "        blast_score = get_blast_score(sequence)\n",
    "        return feature, kmer_feature, blast_score\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = list(executor.map(process_sequence, df['FASTA']))\n",
    "\n",
    "    for feature, kmer_feature, blast_score in results:\n",
    "        features.append(feature)\n",
    "        kmer_features.append(kmer_feature)\n",
    "        blast_scores.append(blast_score)\n",
    "\n",
    "    # Save BLAST scores to file\n",
    "    blast_scores_df = pd.DataFrame({'blast_score': blast_scores})\n",
    "    blast_scores_df.to_csv(blast_scores_file, index=False)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# save the blast scores for future use\n",
    "df.to_csv(features_df, 'blast scores.csv', index=False)\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('temp_query.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46396a3-f3ee-4181-9b79-590e1bc77662",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "More than one record found in handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:81\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m feature, kmer_feature , blast_score\n\u001b[0;32m     80\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m---> 81\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(executor\u001b[39m.\u001b[39mmap(process_sequence, merged_df[\u001b[39m'\u001b[39m\u001b[39mFASTA\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m feature, kmer_feature,blast_score \u001b[39min\u001b[39;00m results: \u001b[39m# ,blast_scores kan ook nog toegevoegd worden\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     features\u001b[39m.\u001b[39mappend(feature)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop())\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39mresult(timeout)\n\u001b[0;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:77\u001b[0m\n\u001b[0;32m     75\u001b[0m feature \u001b[39m=\u001b[39m extract_features(sequence)\n\u001b[0;32m     76\u001b[0m kmer_feature \u001b[39m=\u001b[39m get_kmers(sequence)\n\u001b[1;32m---> 77\u001b[0m blast_score \u001b[39m=\u001b[39m get_blast_score(sequence)\n\u001b[0;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m feature, kmer_feature , blast_score\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39m# Check if the BLAST search produced valid output\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip():\n\u001b[0;32m     52\u001b[0m     \u001b[39m# Parse the BLAST XML output\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     blast_record \u001b[39m=\u001b[39m NCBIXML\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mStringIO(result\u001b[39m.\u001b[39mstdout))\n\u001b[0;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments:\n\u001b[0;32m     55\u001b[0m         \u001b[39mreturn\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mhsps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mscore\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\Bio\\Blast\\NCBIXML.py:754\u001b[0m, in \u001b[0;36mread\u001b[1;34m(handle, debug)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m--> 754\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMore than one record found in handle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    755\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    756\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: More than one record found in handle"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\"{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open('temp_query.fasta', 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', 'temp_query.fasta', '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "        # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_record = NCBIXML.read(io.StringIO(result.stdout))\n",
    "        if blast_record.alignments:\n",
    "            return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Parallelize BLAST queries\n",
    "def process_sequence(fasta):\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score = get_blast_score(sequence)\n",
    "    return feature, kmer_feature , blast_score\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(process_sequence, merged_df['FASTA']))\n",
    "\n",
    "for feature, kmer_feature,blast_score in results: # ,blast_scores kan ook nog toegevoegd worden\n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content','blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, save the model for future use\n",
    "import joblib\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# save the blast scores for future use\n",
    "df.to_csv(features_df, 'blast scores.csv', index=False)\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('temp_query.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae131aa-651c-4378-9379-8f295845f52e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "More than one record found in handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:83\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m feature, kmer_feature, blast_score\n\u001b[0;32m     82\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m---> 83\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(executor\u001b[39m.\u001b[39mmap(process_sequence, merged_df[\u001b[39m'\u001b[39m\u001b[39mFASTA\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m feature, kmer_feature, blast_score \u001b[39min\u001b[39;00m results:\n\u001b[0;32m     86\u001b[0m     features\u001b[39m.\u001b[39mappend(feature)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop())\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39mresult(timeout)\n\u001b[0;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:79\u001b[0m\n\u001b[0;32m     77\u001b[0m feature \u001b[39m=\u001b[39m extract_features(sequence)\n\u001b[0;32m     78\u001b[0m kmer_feature \u001b[39m=\u001b[39m get_kmers(sequence)\n\u001b[1;32m---> 79\u001b[0m blast_score \u001b[39m=\u001b[39m get_blast_score(sequence)\n\u001b[0;32m     80\u001b[0m \u001b[39mreturn\u001b[39;00m feature, kmer_feature, blast_score\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:54\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39m# Check if the BLAST search produced valid output\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip():\n\u001b[0;32m     53\u001b[0m     \u001b[39m# Parse the BLAST XML output\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     blast_record \u001b[39m=\u001b[39m NCBIXML\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mStringIO(result\u001b[39m.\u001b[39mstdout))\n\u001b[0;32m     55\u001b[0m     \u001b[39mif\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments:\n\u001b[0;32m     56\u001b[0m         \u001b[39mreturn\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mhsps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mscore\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\Bio\\Blast\\NCBIXML.py:754\u001b[0m, in \u001b[0;36mread\u001b[1;34m(handle, debug)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m--> 754\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMore than one record found in handle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    755\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    756\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: More than one record found in handle"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open('temp_query.fasta', 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', 'temp_query.fasta', '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_record = NCBIXML.read(io.StringIO(result.stdout))\n",
    "        if blast_record.alignments:\n",
    "            return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Parallelize BLAST queries\n",
    "def process_sequence(fasta):\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score = get_blast_score(sequence)\n",
    "    return feature, kmer_feature, blast_score\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(process_sequence, merged_df['FASTA']))\n",
    "\n",
    "for feature, kmer_feature, blast_score in results:\n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, save the model for future use\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Save the blast scores for future use\n",
    "features_df.to_csv('blast_scores.csv', index=False)\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('temp_query.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bc8fb-5fe9-43eb-bc7a-a31029abfd5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:82\u001b[0m\n\u001b[0;32m     79\u001b[0m     blast_score \u001b[39m=\u001b[39m get_blast_score(sequence)\n\u001b[0;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m feature, kmer_feature, blast_score\n\u001b[1;32m---> 82\u001b[0m \u001b[39mfor\u001b[39;00m feature, kmer_feature, blast_score \u001b[39min\u001b[39;00m results:\n\u001b[0;32m     83\u001b[0m     features\u001b[39m.\u001b[39mappend(feature)\n\u001b[0;32m     84\u001b[0m     kmer_features\u001b[39m.\u001b[39mappend(kmer_feature)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open('temp_query.fasta', 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', 'temp_query.fasta', '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_record = NCBIXML.read(io.StringIO(result.stdout))\n",
    "        if blast_record.alignments:\n",
    "            return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Parallelize BLAST queries\n",
    "def process_sequence(fasta):\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score = get_blast_score(sequence)\n",
    "    return feature, kmer_feature, blast_score\n",
    "\n",
    "for feature, kmer_feature, blast_score in results:\n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, save the model for future use\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Save the blast scores for future use\n",
    "features_df.to_csv('blast_scores.csv', index=False)\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('temp_query.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c0e70-97fc-4165-b54f-6dbd67fab030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5251d9-8b83-48db-adb7-f353d4c3f166",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "More than one record found in handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:87\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[39mreturn\u001b[39;00m feature, kmer_feature, blast_score\n\u001b[0;32m     86\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m---> 87\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(executor\u001b[39m.\u001b[39mmap(process_sequence, merged_df[\u001b[39m'\u001b[39m\u001b[39mFASTA\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     89\u001b[0m \u001b[39mfor\u001b[39;00m feature, kmer_feature, blast_score \u001b[39min\u001b[39;00m results:\n\u001b[0;32m     90\u001b[0m     features\u001b[39m.\u001b[39mappend(feature)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop())\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39mresult(timeout)\n\u001b[0;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:83\u001b[0m\n\u001b[0;32m     81\u001b[0m feature \u001b[39m=\u001b[39m extract_features(sequence)\n\u001b[0;32m     82\u001b[0m kmer_feature \u001b[39m=\u001b[39m get_kmers(sequence)\n\u001b[1;32m---> 83\u001b[0m blast_score \u001b[39m=\u001b[39m get_blast_score(sequence)\n\u001b[0;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m feature, kmer_feature, blast_score\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:58\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# Check if the BLAST search produced valid output\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip():\n\u001b[0;32m     57\u001b[0m     \u001b[39m# Parse the BLAST XML output\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     blast_record \u001b[39m=\u001b[39m NCBIXML\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mStringIO(result\u001b[39m.\u001b[39mstdout))\n\u001b[0;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments:\n\u001b[0;32m     60\u001b[0m         \u001b[39mreturn\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mhsps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mscore\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\Bio\\Blast\\NCBIXML.py:754\u001b[0m, in \u001b[0;36mread\u001b[1;34m(handle, debug)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m--> 754\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMore than one record found in handle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    755\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    756\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: More than one record found in handle"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Use a unique filename for each thread\n",
    "    temp_fasta_filename = f'temp_query_{threading.get_ident()}.fasta'\n",
    "    \n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open('temp_query.fasta', 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', 'temp_query.fasta', '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_record = NCBIXML.read(io.StringIO(result.stdout))\n",
    "        if blast_record.alignments:\n",
    "            return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Parallelize BLAST queries\n",
    "def process_sequence(fasta):\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score = get_blast_score(sequence)\n",
    "    return feature, kmer_feature, blast_score\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(process_sequence, merged_df['FASTA']))\n",
    "\n",
    "for feature, kmer_feature, blast_score in results:\n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, save the model for future use\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Save the blast scores for future use\n",
    "features_df.to_csv('blast_scores.csv', index=False)\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('temp_query.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c0139-7781-4bc1-b193-282c934d5f2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Het systeem kan het opgegeven bestand niet vinden: 'temp_query_15960.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:89\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[39mreturn\u001b[39;00m feature, kmer_feature, blast_score\n\u001b[0;32m     88\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m---> 89\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(executor\u001b[39m.\u001b[39mmap(process_sequence, merged_df[\u001b[39m'\u001b[39m\u001b[39mFASTA\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m feature, kmer_feature, blast_score \u001b[39min\u001b[39;00m results:\n\u001b[0;32m     92\u001b[0m     features\u001b[39m.\u001b[39mappend(feature)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop())\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39mresult(timeout)\n\u001b[0;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:85\u001b[0m\n\u001b[0;32m     83\u001b[0m feature \u001b[39m=\u001b[39m extract_features(sequence)\n\u001b[0;32m     84\u001b[0m kmer_feature \u001b[39m=\u001b[39m get_kmers(sequence)\n\u001b[1;32m---> 85\u001b[0m blast_score \u001b[39m=\u001b[39m get_blast_score(sequence)\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m feature, kmer_feature, blast_score\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:55\u001b[0m\n\u001b[0;32m     50\u001b[0m result \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mrun(\n\u001b[0;32m     51\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mblastn\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-query\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtemp_query.fasta\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-db\u001b[39m\u001b[39m'\u001b[39m, db, \u001b[39m'\u001b[39m\u001b[39m-outfmt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     52\u001b[0m     capture_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, text\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[39m# Remove the temporary FASTA file\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m os\u001b[39m.\u001b[39mremove(temp_fasta_filename)\n\u001b[0;32m     57\u001b[0m \u001b[39m# Check if the BLAST search produced valid output\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip():\n\u001b[0;32m     59\u001b[0m     \u001b[39m# Parse the BLAST XML output\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Het systeem kan het opgegeven bestand niet vinden: 'temp_query_15960.fasta'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Use a unique filename for each thread\n",
    "    temp_fasta_filename = f'temp_query_{threading.get_ident()}.fasta'\n",
    "    \n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open('temp_query.fasta', 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', 'temp_query.fasta', '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    # Remove the temporary FASTA file\n",
    "    os.remove(temp_fasta_filename)\n",
    "    \n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_record = NCBIXML.read(io.StringIO(result.stdout))\n",
    "        if blast_record.alignments:\n",
    "            return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Parallelize BLAST queries\n",
    "def process_sequence(fasta):\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score = get_blast_score(sequence)\n",
    "    return feature, kmer_feature, blast_score\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(process_sequence, merged_df['FASTA']))\n",
    "\n",
    "for feature, kmer_feature, blast_score in results:\n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, save the model for future use\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Save the blast scores for future use\n",
    "features_df.to_csv('blast_scores.csv', index=False)\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('temp_query.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db4e86-9374-4e63-9b3d-90e583bddd29",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Het systeem kan het opgegeven bestand niet vinden: 'temp_query_10076.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:85\u001b[0m\n\u001b[0;32m     83\u001b[0m feature \u001b[39m=\u001b[39m extract_features(sequence)\n\u001b[0;32m     84\u001b[0m kmer_feature \u001b[39m=\u001b[39m get_kmers(sequence)\n\u001b[1;32m---> 85\u001b[0m blast_score \u001b[39m=\u001b[39m get_blast_score(sequence)\n\u001b[0;32m     87\u001b[0m features\u001b[39m.\u001b[39mappend(feature)\n\u001b[0;32m     88\u001b[0m kmer_features\u001b[39m.\u001b[39mappend(kmer_feature)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:55\u001b[0m\n\u001b[0;32m     50\u001b[0m result \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mrun(\n\u001b[0;32m     51\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mblastn\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-query\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtemp_query.fasta\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-db\u001b[39m\u001b[39m'\u001b[39m, db, \u001b[39m'\u001b[39m\u001b[39m-outfmt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     52\u001b[0m     capture_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, text\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[39m# Remove the temporary FASTA file\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m os\u001b[39m.\u001b[39mremove(temp_fasta_filename)\n\u001b[0;32m     57\u001b[0m \u001b[39m# Check if the BLAST search produced valid output\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip():\n\u001b[0;32m     59\u001b[0m     \u001b[39m# Parse the BLAST XML output\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Het systeem kan het opgegeven bestand niet vinden: 'temp_query_10076.fasta'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Use a unique filename for each thread\n",
    "    temp_fasta_filename = f'temp_query_{threading.get_ident()}.fasta'\n",
    "    \n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open('temp_query.fasta', 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', 'temp_query.fasta', '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    # Remove the temporary FASTA file\n",
    "    os.remove(temp_fasta_filename)\n",
    "\n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_record = NCBIXML.read(io.StringIO(result.stdout))\n",
    "        if blast_record.alignments:\n",
    "            return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, save the model for future use\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Save the blast scores for future use\n",
    "features_df.to_csv('blast_scores.csv', index=False)\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('temp_query.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19903493-d19c-439f-89b8-bed744d2f90e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "More than one record found in handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:83\u001b[0m\n\u001b[0;32m     81\u001b[0m feature \u001b[39m=\u001b[39m extract_features(sequence)\n\u001b[0;32m     82\u001b[0m kmer_feature \u001b[39m=\u001b[39m get_kmers(sequence)\n\u001b[1;32m---> 83\u001b[0m blast_score \u001b[39m=\u001b[39m get_blast_score(sequence)\n\u001b[0;32m     85\u001b[0m features\u001b[39m.\u001b[39mappend(feature)\n\u001b[0;32m     86\u001b[0m kmer_features\u001b[39m.\u001b[39mappend(kmer_feature)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:58\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# Check if the BLAST search produced valid output\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip():\n\u001b[0;32m     57\u001b[0m     \u001b[39m# Parse the BLAST XML output\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     blast_record \u001b[39m=\u001b[39m NCBIXML\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mStringIO(result\u001b[39m.\u001b[39mstdout))\n\u001b[0;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments:\n\u001b[0;32m     60\u001b[0m         \u001b[39mreturn\u001b[39;00m blast_record\u001b[39m.\u001b[39malignments[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mhsps[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mscore\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\Bio\\Blast\\NCBIXML.py:754\u001b[0m, in \u001b[0;36mread\u001b[1;34m(handle, debug)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m--> 754\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMore than one record found in handle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    755\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    756\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: More than one record found in handle"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Use a unique filename for each thread\n",
    "    temp_fasta_filename = f'temp_query_{threading.get_ident()}.fasta'\n",
    "    \n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open('temp_query.fasta', 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', 'temp_query.fasta', '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "\n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_record = NCBIXML.read(io.StringIO(result.stdout))\n",
    "        if blast_record.alignments:\n",
    "            return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, save the model for future use\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Save the blast scores for future use\n",
    "features_df.to_csv('blast_scores.csv', index=False)\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('temp_query.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e95e03-9913-4ab6-a1c8-3709ef68b2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8975\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.84      0.98      0.91       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.93      0.80      0.86       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.96      0.99      0.97        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.53      0.44      0.45       400\n",
      "weighted avg       0.89      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Use a unique filename for each thread\n",
    "    temp_fasta_filename = f'temp_query_{threading.get_ident()}.fasta'\n",
    "    \n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open(temp_fasta_filename, 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', temp_fasta_filename, '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Remove the temporary FASTA file\n",
    "    os.remove(temp_fasta_filename)\n",
    "    \n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_records = NCBIXML.parse(io.StringIO(result.stdout))\n",
    "        for blast_record in blast_records:\n",
    "            if blast_record.alignments:\n",
    "                return blast_record.alignments[0].hsps[0].score\n",
    "    return 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally, save the model for future use\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Save the blast scores for future use\n",
    "features_df.to_csv('blast_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337b43b-c147-44be-845e-5bc9fe832bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.67      0.71      0.69       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       1.00      1.00      1.00         2\n",
      "         ssj       1.00      0.50      0.67         2\n",
      "         std       0.60      0.59      0.60       135\n",
      "         stf       0.50      0.14      0.22         7\n",
      "         stx       0.79      0.79      0.79        97\n",
      "\n",
      "    accuracy                           0.68       400\n",
      "   macro avg       0.65      0.53      0.57       400\n",
      "weighted avg       0.68      0.68      0.68       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] # + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf679d-0ca8-4f33-bda8-01caaf1f30a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.61      0.66      0.63       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       1.00      1.00      1.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.53      0.53      0.53       135\n",
      "         stf       1.00      0.14      0.25         7\n",
      "         stx       0.74      0.69      0.72        97\n",
      "\n",
      "    accuracy                           0.61       400\n",
      "   macro avg       0.55      0.43      0.45       400\n",
      "weighted avg       0.62      0.61      0.61       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = [ 'gc_content', 'blast_score'] # + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad8ebd-ce40-4de5-a728-88450e846506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6325\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.59      0.74      0.66       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hax       0.00      0.00      0.00         0\n",
      "         hex       1.00      1.00      1.00         2\n",
      "         ssj       1.00      1.00      1.00         2\n",
      "         std       0.54      0.41      0.46       135\n",
      "         stf       0.00      0.00      0.00         7\n",
      "         stx       0.80      0.80      0.80        97\n",
      "\n",
      "    accuracy                           0.63       400\n",
      "   macro avg       0.49      0.49      0.49       400\n",
      "weighted avg       0.62      0.63      0.62       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'blast_score'] # + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116ebc1-6b6a-4b03-add2-0d4810409c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5075\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.54      0.56      0.55       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       1.00      1.00      1.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.44      0.43      0.43       135\n",
      "         stf       0.17      0.14      0.15         7\n",
      "         stx       0.56      0.57      0.56        97\n",
      "\n",
      "    accuracy                           0.51       400\n",
      "   macro avg       0.39      0.39      0.39       400\n",
      "weighted avg       0.50      0.51      0.50       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_columns = ['length', 'gc_content'] # + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db06c1-1586-4979-a948-2d5d57a70dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.67      0.71      0.69       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       1.00      1.00      1.00         2\n",
      "         ssj       1.00      0.50      0.67         2\n",
      "         std       0.60      0.59      0.60       135\n",
      "         stf       0.50      0.14      0.22         7\n",
      "         stx       0.79      0.79      0.79        97\n",
      "\n",
      "    accuracy                           0.68       400\n",
      "   macro avg       0.65      0.53      0.57       400\n",
      "weighted avg       0.68      0.68      0.68       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score'] # + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b05220-58e3-4fe6-a4a4-e733dfa8acea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['blast_score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Prepare the data\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# Assuming 'Characteristic' is the column you want to predict\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Specify the columns you want to use for X\u001b[39;00m\n\u001b[0;32m     41\u001b[0m feature_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgc_content\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblast_score\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kmer_df\u001b[39m.\u001b[39mcolumns)  \u001b[39m# Add more features as needed\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m X \u001b[39m=\u001b[39m df[feature_columns]\n\u001b[0;32m     43\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mMod\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Replace with your target column\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['blast_score'] not in index\""
     ]
    }
   ],
   "source": [
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c5e0a-8019-48eb-9889-ccda8dec682c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['blast_score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Prepare the data\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# Assuming 'Characteristic' is the column you want to predict\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Specify the columns you want to use for X\u001b[39;00m\n\u001b[0;32m     41\u001b[0m feature_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgc_content\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblast_score\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kmer_df\u001b[39m.\u001b[39mcolumns)  \u001b[39m# Add more features as needed\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m X \u001b[39m=\u001b[39m df[feature_columns]\n\u001b[0;32m     43\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mMod\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Replace with your target column\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['blast_score'] not in index\""
     ]
    }
   ],
   "source": [
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b675320d-49c7-4d70-af45-ba4bd5406721",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[\\'>NC\\', \\'NC_\\', \\'C_0\\', \\'_03\\', \\'039\\', \\'399\\', \\'992\\', \\'929\\', \\'29.\\', \\'9.1\\', \\'.1:\\', \\'1:1\\', \\':16\\', \\'166\\', \\'668\\', \\'687\\', \\'87-\\', \\'7-1\\', \\'-19\\', \\'191\\', \\'911\\', \\'112\\', \\'12 \\', \\'2 A\\', \\' Ac\\', \\'Act\\', \\'cti\\', \\'tin\\', \\'ini\\', \\'nia\\', \\'ia \\', \\'a e\\', \\' eq\\', \\'equ\\', \\'qui\\', \\'uin\\', \\'ina\\', \\'na \\', \\'a m\\', \\' mi\\', \\'mit\\', \\'ito\\', \\'toc\\', \\'och\\', \\'cho\\', \\'hon\\', \\'ond\\', \\'ndr\\', \\'dri\\', \\'rio\\', \\'ion\\', \\'on,\\', \\'n, \\', \\', c\\', \\' co\\', \\'com\\', \\'omp\\', \\'mpl\\', \\'ple\\', \\'let\\', \\'ete\\', \\'te \\', \\'e g\\', \\' ge\\', \\'gen\\', \\'eno\\', \\'nom\\', \\'ome\\', \\'me\\\\n\\', \\'e\\\\nA\\', \\'\\\\nAT\\', \\'ATG\\', \\'TGA\\', \\'GAA\\', \\'AAT\\', \\'ATA\\', \\'TAA\\', \\'AAA\\', \\'ATT\\', \\'TTT\\', \\'TTA\\', \\'AAC\\', \\'ACT\\', \\'CTC\\', \\'TCG\\', \\'CGT\\', \\'GTT\\', \\'TTG\\', \\'GAG\\', \\'AGT\\', \\'GTA\\', \\'TAT\\', \\'TTC\\', \\'TCC\\', \\'CCA\\', \\'CAC\\', \\'CTA\\', \\'ATC\\', \\'TCA\\', \\'ACA\\', \\'CAA\\', \\'AAG\\', \\'AGA\\', \\'GAT\\', \\'CGG\\', \\'GGA\\', \\'CTT\\', \\'TA\\\\n\\', \\'A\\\\nT\\', \\'\\\\nTA\\', \\'TAG\\', \\'GTG\\', \\'TGT\\', \\'TGG\\', \\'AGG\\', \\'CCG\\', \\'GGT\\', \\'GGC\\', \\'GCA\\', \\'CAG\\', \\'AGC\\', \\'GCT\\', \\'GA\\\\n\\', \\'\\\\nTT\\', \\'TCT\\', \\'CTG\\', \\'TGC\\', \\'GCC\\', \\'CCC\\', \\'CCT\\', \\'TAC\\', \\'GGG\\', \\'GAC\\', \\'ACG\\', \\'CGA\\', \\'ACC\\', \\'CAT\\', \\'GTC\\', \\'TG\\\\n\\', \\'G\\\\nA\\', \\'\\\\nAC\\', \\'CGC\\', \\'TT\\\\n\\', \\'T\\\\nG\\', \\'\\\\nGG\\', \\'GCG\\', \\'AC\\\\n\\', \\'C\\\\nA\\', \\'\\\\nAA\\', \\'\\\\nGA\\', \\'C\\\\nT\\', \\'\\\\nTC\\', \\'G\\\\nG\\', \\'CC\\\\n\\', \\'C\\\\nC\\', \\'\\\\nCT\\', \\'CT\\\\n\\', \\'T\\\\nT\\', \\'A\\\\nC\\', \\'\\\\nCC\\', \\'GC\\\\n\\', \\'\\\\nCG\\', \\'A\\\\nA\\', \\'A\\\\nG\\', \\'\\\\nGC\\', \\'TC\\\\n\\', \\'\\\\nAG\\', \\'CG\\\\n\\', \\'G\\\\nC\\', \\'AA\\\\n\\', \\'C\\\\nG\\', \\'T\\\\nC\\', \\'T\\\\nA\\', \\'AG\\\\n\\', \\'\\\\nCA\\', \\'CA\\\\n\\', \\'G\\\\nT\\', \\'GG\\\\n\\', \\'\\\\nGT\\', \\'_00\\', \\'000\\', \\'009\\', \\'093\\', \\'933\\', \\'33.\\', \\'3.1\\', \\'1:3\\', \\':32\\', \\'326\\', \\'263\\', \\'63-\\', \\'3-5\\', \\'-57\\', \\'570\\', \\'708\\', \\'08 \\', \\'8 M\\', \\' Me\\', \\'Met\\', \\'etr\\', \\'tri\\', \\'rid\\', \\'idi\\', \\'diu\\', \\'ium\\', \\'um \\', \\'m s\\', \\' se\\', \\'sen\\', \\'eni\\', \\'nil\\', \\'ile\\', \\'le \\', \\'e m\\', \\'\\\\nTG\\', \\'GT\\\\n\\', \\'AT\\\\n\\', \\'_08\\', \\'080\\', \\'803\\', \\'035\\', \\'358\\', \\'58.\\', \\'8.1\\', \\'322\\', \\'221\\', \\'21-\\', \\'1-4\\', \\'-47\\', \\'479\\', \\'798\\', \\'98 \\', \\'8 P\\', \\' Pe\\', \\'Pel\\', \\'ela\\', \\'lag\\', \\'agi\\', \\'gia\\', \\'a n\\', \\' no\\', \\'noc\\', \\'oct\\', \\'til\\', \\'ilu\\', \\'luc\\', \\'uca\\', \\'ca \\', \\'e\\\\nC\\', \\'_01\\', \\'016\\', \\'164\\', \\'646\\', \\'466\\', \\'66.\\', \\'6.1\\', \\'1:2\\', \\':26\\', \\'268\\', \\'7-4\\', \\'-42\\', \\'426\\', \\'267\\', \\'67 \\', \\'7 C\\', \\' Ca\\', \\'Cas\\', \\'ass\\', \\'ssi\\', \\'sio\\', \\'iop\\', \\'ope\\', \\'pea\\', \\'ea \\', \\'a x\\', \\' xa\\', \\'xam\\', \\'ama\\', \\'mac\\', \\'ach\\', \\'cha\\', \\'han\\', \\'ana\\', \\'e\\\\nT\\', \\'161\\', \\'611\\', \\'117\\', \\'17.\\', \\'7.1\\', \\':1-\\', \\'1-1\\', \\'-15\\', \\'152\\', \\'524\\', \\'24 \\', \\'4 M\\', \\' Mn\\', \\'Mne\\', \\'nem\\', \\'emi\\', \\'mio\\', \\'ops\\', \\'psi\\', \\'sis\\', \\'is \\', \\'s l\\', \\' le\\', \\'lei\\', \\'eid\\', \\'idy\\', \\'dyi\\', \\'yi \\', \\'i m\\', \\'014\\', \\'145\\', \\'457\\', \\'578\\', \\'78.\\', \\'1:7\\', \\':7-\\', \\'155\\', \\'551\\', \\'51 \\', \\'1 S\\', \\' Sy\\', \\'Sym\\', \\'yms\\', \\'msa\\', \\'sag\\', \\'git\\', \\'itt\\', \\'tti\\', \\'tif\\', \\'ife\\', \\'fer\\', \\'era\\', \\'ra \\', \\'a r\\', \\' ro\\', \\'ros\\', \\'osc\\', \\'sco\\', \\'cof\\', \\'off\\', \\'ffe\\', \\'fen\\', \\'ens\\', \\'nsi\\', \\'s m\\', \\'010\\', \\'104\\', \\'048\\', \\'484\\', \\'84.\\', \\'4.1\\', \\'1 B\\', \\' Br\\', \\'Bra\\', \\'rac\\', \\'chi\\', \\'hio\\', \\'onu\\', \\'nus\\', \\'us \\', \\'s p\\', \\' pl\\', \\'pli\\', \\'lic\\', \\'ica\\', \\'cat\\', \\'ati\\', \\'ili\\', \\'lis\\', \\'on \\', \\'n p\\', \\' pa\\', \\'par\\', \\'art\\', \\'rt \\', \\'t I\\', \\' II\\', \\'II,\\', \\'I, \\', \\'001\\', \\'163\\', \\'636\\', \\'36.\\', \\'154\\', \\'548\\', \\'48 \\', \\'8 K\\', \\' Ka\\', \\'Kat\\', \\'ath\\', \\'tha\\', \\'har\\', \\'ari\\', \\'rin\\', \\'a t\\', \\' tu\\', \\'tun\\', \\'uni\\', \\'nic\\', \\'ata\\', \\'ta \\', \\'GCN\\', \\'CN\\\\n\\', \\'N\\\\nG\\', \\'_02\\', \\'026\\', \\'685\\', \\'850\\', \\'50.\\', \\'0.1\\', \\'153\\', \\'533\\', \\'33 \\', \\'3 C\\', \\' Cr\\', \\'Cry\\', \\'ryp\\', \\'ypt\\', \\'pto\\', \\'hit\\', \\'ton\\', \\'n s\\', \\' st\\', \\'ste\\', \\'tel\\', \\'ell\\', \\'lle\\', \\'ler\\', \\'eri\\', \\'ri \\', \\'007\\', \\'072\\', \\'723\\', \\'234\\', \\'34.\\', \\':14\\', \\'141\\', \\'410\\', \\'105\\', \\'05-\\', \\'5-1\\', \\'156\\', \\'561\\', \\'617\\', \\'17 \\', \\'7 P\\', \\' Pl\\', \\'Pla\\', \\'lac\\', \\'aco\\', \\'cop\\', \\'pec\\', \\'ect\\', \\'cte\\', \\'ten\\', \\'en \\', \\'n m\\', \\' ma\\', \\'mag\\', \\'age\\', \\'gel\\', \\'lla\\', \\'lan\\', \\'ani\\', \\'icu\\', \\'cus\\', \\'027\\', \\'279\\', \\'794\\', \\'943\\', \\'43.\\', \\'-16\\', \\'160\\', \\'602\\', \\'02 \\', \\' Ar\\', \\'Arg\\', \\'rgo\\', \\'gop\\', \\' pu\\', \\'pur\\', \\'urp\\', \\'rpu\\', \\'ura\\', \\'rat\\', \\'atu\\', \\'tus\\', \\'_06\\', \\'061\\', \\'174\\', \\'741\\', \\'41.\\', \\'1.1\\', \\'260\\', \\'604\\', \\'04-\\', \\'4-4\\', \\'-41\\', \\'412\\', \\'127\\', \\'27 \\', \\'7 M\\', \\' Mi\\', \\'Mim\\', \\'ima\\', \\'chl\\', \\'hla\\', \\'lam\\', \\'amy\\', \\'mys\\', \\'ys \\', \\'s v\\', \\' va\\', \\'var\\', \\'ria\\', \\'012\\', \\'276\\', \\'76.\\', \\':15\\', \\'559\\', \\'598\\', \\'98-\\', \\'8-1\\', \\'-17\\', \\'171\\', \\'711\\', \\'115\\', \\'15 \\', \\'5 C\\', \\'Cra\\', \\'ras\\', \\'sso\\', \\'sos\\', \\'ost\\', \\'str\\', \\'tre\\', \\'rea\\', \\'a g\\', \\' gi\\', \\'gig\\', \\'iga\\', \\'gas\\', \\'as \\', \\'618\\', \\'180\\', \\'80.\\', \\'566\\', \\'66 \\', \\'6 O\\', \\' Os\\', \\'Ost\\', \\' ed\\', \\'edu\\', \\'dul\\', \\'uli\\', \\'277\\', \\'772\\', \\'724\\', \\'24.\\', \\'165\\', \\'656\\', \\'56 \\', \\'6 S\\', \\' Sa\\', \\'Sac\\', \\'acc\\', \\'cco\\', \\'cos\\', \\'a c\\', \\' cu\\', \\'cuc\\', \\'ucu\\', \\'cul\\', \\'ull\\', \\'lat\\', \\'064\\', \\'641\\', \\'413\\', \\'131\\', \\'31.\\', \\'605\\', \\'05 \\', \\'5 B\\', \\'hid\\', \\'ido\\', \\'don\\', \\'ont\\', \\'nte\\', \\'tes\\', \\'es \\', \\' ph\\', \\'pha\\', \\'ara\\', \\'rao\\', \\'aon\\', \\'oni\\', \\'nis\\', \\'s i\\', \\' is\\', \\'iso\\', \\'sol\\', \\'ola\\', \\'ate\\', \\'e B\\', \\' BR\\', \\'BRS\\', \\'RS_\\', \\'S_A\\', \\'_A \\', \\'A m\\', \\'619\\', \\'190\\', \\'903\\', \\'03.\\', \\'1:5\\', \\':52\\', \\'529\\', \\'294\\', \\'94-\\', \\'4-6\\', \\'-68\\', \\'689\\', \\'895\\', \\'95 \\', \\'5 G\\', \\' Ge\\', \\'Geu\\', \\'euk\\', \\'uke\\', \\'ken\\', \\'sia\\', \\'a d\\', \\' de\\', \\'dem\\', \\'mis\\', \\'iss\\', \\'ssa\\', \\'sa \\', \\'a v\\', \\' vo\\', \\'vou\\', \\'ouc\\', \\'uch\\', \\'che\\', \\'her\\', \\'er \\', \\'r W\\', \\' WA\\', \\'WAM\\', \\'AM \\', \\'M 7\\', \\' 70\\', \\'706\\', \\'640\\', \\'40 \\', \\'0 m\\', \\'015\\', \\'159\\', \\'599\\', \\'993\\', \\'93.\\', \\'1:9\\', \\':90\\', \\'905\\', \\'051\\', \\'51-\\', \\'-10\\', \\'107\\', \\'070\\', \\'06 \\', \\'6 M\\', \\' My\\', \\'Myt\\', \\'yti\\', \\'lus\\', \\'s c\\', \\' ca\\', \\'cal\\', \\'ali\\', \\'lif\\', \\'ifo\\', \\'for\\', \\'orn\\', \\'rni\\', \\'ian\\', \\'anu\\', \\'006\\', \\'068\\', \\'688\\', \\'886\\', \\'86.\\', \\'6.2\\', \\'.2:\\', \\'2:9\\', \\'906\\', \\'68-\\', \\'073\\', \\'732\\', \\'32 \\', \\'2 M\\', \\'s g\\', \\' ga\\', \\'gal\\', \\'all\\', \\'llo\\', \\'lop\\', \\'opr\\', \\'pro\\', \\'rov\\', \\'ovi\\', \\'vin\\', \\'inc\\', \\'nci\\', \\'cia\\', \\'ial\\', \\'076\\', \\'768\\', \\'87.\\', \\':12\\', \\'122\\', \\'222\\', \\'229\\', \\'29-\\', \\'9-1\\', \\'-13\\', \\'138\\', \\'388\\', \\'884\\', \\'84 \\', \\'s t\\', \\' tr\\', \\'tro\\', \\'oss\\', \\'ssu\\', \\'sul\\', \\'ulu\\', \\'GGN\\', \\'GNG\\', \\'NGT\\', \\'018\\', \\'183\\', \\'836\\', \\'362\\', \\'62.\\', \\'2.1\\', \\'124\\', \\'245\\', \\'450\\', \\'50-\\', \\'0-1\\', \\'139\\', \\'398\\', \\'985\\', \\'85 \\', \\'5 P\\', \\'Per\\', \\'ern\\', \\'rna\\', \\' vi\\', \\'vir\\', \\'iri\\', \\'dis\\', \\'262\\', \\'628\\', \\'288\\', \\'88.\\', \\'565\\', \\'654\\', \\'54-\\', \\'4-1\\', \\'172\\', \\'728\\', \\'282\\', \\'82 \\', \\'2 P\\', \\'a p\\', \\' pe\\', \\'per\\', \\'e\\\\nG\\', \\'_05\\', \\'054\\', \\'542\\', \\'424\\', \\'242\\', \\'42.\\', \\'144\\', \\'444\\', \\'447\\', \\'47-\\', \\'600\\', \\'003\\', \\'03 \\', \\'3 P\\', \\'can\\', \\'nal\\', \\'069\\', \\'690\\', \\'060\\', \\'60.\\', \\'564\\', \\'64 \\', \\'ise\\', \\'sep\\', \\'ept\\', \\'pta\\', \\'irg\\', \\'rga\\', \\'gat\\', \\'022\\', \\'228\\', \\'284\\', \\'846\\', \\'46.\\', \\':55\\', \\'595\\', \\'95-\\', \\'5-7\\', \\'-71\\', \\'717\\', \\'175\\', \\'75 \\', \\'5 L\\', \\' La\\', \\'Lat\\', \\'ter\\', \\'rnu\\', \\'nul\\', \\'ula\\', \\'la \\', \\' el\\', \\'lli\\', \\'lip\\', \\'ipt\\', \\'pti\\', \\'tic\\', \\'357\\', \\'572\\', \\'28.\\', \\'61 \\', \\'1 C\\', \\' Ce\\', \\'Cer\\', \\'ast\\', \\'sto\\', \\'tod\\', \\'ode\\', \\'der\\', \\'erm\\', \\'rma\\', \\'ma \\', \\'ule\\', \\'e i\\', \\'e C\\', \\'Ced\\', \\'du.\\', \\'u.1\\', \\'.11\\', \\'11.\\', \\'.16\\', \\'16.\\', \\'6.N\\', \\'.N0\\', \\'N01\\', \\'01.\\', \\'1.0\\', \\'.02\\', \\'22 \\', \\'2 m\\', \\'\\\\nT\\\\n\\', \\'050\\', \\'506\\', \\'683\\', \\'83.\\', \\':24\\', \\'249\\', \\'49-\\', \\'-18\\', \\'186\\', \\'865\\', \\'65 \\', \\'5 T\\', \\' Tr\\', \\'Tri\\', \\'ida\\', \\'dac\\', \\'acn\\', \\'cna\\', \\'359\\', \\'85.\\', \\'5.1\\', \\':75\\', \\'750\\', \\'509\\', \\'09-\\', \\'9-9\\', \\'-92\\', \\'921\\', \\'218\\', \\'18 \\', \\'8 D\\', \\' Do\\', \\'Don\\', \\'ona\\', \\'nax\\', \\'ax \\', \\'x t\\', \\'tru\\', \\'run\\', \\'unc\\', \\'ncu\\', \\'987\\', \\':74\\', \\'740\\', \\'409\\', \\'-91\\', \\'118\\', \\'x v\\', \\'vit\\', \\'tta\\', \\'tat\\', \\'_04\\', \\'046\\', \\'465\\', \\'651\\', \\'519\\', \\'19.\\', \\'554\\', \\'54 \\', \\'4 L\\', \\' Li\\', \\'Lim\\', \\'ime\\', \\'mec\\', \\'eco\\', \\'col\\', \\'a b\\', \\' ba\\', \\'bal\\', \\'alt\\', \\'lth\\', \\'thi\\', \\'hic\\', \\'024\\', \\'247\\', \\'473\\', \\'738\\', \\'38.\\', \\'755\\', \\'55 \\', \\'5 M\\', \\'Mya\\', \\'ya \\', \\'a a\\', \\' ar\\', \\'are\\', \\'ren\\', \\'ena\\', \\'nar\\', \\'227\\', \\'270\\', \\'709\\', \\'09.\\', \\':33\\', \\'331\\', \\'315\\', \\'15-\\', \\'5-4\\', \\'-49\\', \\'498\\', \\'5 A\\', \\'Arc\\', \\'rct\\', \\'a i\\', \\'isl\\', \\'sla\\', \\'and\\', \\'ndi\\', \\'dic\\', \\' po\\', \\'pop\\', \\'op-\\', \\'p-v\\', \\'-va\\', \\'ant\\', \\'nt \\', \\'t 2\\', \\' 27\\', \\'766\\', \\'663\\', \\'63 \\', \\'3 m\\', \\'464\\', \\'10.\\', \\'614\\', \\'14 \\', \\'4 C\\', \\' Co\\', \\'Cor\\', \\'orb\\', \\'rbi\\', \\'bic\\', \\'a f\\', \\' fl\\', \\'flu\\', \\'lum\\', \\'umi\\', \\'min\\', \\'ine\\', \\'nea\\', \\'038\\', \\'380\\', \\'806\\', \\'063\\', \\'63.\\', \\'608\\', \\'Dos\\', \\'osi\\', \\'sin\\', \\'a j\\', \\' ja\\', \\'jap\\', \\'apo\\', \\'pon\\', \\'848\\', \\'487\\', \\':21\\', \\'210\\', \\'109\\', \\'9-3\\', \\'-36\\', \\'367\\', \\'677\\', \\'77 \\', \\'Mer\\', \\'erc\\', \\'rce\\', \\'cen\\', \\' me\\', \\'mer\\', \\'031\\', \\'313\\', \\'133\\', \\'332\\', \\'32.\\', \\'142\\', \\'427\\', \\'271\\', \\'71-\\', \\'989\\', \\'89 \\', \\'9 R\\', \\' Ru\\', \\'Rud\\', \\'udi\\', \\'dit\\', \\'ita\\', \\'tap\\', \\'ape\\', \\'pes\\', \\'phi\\', \\'hil\\', \\'ipp\\', \\'ppi\\', \\'pin\\', \\'aru\\', \\'rum\\', \\'m m\\', \\'AGY\\', \\'GYT\\', \\'YTT\\', \\'GGK\\', \\'GKT\\', \\'KTT\\', \\'GTR\\', \\'TRT\\', \\'RTG\\', \\'GTY\\', \\'TYT\\', \\'TTY\\', \\'YTG\\', \\'TGY\\', \\'YTA\\', \\'GGR\\', \\'GRA\\', \\'RAT\\', \\'GAY\\', \\'AYA\\', \\'YAC\\', \\'TAY\\', \\'AYT\\', \\'YTC\\', \\'575\\', \\'757\\', \\'57.\\', \\'716\\', \\'16 \\', \\'6 R\\', \\'s d\\', \\'dec\\', \\'ecu\\', \\'uss\\', \\'sat\\', \\'034\\', \\'348\\', \\'845\\', \\'45.\\', \\'539\\', \\'39 \\', \\'9 E\\', \\' Ec\\', \\'Ech\\', \\'chy\\', \\'hyr\\', \\'yri\\', \\'ide\\', \\'del\\', \\'men\\', \\'enz\\', \\'nzi\\', \\'zie\\', \\'ies\\', \\'esi\\', \\'sii\\', \\'ii \\', \\'i i\\', \\'e S\\', \\' SB\\', \\'SB1\\', \\'B11\\', \\'11 \\', \\'1 m\\', \\'545\\', \\'45 \\', \\' Cu\\', \\'Cum\\', \\'umb\\', \\'mbe\\', \\'ber\\', \\'erl\\', \\'rla\\', \\'dia\\', \\' mo\\', \\'mon\\', \\'ono\\', \\'nod\\', \\'odo\\', \\'nta\\', \\'e H\\', \\' H3\\', \\'H30\\', \\'301\\', \\'10 \\', \\'_07\\', \\'079\\', \\'796\\', \\'969\\', \\'691\\', \\'91.\\', \\' Ma\\', \\'Mar\\', \\'arg\\', \\'gar\\', \\'rit\\', \\'iti\\', \\'a l\\', \\' la\\', \\'lae\\', \\'aev\\', \\'evi\\', \\'vis\\', \\'r 2\\', \\' 20\\', \\'20 \\', \\'0 -\\', \\' - \\', \\'- M\\', \\' MM\\', \\'MMt\\', \\'Mt-\\', \\'t-t\\', \\'-tc\\', \\'tc0\\', \\'c01\\', \\'01 \\', \\'043\\', \\'438\\', \\'383\\', \\'mar\\', \\'r B\\', \\' B1\\', \\'B15\\', \\'55G\\', \\'5G \\', \\'G m\\', \\'500\\', \\'005\\', \\'056\\', \\'56.\\', \\' Am\\', \\'Amb\\', \\'mbl\\', \\'ble\\', \\'lem\\', \\'ema\\', \\' BI\\', \\'BIV\\', \\'IV2\\', \\'V24\\', \\'244\\', \\'448\\', \\'8 v\\', \\'r 0\\', \\' 06\\', \\'61T\\', \\'1TS\\', \\'TS \\', \\'S m\\', \\'013\\', \\'136\\', \\'365\\', \\'658\\', \\'42 \\', \\'2 Q\\', \\' Qu\\', \\'Qua\\', \\'uad\\', \\'adr\\', \\'dru\\', \\'rul\\', \\'a q\\', \\' qu\\', \\'qua\\', \\'044\\', \\'441\\', \\'411\\', \\'111\\', \\'5 U\\', \\' Un\\', \\'Uni\\', \\'nio\\', \\'io \\', \\'o b\\', \\' bo\\', \\'bon\\', \\'one\\', \\'nel\\', \\'lii\\', \\'i v\\', \\'r M\\', \\' MC\\', \\'MC2\\', \\'C28\\', \\'28 \\', \\'8 m\\', \\'030\\', \\'300\\', \\'73.\\', \\' Po\\', \\'Pot\\', \\'oto\\', \\'tom\\', \\'omi\\', \\'mid\\', \\'da \\', \\' li\\', \\'lit\\', \\'tto\\', \\'tor\\', \\'ora\\', \\'ral\\', \\'e P\\', \\' PL\\', \\'PL7\\', \\'L70\\', \\'702\\', \\'02F\\', \\'2F \\', \\'F m\\', \\'062\\', \\'287\\', \\'877\\', \\'77.\\', \\':39\\', \\'986\\', \\'86-\\', \\'6-5\\', \\'-55\\', \\'552\\', \\'527\\', \\'7 L\\', \\'Lam\\', \\'ame\\', \\'mel\\', \\'lid\\', \\'den\\', \\'ns \\', \\'rgi\\', \\'gin\\', \\'r C\\', \\' CI\\', \\'CIF\\', \\'IFE\\', \\'FEF\\', \\'EFG\\', \\'FGB\\', \\'GB-\\', \\'B-L\\', \\'-LM\\', \\'LM1\\', \\'M1 \\', \\'037\\', \\'374\\', \\'743\\', \\'431\\', \\'143\\', \\'434\\', \\'48-\\', \\'158\\', \\'588\\', \\'889\\', \\'9 A\\', \\' Al\\', \\'Ala\\', \\'las\\', \\'asm\\', \\'smi\\', \\'a h\\', \\' he\\', \\'het\\', \\'ero\\', \\'rod\\', \\'280\\', \\':53\\', \\'531\\', \\'316\\', \\'16-\\', \\'6-6\\', \\'857\\', \\'57 \\', \\'7 A\\', \\' An\\', \\'Ano\\', \\' an\\', \\'nat\\', \\'e 1\\', \\' 10\\', \\'106\\', \\'6 h\\', \\' ha\\', \\'hap\\', \\'apl\\', \\'plo\\', \\'lot\\', \\'oty\\', \\'typ\\', \\'ype\\', \\'pe \\', \\'e F\\', \\' F \\', \\'036\\', \\'364\\', \\'648\\', \\'488\\', \\'530\\', \\'308\\', \\'08-\\', \\'8-6\\', \\'684\\', \\'849\\', \\'49 \\', \\' cy\\', \\'cyg\\', \\'ygn\\', \\'gne\\', \\'057\\', \\'571\\', \\'12.\\', \\' Ps\\', \\'Pse\\', \\'seu\\', \\'eud\\', \\'uda\\', \\'dan\\', \\'ano\\', \\'pla\\', \\'IV0\\', \\'V01\\', \\'86 \\', \\'6 v\\', \\'6 m\\', \\'366\\', \\'661\\', \\'61.\\', \\':2-\\', \\'2-1\\', \\'540\\', \\'0 P\\', \\' Py\\', \\'Pyg\\', \\'yga\\', \\'gan\\', \\'n g\\', \\' gr\\', \\'gra\\', \\'ran\\', \\'494\\', \\'1:4\\', \\':49\\', \\'946\\', \\'46-\\', \\'-64\\', \\'87 \\', \\'7 S\\', \\' Si\\', \\'Sin\\', \\'nan\\', \\'a w\\', \\' wo\\', \\'woo\\', \\'ood\\', \\'odi\\', \\'201\\', \\'14-\\', \\'4-p\\', \\'-ph\\', \\'phc\\', \\'hc-\\', \\'c-s\\', \\'-si\\', \\'si-\\', \\'i-w\\', \\'-wo\\', \\'wo-\\', \\'o-0\\', \\'-00\\', \\'310\\', \\'339\\', \\'39-\\', \\'9-6\\', \\'892\\', \\'92 \\', \\'2 U\\', \\'o p\\', \\' pi\\', \\'pic\\', \\'ict\\', \\'cto\\', \\'oru\\', \\'356\\', \\'568\\', \\'682\\', \\'82.\\', \\':29\\', \\'295\\', \\'954\\', \\'-44\\', \\'489\\', \\'9 G\\', \\' Gi\\', \\'Gib\\', \\'ibb\\', \\'bbu\\', \\'bul\\', \\'a u\\', \\' um\\', \\'mbi\\', \\'bil\\', \\'059\\', \\'594\\', \\'940\\', \\'40.\\', \\'335\\', \\'352\\', \\'52-\\', \\'2-4\\', \\'-48\\', \\'893\\', \\'93 \\', \\'3 H\\', \\' Ha\\', \\'Hal\\', \\'lio\\', \\'iot\\', \\'oti\\', \\'tis\\', \\'s r\\', \\' ru\\', \\'rub\\', \\'ubr\\', \\'bra\\', \\'318\\', \\'189\\', \\':27\\', \\'273\\', \\'735\\', \\'35-\\', \\'428\\', \\'2 C\\', \\' Cl\\', \\'Cli\\', \\'ith\\', \\'tho\\', \\'n r\\', \\' re\\', \\'ret\\', \\'rop\\', \\'opi\\', \\'ctu\\', \\' CL\\', \\'CL2\\', \\'L24\\', \\'4 m\\', \\'458\\', \\'586\\', \\'536\\', \\'36 \\', \\'6 P\\', \\'Pom\\', \\'oma\\', \\'ace\\', \\'cea\\', \\'040\\', \\'094\\', \\'6 B\\', \\' Bu\\', \\'Buc\\', \\'ucc\\', \\'cci\\', \\'cin\\', \\'inu\\', \\'num\\', \\'m u\\', \\' un\\', \\'und\\', \\'nda\\', \\'dat\\', \\'tum\\', \\'705\\', \\'577\\', \\'ota\\', \\'tam\\', \\'amo\\', \\'mop\\', \\'opy\\', \\'pyr\\', \\'yrg\\', \\'rgu\\', \\'gus\\', \\'s a\\', \\'nti\\', \\'tip\\', \\'ipo\\', \\'pod\\', \\'oda\\', \\'dar\\', \\'058\\', \\'582\\', \\'827\\', \\'27.\\', \\':59\\', \\'59-\\', \\'603\\', \\'3 A\\', \\' Ap\\', \\'Apl\\', \\'ply\\', \\'lys\\', \\'ysi\\', \\'607\\', \\'98.\\', \\':10\\', \\'047\\', \\'471\\', \\'-11\\', \\'119\\', \\'199\\', \\'997\\', \\'97 \\', \\'7 B\\', \\'Bul\\', \\'lin\\', \\' gl\\', \\'glo\\', \\'lob\\', \\'obo\\', \\'bos\\', \\'osu\\', \\'sus\\', \\'BuG\\', \\'uGe\\', \\'Ge \\', \\'795\\', \\'95.\\', \\'19-\\', \\'-12\\', \\'120\\', \\'204\\', \\'045\\', \\'nca\\', \\'BuT\\', \\'uT \\', \\'T m\\', \\'088\\', \\'885\\', \\'852\\', \\'521\\', \\'21.\\', \\':58\\', \\'584\\', \\'843\\', \\'43-\\', \\'3-7\\', \\'-73\\', \\'355\\', \\'5 F\\', \\' Fe\\', \\'Fer\\', \\'err\\', \\'rri\\', \\'ris\\', \\' fr\\', \\'fra\\', \\'rag\\', \\'gil\\', \\'r F\\', \\'Fe2\\', \\'e2-\\', \\'2-e\\', \\'-e4\\', \\'e41\\', \\'41d\\', \\'1d4\\', \\'d4p\\', \\'4p2\\', \\'p2 \\', \\'543\\', \\'439\\', \\'39.\\', \\'474\\', \\'74-\\', \\'200\\', \\'00 \\', \\'0 B\\', \\' Bi\\', \\'Bio\\', \\'iom\\', \\'mph\\', \\'hal\\', \\'ala\\', \\'lar\\', \\'gla\\', \\'lab\\', \\'abr\\', \\'805\\', \\'59.\\', \\'041\\', \\'416\\', \\'6-1\\', \\'196\\', \\'963\\', \\'3 B\\', \\' pf\\', \\'pfe\\', \\'fei\\', \\'eif\\', \\'iff\\', \\'023\\', \\'232\\', \\'325\\', \\'253\\', \\'53.\\', \\' Ph\\', \\'Phy\\', \\'hys\\', \\'yse\\', \\'sel\\', \\' ac\\', \\'acu\\', \\'cut\\', \\'uta\\', \\'e A\\', \\' A \\', \\'90.\\', \\'8 S\\', \\' Su\\', \\'Suc\\', \\'put\\', \\'utr\\', \\'065\\', \\'657\\', \\'573\\', \\'731\\', \\'7 D\\', \\' Di\\', \\'Dis\\', \\'isc\\', \\'scu\\', \\'ers\\', \\'rsp\\', \\'spe\\', \\'tiv\\', \\'ivu\\', \\'vus\\', \\'r U\\', \\' UC\\', \\'UC0\\', \\'C06\\', \\'729\\', \\'54.\\', \\'big\\', \\'igo\\', \\'gol\\', \\'oli\\', \\'lim\\', \\'max\\', \\'val\\', \\'ale\\', \\'len\\', \\'ent\\', \\'tia\\', \\'47.\\', \\'30 \\', \\'0 H\\', \\' He\\', \\'Hel\\', \\'eli\\', \\'lix\\', \\'ix \\', \\'x p\\', \\'pom\\', \\'mat\\', \\'r R\\', \\' RM\\', \\'RMN\\', \\'MNH\\', \\'NH.\\', \\'H.5\\', \\'.50\\', \\'067\\', \\'670\\', \\'707\\', \\'07.\\', \\'.1 \\', \\'715\\', \\'15.\\', \\'3 N\\', \\' Na\\', \\'Nau\\', \\'aut\\', \\'uti\\', \\'mpi\\', \\'pil\\', \\'liu\\', \\'ius\\', \\'128\\', \\'840\\', \\'1:8\\', \\':88\\', \\'851\\', \\'103\\', \\'83 \\', \\'3 D\\', \\'Dor\\', \\'ory\\', \\'ryt\\', \\'yte\\', \\'teu\\', \\'eut\\', \\'uth\\', \\'his\\', \\'s o\\', \\' op\\', \\'opa\\', \\'pal\\', \\'les\\', \\'esc\\', \\'sce\\', \\'002\\', \\'025\\', \\'250\\', \\'507\\', \\':87\\', \\'878\\', \\'785\\', \\'85-\\', \\'317\\', \\' Lo\\', \\'Lol\\', \\'lig\\', \\'go \\', \\' bl\\', \\'lee\\', \\'eek\\', \\'eke\\', \\'ker\\', \\'078\\', \\'789\\', \\'894\\', \\'94.\\', \\'580\\', \\'733\\', \\'337\\', \\'37 \\', \\' Se\\', \\'Sep\\', \\'epi\\', \\'pio\\', \\'ote\\', \\'ess\\', \\'son\\', \\'028\\', \\'281\\', \\'818\\', \\'89.\\', \\'896\\', \\'96-\\', \\'042\\', \\'8 U\\', \\' Ur\\', \\'Uro\\', \\'rot\\', \\' ch\\', \\'hin\\', \\'nen\\', \\'900\\', \\'008\\', \\'0 U\\', \\' du\\', \\'duv\\', \\'uva\\', \\'vau\\', \\'auc\\', \\'uce\\', \\'cel\\', \\'017\\', \\'177\\', \\'774\\', \\'746\\', \\'844\\', \\'44-\\', \\'376\\', \\'76 \\', \\'6 U\\', \\'s e\\', \\'082\\', \\'823\\', \\'26.\\', \\'65-\\', \\'397\\', \\'Lio\\', \\'ioc\\', \\'ocr\\', \\'cra\\', \\'anc\\', \\'nch\\', \\'hia\\', \\'rei\\', \\'ein\\', \\'inh\\', \\'nha\\', \\'ard\\', \\'rdt\\', \\'dti\\', \\'tii\\', \\' CE\\', \\'CEP\\', \\'EP2\\', \\'P21\\', \\'214\\', \\'233\\', \\':89\\', \\'898\\', \\'89-\\', \\'052\\', \\'21 \\', \\'1 A\\', \\' Ab\\', \\'Abr\\', \\'mor\\', \\'ori\\', \\'isi\\', \\'EP3\\', \\'P32\\', \\'323\\', \\'23 \\', \\'150\\', \\'098\\', \\'630\\', \\'0 W\\', \\' Wa\\', \\'Wat\\', \\'tas\\', \\'ase\\', \\'a s\\', \\' sc\\', \\'sci\\', \\'int\\', \\'ill\\', \\'ans\\', \\'918\\', \\'187\\', \\' Hi\\', \\'His\\', \\'ist\\', \\'sti\\', \\'tio\\', \\'s b\\', \\'onn\\', \\'nne\\', \\'EP0\\', \\'P01\\', \\'019\\', \\'19 \\', \\'9 m\\', \\'269\\', \\'908\\', \\'08.\\', \\'901\\', \\'8 I\\', \\' Il\\', \\'Ill\\', \\'lex\\', \\'ex \\', \\'x a\\', \\'rge\\', \\'097\\', \\'973\\', \\'734\\', \\':84\\', \\'454\\', \\'4-9\\', \\'-99\\', \\'998\\', \\'6 D\\', \\'sid\\', \\'421\\', \\'1-2\\', \\'-29\\', \\'953\\', \\'53 \\', \\'3 S\\', \\' St\\', \\'Sth\\', \\'the\\', \\'hen\\', \\'not\\', \\' ou\\', \\'oua\\', \\'ual\\', \\'nie\\', \\'ien\\', \\'583\\', \\'830\\', \\'404\\', \\'169\\', \\'693\\', \\'936\\', \\'6 T\\', \\' Th\\', \\'Thy\\', \\'ysa\\', \\'san\\', \\' rh\\', \\'rho\\', \\'hom\\', \\'omb\\', \\'mbu\\', \\'bus\\', \\'224\\', \\'246\\', \\':20\\', \\'206\\', \\'5-3\\', \\'-35\\', \\'597\\', \\'pia\\', \\' ap\\', \\'apa\\', \\'pam\\', \\'ele\\', \\'leg\\', \\'ega\\', \\'e T\\', \\' TO\\', \\'TON\\', \\'ON0\\', \\'N00\\', \\'004\\', \\'04 \\', \\'205\\', \\'58-\\', \\'8-3\\', \\'590\\', \\'90 \\', \\'0 S\\', \\'a o\\', \\' of\\', \\'ffi\\', \\'fic\\', \\'ici\\', \\'188\\', \\' or\\', \\'ign\\', \\'gny\\', \\'nya\\', \\'yan\\', \\'P02\\', \\'25 \\', \\'5 m\\', \\'021\\', \\'211\\', \\'114\\', \\'146\\', \\'69-\\', \\'360\\', \\'601\\', \\'226\\', \\'61-\\', \\'1-3\\', \\'593\\', \\'pie\\', \\'iel\\', \\' in\\', \\'ner\\', \\'rmi\\', \\'48.\\', \\'241\\', \\'12-\\', \\'2-3\\', \\'-39\\', \\'394\\', \\'944\\', \\'44 \\', \\'4 S\\', \\'iet\\', \\'ett\\', \\' ob\\', \\'obs\\', \\'bsc\\', \\'cur\\', \\'r I\\', \\' IC\\', \\'ICM\\', \\'CM:\\', \\'M:C\\', \\':C0\\', \\'C00\\', \\'642\\', \\'11-\\', \\'43 \\', \\'3 R\\', \\' Ro\\', \\'Ros\\', \\'acr\\', \\'cro\\', \\'oso\\', \\'som\\', \\'032\\', \\'329\\', \\'29 \\', \\'346\\', \\'468\\', \\'84-\\', \\'216\\', \\' Sp\\', \\'Spi\\', \\'pir\\', \\'iru\\', \\' sp\\', \\'spi\\', \\'r N\\', \\' NM\\', \\'NMV\\', \\'MV:\\', \\'V:Z\\', \\':Z7\\', \\'Z79\\', \\'46 \\', \\'699\\', \\'999\\', \\'996\\', \\'96.\\', \\'gon\\', \\'nau\\', \\'o i\\', \\' A2\\', \\'A20\\', \\'108\\', \\'CMC\\', \\'MC0\\', \\'31 \\', \\'363\\', \\'635\\', \\'354\\', \\' hi\\', \\'866\\', \\':25\\', \\'259\\', \\'93-\\', \\'3-4\\', \\'125\\', \\'5 J\\', \\' Ja\\', \\'Jap\\', \\'pet\\', \\' di\\', \\'iap\\', \\'aph\\', \\'97.\\', \\'3 E\\', \\' El\\', \\'Ele\\', \\'led\\', \\'edo\\', \\'ne \\', \\'e c\\', \\' ci\\', \\'cir\\', \\'irr\\', \\'rrh\\', \\'hos\\', \\'osa\\', \\'09 \\', \\'563\\', \\'638\\', \\'385\\', \\'256\\', \\'569\\', \\'9-4\\', \\'101\\', \\'1 E\\', \\' En\\', \\'Ent\\', \\'roc\\', \\'top\\', \\'opu\\', \\'pus\\', \\' do\\', \\'dof\\', \\'ofl\\', \\'fle\\', \\'ni \\', \\'029\\', \\'297\\', \\'970\\', \\'02.\\', \\'257\\', \\'75-\\', \\'07 \\', \\'Amp\\', \\' ae\\', \\'aeg\\', \\'egi\\', \\'254\\', \\'42-\\', \\'-40\\', \\'407\\', \\'074\\', \\'74 \\', \\'4 O\\', \\' Oc\\', \\'Oct\\', \\' oc\\', \\'oce\\', \\'972\\', \\'23.\\', \\'255\\', \\'557\\', \\'57-\\', \\'408\\', \\'089\\', \\'9 O\\', \\' bi\\', \\'bim\\', \\'ulo\\', \\'loi\\', \\'oid\\', \\'des\\', \\'984\\', \\'847\\', \\'086\\', \\'cya\\', \\'ane\\', \\'e X\\', \\' XX\\', \\'XX \\', \\'X m\\', \\'440\\', \\'66-\\', \\'6-4\\', \\'8 O\\', \\'mim\\', \\'imu\\', \\'mus\\', \\'353\\', \\'64-\\', \\'096\\', \\'96 \\', \\' vu\\', \\'vul\\', \\'ulg\\', \\'lga\\', \\'919\\', \\'193\\', \\' Pt\\', \\'Pte\\', \\' te\\', \\'tet\\', \\'tra\\', \\'aci\\', \\'rhu\\', \\'hus\\', \\'EP1\\', \\'P11\\', \\'968\\', \\'558\\', \\'8-4\\', \\'090\\', \\'0 V\\', \\' Va\\', \\'Vam\\', \\'amp\\', \\'mpy\\', \\'yro\\', \\'inf\\', \\'nfe\\', \\'167\\', \\'672\\', \\'722\\', \\'22.\\', \\':13\\', \\'137\\', \\'377\\', \\'77-\\', \\'7-2\\', \\'292\\', \\'926\\', \\'26 \\', \\'6 F\\', \\' Fl\\', \\'Flu\\', \\'ust\\', \\' fo\\', \\'fol\\', \\'lia\\', \\'iac\\', \\'74.\\', \\'130\\', \\'307\\', \\'72-\\', \\'-14\\', \\'460\\', \\'606\\', \\'6 H\\', \\'Hed\\', \\'edi\\', \\'e d\\', \\'div\\', \\'ive\\', \\'ver\\', \\'rsi\\', \\'sic\\', \\'ico\\', \\'olo\\', \\'lor\\', \\'or \\', \\'r m\\', \\'637\\', \\'379\\', \\'79.\\', \\'3 U\\', \\'Ure\\', \\'rec\\', \\'ech\\', \\'cau\\', \\'aup\\', \\'upo\\', \\'po \\', \\'o m\\', \\'673\\', \\'0 L\\', \\' Lu\\', \\'Lum\\', \\'mbr\\', \\'bri\\', \\'ric\\', \\'rre\\', \\'res\\', \\'est\\', \\'ACN\\', \\'CNN\\', \\'NNN\\', \\'NNT\\', \\'NTT\\', \\'066\\', \\'664\\', \\'400\\', \\'00.\\', \\'0 A\\', \\'Apo\\', \\'por\\', \\'orr\\', \\'dea\\', \\'igi\\', \\'ino\\', \\'nos\\', \\'e 4\\', \\' 42\\', \\'420\\', \\'20R\\', \\'0Ra\\', \\'Ra \\', \\'652\\', \\'212\\', \\'0 E\\', \\' Ei\\', \\'Eis\\', \\'dre\\', \\'ei \\', \\'213\\', \\'13.\\', \\' fe\\', \\'fet\\', \\'eti\\', \\'tid\\', \\'534\\', \\'34 \\', \\'4 B\\', \\' Ba\\', \\'Bar\\', \\'arb\\', \\'rbr\\', \\'bro\\', \\'ron\\', \\' we\\', \\'web\\', \\'ebe\\', \\' CS\\', \\'CSU\\', \\'SU-\\', \\'U-M\\', \\'-MG\\', \\'MG-\\', \\'G-1\\', \\'-1 \\', \\'692\\', \\'920\\', \\'203\\', \\':98\\', \\'980\\', \\'804\\', \\'113\\', \\'134\\', \\'340\\', \\'0 T\\', \\'The\\', \\'rom\\', \\'omy\\', \\'myz\\', \\'yzo\\', \\'zon\\', \\'n t\\', \\'3 L\\', \\'Lin\\', \\'neu\\', \\'eus\\', \\'132\\', \\'328\\', \\':78\\', \\'784\\', \\'45-\\', \\'5-9\\', \\'-94\\', \\'942\\', \\'422\\', \\'Cae\\', \\'aen\\', \\'nor\\', \\'orh\\', \\'rha\\', \\'hab\\', \\'abd\\', \\'bdi\\', \\' Rh\\', \\'Rhi\\', \\'hiz\\', \\'izo\\', \\'zog\\', \\'ogl\\', \\'gly\\', \\'lyp\\', \\'yph\\', \\'phu\\', \\'rob\\', \\'obi\\', \\'bin\\', \\'710\\', \\'4 A\\', \\'Art\\', \\'rte\\', \\'tem\\', \\'mia\\', \\' sa\\', \\'sal\\', \\'686\\', \\'665\\', \\'65.\\', \\' ur\\', \\'urm\\', \\' mt\\', \\'mtA\\', \\'tAr\\', \\'rt_\\', \\'t_1\\', \\'_1 \\', \\'503\\', \\':11\\', \\'147\\', \\'73-\\', \\'3-1\\', \\'6 E\\', \\' Eu\\', \\'Eub\\', \\'hip\\', \\'ipu\\', \\'gru\\', \\'ubi\\', \\'bii\\', \\'e D\\', \\' DM\\', \\'DM1\\', \\'M11\\', \\'704\\', \\'04.\\', \\'Str\\', \\'rep\\', \\'cep\\', \\'eph\\', \\'alu\\', \\'s s\\', \\' si\\', \\'sir\\', \\'ind\\', \\'ndh\\', \\'dho\\', \\'hor\\', \\'nae\\', \\'ae \\', \\'425\\', \\'345\\', \\'5-2\\', \\'-28\\', \\'875\\', \\'a k\\', \\' ku\\', \\'kug\\', \\'uge\\', \\'enu\\', \\'uma\\', \\'mae\\', \\'815\\', \\'52.\\', \\'34-\\', \\'4-2\\', \\'296\\', \\'967\\', \\' Da\\', \\'Dap\\', \\'phn\\', \\'hni\\', \\'car\\', \\'914\\', \\'14.\\', \\'13-\\', \\'3-2\\', \\'9 D\\', \\'agn\\', \\'gna\\', \\'084\\', \\'44.\\', \\'97-\\', \\'293\\', \\'934\\', \\'4 D\\', \\'pul\\', \\'x m\\', \\'747\\', \\'18-\\', \\'8-2\\', \\'285\\', \\'Sim\\', \\'imo\\', \\'moc\\', \\'ser\\', \\'rru\\', \\'596\\', \\'694\\', \\'696\\', \\'223\\', \\'231\\', \\'1 D\\', \\'Dia\\', \\' ex\\', \\'exc\\', \\'xci\\', \\'cis\\', \\'isu\\', \\'sum\\', \\'m c\\', \\' cl\\', \\'clo\\', \\'lon\\', \\' 1 \\', \\'446\\', \\'88-\\', \\'924\\', \\' Le\\', \\'Lep\\', \\'pid\\', \\'idu\\', \\'dur\\', \\'uru\\', \\'rus\\', \\'arc\\', \\'e L\\', \\'Lar\\', \\'rt-\\', \\'t-F\\', \\'-F3\\', \\'F3 \\', \\'478\\', \\'781\\', \\'81.\\', \\'373\\', \\'290\\', \\'909\\', \\'9 T\\', \\'ps \\', \\'riu\\', \\'291\\', \\'8 T\\', \\' lo\\', \\'ong\\', \\'ngi\\', \\'gic\\', \\'aud\\', \\'148\\', \\'4-3\\', \\'-30\\', \\'9 P\\', \\'Pol\\', \\'oll\\', \\'cip\\', \\'ipe\\', \\'pol\\', \\'oly\\', \\'lym\\', \\'yme\\', \\'eru\\', \\'452\\', \\'525\\', \\'25.\\', \\'550\\', \\'50 \\', \\'hib\\', \\'iba\\', \\' am\\', \\'itr\\', \\'ite\\', \\'669\\', \\'Eur\\', \\'ury\\', \\'emo\\', \\' af\\', \\'aff\\', \\'fin\\', \\'567\\', \\'676\\', \\'769\\', \\'69.\\', \\':82\\', \\'829\\', \\'91-\\', \\'1-9\\', \\'-98\\', \\'982\\', \\'9 L\\', \\'epe\\', \\'peo\\', \\'eop\\', \\'oph\\', \\'pht\\', \\'hth\\', \\'hei\\', \\'eir\\', \\'alm\\', \\'lmo\\', \\'860\\', \\'6 G\\', \\' Go\\', \\'Gon\\', \\'act\\', \\'cty\\', \\'tyl\\', \\'yla\\', \\'ceu\\', \\'s f\\', \\' fa\\', \\'fal\\', \\'alc\\', \\'lca\\', \\'349\\', \\'493\\', \\'937\\', \\'37.\\', \\'4 G\\', \\' Ga\\', \\'Gam\\', \\'amm\\', \\'mma\\', \\'fos\\', \\'sar\\', \\'748\\', \\'481\\', \\'3 G\\', \\'roe\\', \\'oes\\', \\'ese\\', \\'403\\', \\'828\\', \\'28-\\', \\'8-7\\', \\'736\\', \\'4 H\\', \\' Hy\\', \\'Hya\\', \\'yal\\', \\'lel\\', \\' az\\', \\'azt\\', \\'zte\\', \\'tec\\', \\'eca\\', \\'123\\', \\'32-\\', \\'2-2\\', \\'-27\\', \\'770\\', \\'70 \\', \\'Eup\\', \\'uph\\', \\'hau\\', \\'aus\\', \\'usi\\', \\' su\\', \\'sup\\', \\'upe\\', \\'erb\\', \\'rba\\', \\'ba \\', \\'60-\\', \\'0-2\\', \\'299\\', \\'8 L\\', \\'Lit\\', \\'pen\\', \\'aeu\\', \\'sty\\', \\'yli\\', \\'lir\\', \\'iro\\', \\'701\\', \\'463\\', \\'ars\\', \\'rsu\\', \\'s j\\', \\'679\\', \\'4 F\\', \\'Fen\\', \\'enn\\', \\'760\\', \\' Pa\\', \\'Par\\', \\'aty\\', \\'tya\\', \\' au\\', \\'lie\\', \\'rai\\', \\'ain\\', \\'in \\', \\'n A\\', \\' AP\\', \\'APR\\', \\'PR1\\', \\'R12\\', \\'020\\', \\'20.\\', \\' Ho\\', \\'Hom\\', \\'gam\\', \\'560\\', \\'537\\', \\'7 H\\', \\'033\\', \\'350\\', \\'Pac\\', \\'cif\\', \\'ifa\\', \\'fas\\', \\'sta\\', \\'tac\\', \\'niu\\', \\'usc\\', \\' AU\\', \\'AUG\\', \\'UG2\\', \\'G2 \\', \\'504\\', \\'535\\', \\'35 \\', \\' Au\\', \\'Aus\\', \\'opo\\', \\'pot\\', \\'mob\\', \\'biu\\', \\' to\\', \\'tiu\\', \\'m i\\', \\' F1\\', \\'F11\\', \\' Pr\\', \\'Pro\\', \\'oca\\', \\'cam\\', \\'amb\\', \\'mba\\', \\'bar\\', \\'cla\\', \\'ark\\', \\'rki\\', \\'kii\\', \\'286\\', \\'862\\', \\'627\\', \\'4 P\\', \\'Pan\\', \\' ve\\', \\'hod\\', \\'amt\\', \\'mts\\', \\'tsc\\', \\'sch\\', \\'hat\\', \\'091\\', \\'Bir\\', \\'atr\\', \\'ro \\', \\' TN\\', \\'TN1\\', \\'N16\\', \\'07D\\', \\'7D2\\', \\'D20\\', \\'202\\', \\'962\\', \\'700\\', \\'00-\\', \\'239\\', \\'9 C\\', \\'Can\\', \\'nce\\', \\'cer\\', \\'r p\\', \\'pag\\', \\'agu\\', \\'gur\\', \\'695\\', \\' Ch\\', \\'Cha\\', \\'ary\\', \\'ryb\\', \\'ybd\\', \\'Por\\', \\'ort\\', \\'rtu\\', \\'unu\\', \\'itu\\', \\'tub\\', \\'ube\\', \\'rcu\\', \\'643\\', \\'419\\', \\'9-2\\', \\'952\\', \\'52 \\', \\'2 F\\', \\' Fo\\', \\'Fol\\', \\'ols\\', \\'lso\\', \\'did\\', \\'n D\\', \\' DK\\', \\'DK \\', \\'K v\\', \\' FC\\', \\'FCD\\', \\'CDK\\', \\'K m\\', \\'TCM\\', \\'CMG\\', \\'MGG\\', \\'283\\', \\':95\\', \\'541\\', \\'41-\\', \\'110\\', \\' Or\\', \\'Orc\\', \\'rch\\', \\'hes\\', \\'nct\\', \\'cta\\', \\'744\\', \\'445\\', \\'116\\', \\'pis\\', \\'ism\\', \\'sma\\', \\'sac\\', \\'cch\\', \\'712\\', \\'433\\', \\'33-\\', \\'68 \\', \\'Loc\\', \\'ocu\\', \\'mig\\', \\'igr\\', \\'ato\\', \\' Ex\\', \\'Ext\\', \\'xta\\', \\'tos\\', \\' ti\\', \\'iar\\', \\' Be\\', \\'Bem\\', \\' ta\\', \\'tab\\', \\'aba\\', \\'bac\\', \\'ci \\', \\'011\\', \\'Acy\\', \\'cyr\\', \\'yrt\\', \\'rth\\', \\'sip\\', \\'iph\\', \\'pho\\', \\'55.\\', \\'140\\', \\'406\\', \\'06-\\', \\'6-2\\', \\'2 N\\', \\' Ne\\', \\'Nez\\', \\'eza\\', \\'zar\\', \\'351\\', \\'515\\', \\'129\\', \\'298\\', \\'834\\', \\' Ae\\', \\'Aed\\', \\'ede\\', \\'egy\\', \\'gyp\\', \\'ti \\', \\'i s\\', \\'n L\\', \\' LV\\', \\'LVP\\', \\'VP_\\', \\'P_A\\', \\'_AG\\', \\'AGW\\', \\'GWG\\', \\'WG \\', \\'Cul\\', \\'pip\\', \\'ipi\\', \\'961\\', \\'7-3\\', \\'Plo\\', \\'lod\\', \\'erp\\', \\'pun\\', \\'235\\', \\'831\\', \\'31-\\', \\'336\\', \\'361\\', \\' Bo\\', \\'Bom\\', \\'mby\\', \\'byx\\', \\'yx \\', \\'102\\', \\'266\\', \\'483\\', \\'83-\\', \\'3-3\\', \\'13 \\', \\'3 M\\', \\'Man\\', \\'ndu\\', \\'duc\\', \\'sex\\', \\'ext\\', \\'278\\', \\'783\\', \\'461\\', \\'991\\', \\'91 \\', \\'Spo\\', \\'dop\\', \\'opt\\', \\'pte\\', \\'fru\\', \\'rug\\', \\'ugi\\', \\'gip\\', \\'erd\\', \\'rda\\', \\'68.\\', \\'994\\', \\'94 \\', \\'cov\\', \\'ove\\', \\'rpa\\', \\'pa \\', \\'arm\\', \\'ige\\', \\'ger\\', \\'505\\', \\'528\\', \\'nep\\', \\'pit\\', \\'hem\\', \\' hu\\', \\'hum\\', \\'mil\\', \\'e v\\', \\'r L\\', \\' LH\\', \\'LH2\\', \\'H20\\', \\'510\\', \\'5 O\\', \\' Op\\', \\'Oph\\', \\'hiu\\', \\'iur\\', \\' al\\', \\'alb\\', \\'lbi\\', \\'bid\\', \\'274\\', \\':31\\', \\'178\\', \\'78-\\', \\'1 P\\', \\' Pi\\', \\'Pis\\', \\'isa\\', \\'sas\\', \\'r o\\', \\'chr\\', \\'hra\\', \\' M0\\', \\'M0D\\', \\'0D0\\', \\'D05\\', \\'055\\', \\'518\\', \\'89C\\', \\'9C \\', \\'C m\\', \\'077\\', \\'778\\', \\'788\\', \\':46\\', \\'5-6\\', \\'-62\\', \\'621\\', \\'217\\', \\'Aca\\', \\'nth\\', \\'has\\', \\':48\\', \\'812\\', \\'2-6\\', \\'-63\\', \\'ore\\', \\'eas\\', \\'r n\\', \\'dos\\', \\'r H\\', \\' HS\\', \\'HS0\\', \\'S00\\', \\'053\\', \\'Cro\\', \\'pap\\', \\'app\\', \\'ppo\\', \\'pos\\', \\'832\\', \\'2-7\\', \\'5 S\\', \\'Ste\\', \\'ere\\', \\'s n\\', \\' ne\\', \\'eum\\', \\'may\\', \\'aye\\', \\'yer\\', \\'417\\', \\'585\\', \\'1-7\\', \\'-74\\', \\'Mes\\', \\'eso\\', \\'soc\\', \\'ntr\\', \\'otu\\', \\'sca\\', \\'099\\', \\'405\\', \\'ngy\\', \\'gyl\\', \\'ylo\\', \\'loc\\', \\' dr\\', \\'dro\\', \\'oeb\\', \\'eba\\', \\'hie\\', \\'941\\', \\'6-7\\', \\'739\\', \\'99 \\', \\'9 S\\', \\'dus\\', \\'453\\', \\':57\\', \\'338\\', \\'38 \\', \\'27-\\', \\'7-7\\', \\'80 \\', \\' Ly\\', \\'Lyt\\', \\'rie\\', \\'ieg\\', \\' Lv\\', \\'Lv4\\', \\'v4 \\', \\'157\\', \\'72.\\', \\'838\\', \\'38-\\', \\'391\\', \\'liv\\', \\'ivi\\', \\'vid\\', \\'237\\', \\'70.\\', \\'40-\\', \\'0-7\\', \\'393\\', \\'Lox\\', \\'oxe\\', \\'xec\\', \\'lbu\\', \\'881\\', \\'549\\', \\'2 E\\', \\'rdi\\', \\'cor\\', \\'ord\\', \\'Hol\\', \\'oth\\', \\'thu\\', \\'hur\\', \\'uri\\', \\'cab\\', \\'083\\', \\'8 B\\', \\'ios\\', \\'flo\\', \\'dae\\', \\'469\\', \\':34\\', \\'344\\', \\'442\\', \\'2-5\\', \\'-50\\', \\'501\\', \\'6 A\\', \\' As\\', \\'Asc\\', \\'cid\\', \\'die\\', \\' as\\', \\'asp\\', \\'rsa\\', \\'al \\', \\'l g\\', \\'179\\', \\'792\\', \\'272\\', \\' Ci\\', \\'Cio\\', \\'s B\\', \\' B \\', \\'B C\\', \\' CG\\', \\'CG-\\', \\'G-2\\', \\'-20\\', \\'Bot\\', \\'otr\\', \\'try\\', \\'ryl\\', \\'yll\\', \\'vio\\', \\'iol\\', \\'135\\', \\':35\\', \\'8-5\\', \\'Sty\\', \\'tye\\', \\'yel\\', \\'639\\', \\'Myx\\', \\'yxi\\', \\'xin\\', \\'glu\\', \\'lut\\', \\'Geo\\', \\'eot\\', \\'930\\', \\':70\\', \\'703\\', \\'37-\\', \\'7-8\\', \\'-85\\', \\'858\\', \\'587\\', \\' Mo\\', \\'Mor\\', \\'dax\\', \\'l D\\', \\' DN\\', \\'DNA\\', \\'NA,\\', \\'A, \\', \\'162\\', \\'626\\', \\'1:6\\', \\':66\\', \\'610\\', \\'10-\\', \\'0-8\\', \\'-81\\', \\'816\\', \\'Pet\\', \\'555\\', \\'7 I\\', \\' Ic\\', \\'Ich\\', \\'cht\\', \\'thy\\', \\'hyo\\', \\'yom\\', \\'n f\\', \\'sor\\', \\'342\\', \\'429\\', \\':65\\', \\'589\\', \\'9-8\\', \\'814\\', \\'5 I\\', \\'gag\\', \\'gei\\', \\'902\\', \\'343\\', \\'3-6\\', \\'nto\\', \\'osp\\', \\'sph\\', \\'phe\\', \\'mpe\\', \\'ppe\\', \\'end\\', \\'dix\\', \\'2 L\\', \\'Let\\', \\'eth\\', \\'n c\\', \\'cum\\', \\'917\\', \\'aep\\', \\'epy\\', \\'pyp\\', \\'415\\', \\'luv\\', \\'uvi\\', \\'via\\', \\'iat\\', \\':54\\', \\'24-\\', \\'-69\\', \\'698\\', \\'983\\', \\'Cal\\', \\'rhi\\', \\'chu\\', \\'cap\\', \\'456\\', \\'56-\\', \\'-70\\', \\'Chi\\', \\'him\\', \\'aer\\', \\'ons\\', \\'nst\\', \\'544\\', \\'4-7\\', \\' fu\\', \\'ful\\', \\'ulv\\', \\'lva\\', \\'va \\', \\':28\\', \\'883\\', \\'2 R\\', \\'pac\\', \\'ifi\\', \\'745\\', \\'546\\', \\'Hem\\', \\'scy\\', \\'cyl\\', \\'m o\\', \\'0 C\\', \\'ilo\\', \\'los\\', \\'m p\\', \\'gio\\', \\'948\\', \\'480\\', \\'490\\', \\'90-\\', \\'teg\\', \\'ego\\', \\'gos\\', \\'asc\\', \\'455\\', \\'547\\', \\'79-\\', \\'9-7\\', \\'5 R\\', \\'nco\\', \\'cod\\', \\' ty\\', \\'ypu\\', \\'475\\', \\'1 G\\', \\'Gin\\', \\'ing\\', \\'ngl\\', \\'ymo\\', \\'mos\\', \\'rra\\', \\'049\\', \\'988\\', \\'Gal\\', \\'leu\\', \\'omu\\', \\'DM4\\', \\'M43\\', \\'CTY\\', \\'TYC\\', \\'YCA\\', \\'195\\', \\'950\\', \\'418\\', \\' Sc\\', \\'Scy\\', \\'ior\\', \\'275\\', \\'751\\', \\'51.\\', \\'476\\', \\'76-\\', \\'r v\\', \\' US\\', \\'USN\\', \\'SNM\\', \\'NM:\\', \\'M:F\\', \\':FI\\', \\'FIS\\', \\'ISH\\', \\'SH:\\', \\'H:4\\', \\':45\\', \\'790\\', \\'890\\', \\' Mu\\', \\'Mus\\', \\'elu\\', \\'man\\', \\'naz\\', \\'azo\\', \\'zo \\', \\'396\\', \\'629\\', \\' mu\\', \\'462\\', \\'1 T\\', \\'iak\\', \\'aki\\', \\'kis\\', \\'meg\\', \\'alo\\', \\'775\\', \\'758\\', \\'62-\\', \\'sem\\', \\'mif\\', \\'437\\', \\'55-\\', \\'leo\\', \\'eor\\', \\'r G\\', \\' GA\\', \\'AG_\\', \\'G_O\\', \\'_OL\\', \\'OLH\\', \\'LHA\\', \\'HAO\\', \\'AO \\', \\'O O\\', \\' OB\\', \\'OBS\\', \\'BS2\\', \\'S2 \\', \\'459\\', \\'5 H\\', \\'pan\\', \\'240\\', \\'Car\\', \\'arh\\', \\'472\\', \\'6 C\\', \\'ICS\\', \\'CST\\', \\'ST:\\', \\'T:0\\', \\':02\\', \\'208\\', \\'238\\', \\'8 C\\', \\'bly\\', \\'lyr\\', \\'yrh\\', \\'rhy\\', \\'hyn\\', \\'ync\\', \\'os \\', \\'085\\', \\'859\\', \\'971\\', \\'71 \\', \\'752\\', \\' br\\', \\'hyu\\', \\'yur\\', \\'r S\\', \\' SN\\', \\'SNU\\', \\'NU-\\', \\'-MO\\', \\'MO-\\', \\'O-0\\', \\'081\\', \\'bre\\', \\'rev\\', \\'vip\\', \\'inn\\', \\'nna\\', \\'225\\', \\'lci\\', \\'orm\\', \\'522\\', \\'euc\\', \\'cas\\', \\'520\\', \\'gim\\', \\'248\\', \\'486\\', \\'acl\\', \\'nop\\', \\'plu\\', \\'beu\\', \\' so\\', \\'rah\\', \\'ah \\', \\'h m\\', \\'219\\', \\'2 G\\', \\'eoc\\', \\'rdo\\', \\'do \\', \\'o c\\', \\'cuv\\', \\'vie\\', \\'ier\\', \\'0 R\\', \\'zop\\', \\'pri\\', \\'n a\\', \\'utu\\', \\'819\\', \\'Pri\\', \\'nac\\', \\'ce \\', \\'lau\\', \\'309\\', \\'095\\', \\'5 N\\', \\'Neg\\', \\'gap\\', \\'apr\\', \\'n b\\', \\'oxo\\', \\'xod\\', \\'ror\\', \\'Sco\\', \\'iod\\', \\'n l\\', \\'udu\\', \\'iae\\', \\'n o\\', \\'obe\\', \\'bes\\', \\'esu\\', \\'320\\', \\'1 H\\', \\'mip\\', \\'ipr\\', \\'elo\\', \\'nga\\', \\'Sph\\', \\'phy\\', \\'yrn\\', \\'lew\\', \\'ewi\\', \\'win\\', \\'491\\', \\'mok\\', \\'oka\\', \\'kar\\', \\'arr\\', \\'an \\', \\'n v\\', \\'r O\\', \\' OC\\', \\'OC-\\', \\'C-2\\', \\'-22\\', \\'508\\', \\'tib\\', \\'ibu\\', \\'bur\\', \\'uro\\', \\'a z\\', \\' zy\\', \\'zyg\\', \\'gae\\', \\'181\\', \\'8 E\\', \\'Eus\\', \\'usp\\', \\'yra\\', \\'blo\\', \\'hii\\', \\'ias\\', \\'tau\\', \\'aur\\', \\'amn\\', \\'mna\\', \\' na\\', \\'nas\\', \\'asu\\', \\'4 I\\', \\' Is\\', \\'Isu\\', \\'sur\\', \\' ox\\', \\'oxy\\', \\'xyr\\', \\'aro\\', \\'udo\\', \\'doc\\', \\'s k\\', \\' ka\\', \\'kam\\', \\'moh\\', \\'oha\\', \\'ai \\', \\'822\\', \\'Alo\\', \\'pel\\', \\'443\\', \\'rci\\', \\'cil\\', \\'ulp\\', \\'lpi\\', \\'DM5\\', \\'M51\\', \\'Cet\\', \\'eto\\', \\'axi\\', \\'xim\\', \\'182\\', \\'825\\', \\'Mit\\', \\'its\\', \\'tsu\\', \\'suk\\', \\'uku\\', \\'kur\\', \\' ow\\', \\'ows\\', \\'wst\\', \\'449\\', \\'Chl\\', \\'myd\\', \\'ydo\\', \\'ose\\', \\'ang\\', \\'ngu\\', \\'gui\\', \\'730\\', \\'30.\\', \\'Hep\\', \\'ptr\\', \\'rlo\\', \\'lo \\', \\'6 N\\', \\' No\\', \\'Not\\', \\'ryn\\', \\' ce\\', \\'ped\\', \\' Sq\\', \\'Squ\\', \\'aca\\', \\'470\\', \\'70-\\', \\'bla\\', \\'lai\\', \\'inv\\', \\'nvi\\', \\'vil\\', \\'853\\', \\'467\\', \\'67-\\', \\'tal\\', \\'lba\\', \\'ban\\', \\'864\\', \\'64.\\', \\' So\\', \\'Som\\', \\'omn\\', \\'mni\\', \\'mic\\', \\'icr\\', \\'DM3\\', \\'M35\\', \\'59 \\', \\'451\\', \\'uat\\', \\'dum\\', \\'ume\\', \\'ril\\', \\'il \\', \\'l v\\', \\'C-0\\', \\'797\\', \\'974\\', \\'raj\\', \\'aja\\', \\'ja \\', \\'geo\\', \\'org\\', \\'r e\\', \\' ef\\', \\'efi\\', \\'fis\\', \\'ish\\', \\'sh-\\', \\'h-1\\', \\'121\\', \\'7 m\\', \\' ra\\', \\'rad\\', \\'adi\\', \\'808\\', \\'2 B\\', \\'Ber\\', \\'ngr\\', \\' UW\\', \\'UW:\\', \\'W:4\\', \\':47\\', \\'477\\', \\' Ra\\', \\'Raj\\', \\'ulc\\', \\'lch\\', \\'964\\', \\'793\\', \\'9 B\\', \\'llu\\', \\'lul\\', \\'W:1\\', \\'Dip\\', \\'ptu\\', \\'tur\\', \\'bat\\', \\'nno\\', \\' eF\\', \\'eFi\\', \\'Fis\\', \\'05.\\', \\'5.2\\', \\'2:5\\', \\'2 D\\', \\' kw\\', \\'kwa\\', \\'wan\\', \\'ngt\\', \\'gtu\\', \\'ung\\', \\'nge\\', \\'67.\\', \\'170\\', \\'hyd\\', \\'yde\\', \\'Leu\\', \\'uco\\', \\' er\\', \\'evu\\', \\'81 \\', \\'071\\', \\'173\\', \\'1 O\\', \\' Ok\\', \\'Oka\\', \\'mej\\', \\'eje\\', \\'jei\\', \\'i k\\', \\' ke\\', \\'noj\\', \\'oje\\', \\'81-\\', \\'7 R\\', \\'lav\\', \\'ava\\', \\'vat\\', \\'197\\', \\'mir\\', \\'ira\\', \\'etu\\', \\'71.\\', \\'yst\\', \\'tig\\', \\'igm\\', \\'gma\\', \\'939\\', \\'0 Z\\', \\' Ze\\', \\'Zea\\', \\'ear\\', \\'sut\\', \\'Bat\\', \\'lbo\\', \\'bom\\', \\'087\\', \\'799\\', \\'99.\\', \\'965\\', \\'gri\\', \\'seo\\', \\'88 \\', \\'809\\', \\'rup\\', \\'upt\\', \\'720\\', \\'800\\', \\'932\\', \\'801\\', \\'tar\\', \\'net\\', \\'etz\\', \\'tzi\\', \\'zi \\', \\'949\\', \\' At\\', \\'Atl\\', \\'tla\\', \\'eln\\', \\'lna\\', \\'aui\\', \\'ui \\', \\' IN\\', \\'INI\\', \\'NID\\', \\'IDE\\', \\'DEP\\', \\'EP-\\', \\'P-T\\', \\'-T \\', \\'T 0\\', \\' 04\\', \\'3 T\\', \\' To\\', \\'Tor\\', \\'orp\\', \\'rpe\\', \\'rmo\\', \\'347\\', \\'771\\', \\'502\\', \\'02-\\', \\'1 N\\', \\'Nar\\', \\'e b\\', \\'asi\\', \\'sil\\', \\'nox\\', \\'xyp\\', \\'ypr\\', \\'718\\', \\'Rhy\\', \\'hob\\', \\'oba\\', \\'897\\', \\'Acr\\', \\'iob\\', \\'ann\\', \\'nnu\\', \\' MV\\', \\'MVS\\', \\'VS1\\', \\'S12\\', \\'482\\', \\'82-\\', \\'8 Z\\', \\' Za\\', \\'Zap\\', \\'apt\\', \\'ery\\', \\'ryx\\', \\'x e\\', \\'exa\\', \\'xas\\', \\'579\\', \\'976\\', \\'5 D\\', \\'Das\\', \\'asy\\', \\'sya\\', \\'yat\\', \\'pas\\', \\' CB\\', \\'CBR\\', \\'BRG\\', \\'RG-\\', \\'G-D\\', \\'-Dp\\', \\'Dpa\\', \\'as1\\', \\'s17\\', \\'176\\', \\'767\\', \\'517\\', \\'17-\\', \\'79 \\', \\'9 N\\', \\'Neo\\', \\'ryg\\', \\'ygo\\', \\'n k\\', \\'kuh\\', \\'uhl\\', \\'hli\\', \\'512\\', \\'opl\\', \\'tyt\\', \\'ytr\\', \\'938\\', \\' Gy\\', \\'Gym\\', \\'ymn\\', \\'mnu\\', \\'nur\\', \\'lta\\', \\'tav\\', \\'ave\\', \\'vel\\', \\'837\\', \\'62 \\', \\'Aet\\', \\'tob\\', \\'fla\\', \\'n 0\\', \\' 09\\', \\'09A\\', \\'9A0\\', \\'A06\\', \\'Mob\\', \\'obu\\', \\'4 R\\', \\':43\\', \\'311\\', \\'126\\', \\'251\\', \\' Er\\', \\'Erp\\', \\'toi\\', \\'oic\\', \\'ich\\', \\'18.\\', \\'697\\', \\'975\\', \\'ene\\', \\'neg\\', \\'lyo\\', \\'yod\\', \\'spa\\', \\'pat\\', \\'hul\\', \\'Aci\\', \\'nse\\', \\'r b\\', \\'bae\\', \\'rii\\', \\'327\\', \\'07-\\', \\'60 \\', \\'m v\\', \\'USF\\', \\'SFW\\', \\'FWS\\', \\'WS-\\', \\'S-1\\', \\'03-\\', \\'r d\\', \\' da\\', \\'dab\\', \\'bry\\', \\'rya\\', \\'303\\', \\'r f\\', \\'lve\\', \\'ves\\', \\' LS\\', \\'LSN\\', \\'SNF\\', \\'NFC\\', \\'FC-\\', \\'C-1\\', \\'5-0\\', \\'576\\', \\'r g\\', \\' gu\\', \\'gue\\', \\'uel\\', \\'eld\\', \\'lde\\', \\'tae\\', \\'aed\\', \\'edt\\', \\'med\\', \\'dir\\', \\' nu\\', \\'nud\\', \\'ven\\', \\'e N\\', \\' NU\\', \\'NUD\\', \\'UD2\\', \\'D2_\\', \\'2_B\\', \\'_Ba\\', \\'Bal\\', \\'alh\\', \\'lha\\', \\'ash\\', \\'sh \\', \\'Lod\\', \\'odg\\', \\'dge\\', \\'geL\\', \\'eLa\\', \\'Lab\\', \\'ab \\', \\'b A\\', \\' Ao\\', \\'Aox\\', \\'us_\\', \\'s_1\\', \\'r s\\', \\'hre\\', \\'enc\\', \\'nck\\', \\'cki\\', \\'264\\', \\'01-\\', \\'stu\\', \\'r t\\', \\'nsm\\', \\'smo\\', \\'tan\\', \\'252\\', \\' Hu\\', \\'Hus\\', \\'uso\\', \\'so \\', \\'o h\\', \\'o d\\', \\'dau\\', \\'324\\', \\'58 \\', \\'Sca\\', \\'hir\\', \\'irh\\', \\'Stu\\', \\'urg\\', \\'rg-\\', \\'g-8\\', \\'-86\\', \\'863\\', \\'utt\\', \\'ttk\\', \\'tku\\', \\'kus\\', \\'si \\', \\' NF\\', \\'NFW\\', \\'FWF\\', \\'WFL\\', \\'FLH\\', \\'LH1\\', \\'H10\\', \\'742\\', \\'20-\\', \\'Ami\\', \\'alv\\', \\'813\\', \\'Atr\\', \\'tul\\', \\'810\\', \\' os\\', \\'sse\\', \\'tyr\\', \\'4 E\\', \\'Elo\\', \\'sau\\', \\'1 M\\', \\'Meg\\', \\' at\\', \\'atl\\', \\'92.\\', \\'Alb\\', \\'lpe\\', \\':41\\', \\'592\\', \\'ir \\', \\'r Z\\', \\' ZM\\', \\'ZMU\\', \\'MUC\\', \\'UC:\\', \\'C:P\\', \\':P3\\', \\'P33\\', \\'369\\', \\'69 \\', \\'653\\', \\'Ang\\', \\'uil\\', \\'7.2\\', \\'511\\', \\'Mur\\', \\'rae\\', \\'nes\\', \\'sox\\', \\'ox \\', \\'x b\\', \\'bag\\', \\'574\\', \\'749\\', \\'492\\', \\'x c\\', \\'reu\\', \\'430\\', \\'30-\\', \\'mno\\', \\'rax\\', \\'x k\\', \\' ki\\', \\'kid\\', \\'dak\\', \\'ako\\', \\'ko \\', \\'9 H\\', \\'Hio\\', \\'erg\\', \\'gis\\', \\'514\\', \\'soi\\', \\'teo\\', \\'eog\\', \\'m b\\', \\'41 \\', \\'713\\', \\'Ara\\', \\'rap\\', \\'pai\\', \\'aim\\', \\'Het\\', \\' ni\\', \\'644\\', \\'Coi\\', \\'oil\\', \\' my\\', \\'957\\', \\'2 S\\', \\'Set\\', \\'ty \\', \\'y m\\', \\'2 T\\', \\'Thr\\', \\'hry\\', \\'rys\\', \\'yss\\', \\'tax\\', \\'381\\', \\'set\\', \\'tir\\', \\'Anc\\', \\'hoa\\', \\'oa \\', \\'itc\\', \\'tch\\', \\'li \\', \\'928\\', \\'879\\', \\'958\\', \\'581\\', \\'80-\\', \\'Eng\\', \\'rau\\', \\'aul\\', \\' en\\', \\'ncr\\', \\'olu\\', \\'5 E\\', \\' ri\\', \\'1 L\\', \\'Lyc\\', \\'yce\\', \\'eng\\', \\'gro\\', \\'Sto\\', \\'tol\\', \\'ole\\', \\'lep\\', \\'omm\\', \\'mme\\', \\'rso\\', \\'nni\\', \\'nii\\', \\'ins\\', \\'nsu\\', \\'s w\\', \\' wa\\', \\'wai\\', \\'ait\\', \\'tei\\', \\'0 J\\', \\' Je\\', \\'Jen\\', \\'enk\\', \\'nki\\', \\'kin\\', \\'mpr\\', \\'Spr\\', \\'pra\\', \\'9 I\\', \\'Ili\\', \\'sha\\', \\'ha \\', \\'afr\\', \\'fri\\', \\'3 I\\', \\'7 O\\', \\'Opi\\', \\'sth\\', \\'hop\\', \\'doo\\', \\'oor\\', \\'re \\', \\'e s\\', \\'seq\\', \\'que\\', \\'uen\\', \\'ce\\\\n\\', \\'Clu\\', \\'lup\\', \\'671\\', \\'8 G\\', \\' Gu\\', \\'Gud\\', \\'667\\', \\'Hyp\\', \\'674\\', \\'mal\\', \\'chm\\', \\'hmo\\', \\'959\\', \\'att\\', \\'ttu\\', \\'spr\\', \\'pei\\', \\'eic\\', \\'aes\\', \\'esa\\', \\'arn\\', \\'rne\\', \\'151\\', \\'eon\\', \\'ult\\', \\'ltr\\', \\'riv\\', \\'370\\', \\'8 A\\', \\'iva\\', \\' NE\\', \\'NEF\\', \\'EFC\\', \\'FC \\', \\'C F\\', \\'F17\\', \\'75.\\', \\'bam\\', \\' Aa\\', \\'Aal\\', \\'ae_\\', \\'e_1\\', \\'dio\\', \\'cri\\', \\'sap\\', \\'api\\', \\'sim\\', \\' ps\\', \\'pse\\', \\'doh\\', \\'Bre\\', \\'evo\\', \\'voo\\', \\'rti\\', \\'Sar\\', \\'din\\', \\'ilc\\', \\'rdu\\', \\'aga\\', \\'gax\\', \\'872\\', \\'imn\\', \\'thr\\', \\'hri\\', \\'n i\\', \\' D2\\', \\'D2 \\', \\'cae\\', \\' D7\\', \\'D7 \\', \\'hac\\', \\'cun\\', \\'7 T\\', \\' Te\\', \\'Ten\\', \\'nua\\', \\' il\\', \\'me,\\', \\'e, \\', \\', s\\', \\'in:\\', \\'n: \\', \\': c\\', \\'cl1\\', \\'l10\\', \\'10\\\\n\\', \\'0\\\\nG\\', \\'lyg\\', \\'irm\\', \\'rm \\', \\'upa\\', \\' th\\', \\'oro\\', \\'0 D\\', \\'se \\', \\'06.\\', \\'485\\', \\' Es\\', \\'Esc\\', \\'cua\\', \\' Et\\', \\'Eth\\', \\'thm\\', \\'hma\\', \\' fi\\', \\'fim\\', \\'imb\\', \\'0 K\\', \\' Ko\\', \\'Kon\\', \\' og\\', \\'gli\\', \\'763\\', \\'880\\', \\'802\\', \\'726\\', \\'lbe\\', \\'bel\\', \\'371\\', \\'gib\\', \\'bbo\\', \\'395\\', \\'955\\', \\'553\\', \\'495\\', \\'emu\\', \\'mur\\', \\'ru \\', \\'u m\\', \\'334\\', \\'ice\\', \\'eps\\', \\'mad\\', \\'ade\\', \\'666\\', \\'Har\\', \\'gul\\', \\'jag\\', \\'gua\\', \\'uan\\', \\'Ale\\', \\'epo\\', \\'poc\\', \\'bai\\', \\'air\\', \\'ird\\', \\'dii\\', \\'Cir\\', \\'CBM\\', \\'BM:\\', \\'M:Z\\', \\':ZF\\', \\'ZF \\', \\'F 1\\', \\' 11\\', \\'647\\', \\'47 \\', \\'761\\', \\':64\\', \\'423\\', \\'23-\\', \\'-79\\', \\'73 \\', \\' mr\\', \\'mri\\', \\'rig\\', \\'abe\\', \\'beo\\', \\'eo \\', \\'bas\\', \\'su \\', \\'168\\', \\'Cat\\', \\'6 L\\', \\'o r\\', \\'roh\\', \\'ohi\\', \\'tit\\', \\' Cy\\', \\'Cyp\\', \\'arp\\', \\'rpi\\', \"o \\'\", \" \\'c\", \"\\'co\", \"or\\'\", \"r\\' \", \"\\' m\", \\'402\\', \\'siu\\', \\'ibe\\', \\'rbu\\', \\'532\\', \\'Luc\\', \\'uci\\', \\'cio\\', \\'scl\\', \\'0 O\\', \\' Ox\\', \\'Oxy\\', \\'xyg\\', \\'ygy\\', \\'gym\\', \\'ocy\\', \\'cyp\\', \\'tew\\', \\'ewa\\', \\'war\\', \\'820\\', \\'Ore\\', \\'Sch\\', \\'zot\\', \\'x w\\', \\'wal\\', \\'lto\\', \\'Pty\\', \\'tyc\\', \\'ych\\', \\'dip\\', \\'pog\\', \\'ogo\\', \\'496\\', \\'lte\\', \\'r l\\', \\'333\\', \\'3.2\\', \\'2:6\\', \\'25-\\', \\'Dan\\', \\'rer\\', \\'ypo\\', \\'lmi\\', \\'mol\\', \\'rix\\', \\'194\\', \\'nob\\', \\'92-\\', \\' Ct\\', \\'Cte\\', \\'yng\\', \\'ngo\\', \\'god\\', \\' id\\', \\' Ti\\', \\'Tin\\', \\'538\\', \\'Rho\\', \\'deu\\', \\'378\\', \\'Abb\\', \\'bot\\', \\'ott\\', \\'662\\', \\'Gob\\', \\'bio\\', \\'o g\\', \\' go\\', \\'gob\\', \\'Pho\\', \\'hox\\', \\'oxi\\', \\'Chr\\', \\'hro\\', \\'yth\\', \\'rog\\', \\'oga\\', \\'CAN\\', \\'ANT\\', \\'NTA\\', \\'Gil\\', \\'ila\\', \\'coe\\', \\'oer\\', \\'lea\\', \\'0 G\\', \\'SNA\\', \\'NAR\\', \\'ARR\\', \\'RRC\\', \\'RC1\\', \\'C18\\', \\'8-0\\', \\'-01\\', \\'414\\', \\'hoc\\', \\'eil\\', \\' lu\\', \\'ciu\\', \\'ARC\\', \\'RCC\\', \\'CC1\\', \\'reg\\', \\'Sip\\', \\'392\\', \\'927\\', \\'Lav\\', \\'avi\\', \\'exi\\', \\'xil\\', \\'659\\', \\'urn\\', \\'0 N\\', \\' cr\\', \\'cry\\', \\'yso\\', \\'ram\\', \\'ami\\', \\'Cho\\', \\'emm\\', \\'mmi\\', \\'gii\\', \\'lyl\\', \\'yle\\', \\'867\\', \\'Rut\\', \\'rut\\', \\'FC_\\', \\'C_F\\', \\'_F2\\', \\'F20\\', \\'lmu\\', \\'Med\\', \\'eda\\', \\'lgi\\', \\'gid\\', \\'b M\\', \\' Mf\\', \\'Mfu\\', \\'da_\\', \\'a_9\\', \\'_9 \\', \\'Sem\\', \\'mot\\', \\'727\\', \\'xyc\\', \\' IH\\', \\'IHB\\', \\'HB-\\', \\'-LH\\', \\'LHG\\', \\'HG2\\', \\'G20\\', \\'306\\', \\'9 M\\', \\'Myl\\', \\'Pog\\', \\'rol\\', \\'dot\\', \\'951\\', \\' Ri\\', \\'Ric\\', \\'rds\\', \\'dso\\', \\' eg\\', \\'egr\\', \\'gre\\', \\'giu\\', \\'7 E\\', \\'Exo\\', \\'xog\\', \\'ua \\', \\'7-0\\', \\'-06\\', \\'8 R\\', \\'Cam\\', \\'mpo\\', \\' Bl\\', \\'Bli\\', \\'icc\\', \\'cca\\', \\' bj\\', \\'bjo\\', \\'joe\\', \\'erk\\', \\'rkn\\', \\'kna\\', \\'499\\', \\'99-\\', \\' BC\\', \\'BC-\\', \\'C-3\\', \\'-34\\', \\'261\\', \\'Dio\\', \\'iab\\', \\'abo\\', \\'bol\\', \\'-08\\', \\'2 H\\', \\'Hyb\\', \\'ybo\\', \\'bog\\', \\'ogn\\', \\'nuc\\', \\'cit\\', \\'907\\', \\'8 H\\', \\'bop\\', \\'923\\', \\'Lux\\', \\'uxi\\', \\'931\\', \\'nut\\', \\'ils\\', \\'lsb\\', \\'sbr\\', \\'ryi\\', \\' LB\\', \\'LBC\\', \\'935\\', \\'35.\\', \\'hru\\', \\'rur\\', \\'s u\\', \\'660\\', \\'1-8\\', \\'Mac\\', \\'crh\\', \\'hyb\\', \\'s h\\', \\' hy\\', \\'yos\\', \\'mee\\', \\'eki\\', \\'ki \\', \\'304\\', \\':44\\', \\'-60\\', \\'925\\', \\'8 N\\', \\'noi\\', \\'bif\\', \\'ifr\\', \\'fre\\', \\'4 N\\', \\'boo\\', \\'oop\\', \\' DF\\', \\'DF-\\', \\'F-4\\', \\'-4 \\', \\'786\\', \\' bu\\', \\'buc\\', \\'ccu\\', \\'r T\\', \\' TC\\', \\'TCW\\', \\'CWC\\', \\'WC:\\', \\'C:F\\', \\':Fi\\', \\'sh:\\', \\'h:2\\', \\'0.0\\', \\'e R\\', \\' RA\\', \\'RAH\\', \\'AH-\\', \\'H-1\\', \\'aly\\', \\'lyb\\', \\'yba\\', \\'F16\\', \\'6-0\\', \\'-05\\', \\'947\\', \\'7 N\\', \\'gir\\', \\'rar\\', \\'di \\', \\'RC2\\', \\'C20\\', \\'0-0\\', \\'-03\\', \\'hud\\', \\'uds\\', \\'-61\\', \\' je\\', \\'jem\\', \\'eme\\', \\'mez\\', \\'zan\\', \\'811\\', \\'092\\', \\'tex\\', \\'xan\\', \\'vol\\', \\'Ops\\', \\'pso\\', \\'sop\\', \\'poe\\', \\'oeo\\', \\'eod\\', \\'odu\\', \\' em\\', \\'Phe\\', \\'cob\\', \\'rab\\', \\'abi\\', \\'Pim\\', \\'mep\\', \\' pr\\', \\'tyg\\', \\'-59\\', \\'bia\\', \\'945\\', \\'rim\\', \\'imi\\', \\'tah\\', \\'aho\\', \\'hoe\\', \\'oen\\', \\'258\\', \\' De\\', \\'Del\\', \\'elt\\', \\'lti\\', \\'lux\\', \\'uxa\\', \\'xat\\', \\'9 X\\', \\' Xy\\', \\'Xyr\\', \\'Eri\\', \\'imy\\', \\'obl\\', \\'0 M\\', \\'Min\\', \\'iny\\', \\'nyt\\', \\'rem\\', \\'m n\\', \\'nig\\', \\'633\\', \\'Tho\\', \\'hot\\', \\'oec\\', \\'Mox\\', \\'xos\\', \\'con\\', \\'ges\\', \\'duq\\', \\'uqu\\', \\'ues\\', \\'esn\\', \\'sni\\', \\' LP\\', \\'LP-\\', \\'P-2\\', \\'-2 \\', \\'P-1\\', \\'eci\\', \\'lur\\', \\'645\\', \\'Cyc\\', \\'ycl\\', \\'cle\\', \\'F19\\', \\'265\\', \\'Ict\\', \\'bub\\', \\'uba\\', \\'719\\', \\'192\\', \\'rip\\', \\'ipl\\', \\'a y\\', \\' ya\\', \\'yar\\', \\'rka\\', \\'kan\\', \\'nde\\', \\'dor\\', \\'ors\\', \\'753\\', \\'Hop\\', \\' LA\\', \\'LAG\\', \\'AGE\\', \\'GEN\\', \\'ENP\\', \\'NPE\\', \\'PE_\\', \\'E_1\\', \\'_11\\', \\'Pia\\', \\'hyp\\', \\'mes\\', \\'goc\\', \\'tte\\', \\'eat\\', \\'obt\\', \\'btu\\', \\'Sal\\', \\'b P\\', \\'Pin\\', \\'si_\\', \\'i_1\\', \\'780\\', \\'ryd\\', \\'isj\\', \\'sju\\', \\'jun\\', \\'agr\\', \\'Hor\\', \\'53-\\', \\'Bag\\', \\'s y\\', \\'rel\\', \\'526\\', \\'26-\\', \\'Cre\\', \\'log\\', \\'215\\', \\'Euc\\', \\'shi\\', \\'nou\\', \\'ouy\\', \\'uye\\', \\'yei\\', \\' Gl\\', \\'Gly\\', \\'rno\\', \\'non\\', \\'876\\', \\'tot\\', \\'x f\\', \\'fok\\', \\'oki\\', \\'kie\\', \\'956\\', \\'375\\', \\'Syn\\', \\'yno\\', \\'833\\', \\'Mal\\', \\'lap\\', \\'lec\\', \\'ctr\\', \\'Sil\\', \\'2 W\\', \\'Wal\\', \\'ago\\', \\'o a\\', \\'tu \\', \\'Cla\\', \\'iep\\', \\'714\\', \\'7-6\\', \\' Ta\\', \\'Tan\\', \\'CES\\', \\'ES-\\', \\'S-0\\', \\'opn\\', \\'pne\\', \\'649\\', \\'497\\', \\' Ai\\', \\'Ail\\', \\'coi\\', \\'Gen\\', \\'nid\\', \\'Net\\', \\' RB\\', \\'RB1\\', \\'B14\\', \\'4-A\\', \\'-A0\\', \\'A04\\', \\'eob\\', \\'vac\\', \\'hel\\', \\'1-6\\', \\'1 R\\', \\'Rit\\', \\'721\\', \\'dig\\', \\'n h\\', \\':50\\', \\'-65\\', \\'tys\\', \\'Sor\\', \\'im \\', \\'m l\\', \\'Lop\\', \\'nog\\', \\'bou\\', \\'oud\\', \\'ude\\', \\'2 I\\', \\'fur\\', \\'urc\\', \\'rca\\', \\':63\\', \\'-78\\', \\'386\\', \\'Pyl\\', \\' ol\\', \\'n N\\', \\'_F1\\', \\'78 \\', \\'Ame\\', \\'mei\\', \\'eiu\\', \\'-37\\', \\'neb\\', \\'ebu\\', \\'650\\', \\' gy\\', \\'gyr\\', \\'Glo\\', \\'lax\\', \\'xia\\', \\'ted\\', \\'6-3\\', \\'umn\\', \\'207\\', \\'762\\', \\'clu\\', \\'eaf\\', \\'afo\\', \\'764\\', \\'piu\\', \\'dra\\', \\'m w\\', \\' wi\\', \\'wil\\', \\'iam\\', \\'ams\\', \\'mso\\', \\'cic\\', \\'305\\', \\'hym\\', \\'yma\\', \\'e K\\', \\' K-\\', \\'K-2\\', \\'2 v\\', \\'r K\\', \\'-80\\', \\'tug\\', \\'uga\\', \\' On\\', \\'Onc\\', \\'gor\\', \\'ket\\', \\'eta\\', \\'utc\\', \\'ch \\', \\'8-8\\', \\'myk\\', \\'yki\\', \\'ss \\', \\'861\\', \\'615\\', \\'ka \\', \\'5-8\\', \\' ts\\', \\'tsh\\', \\'haw\\', \\'awy\\', \\'wyt\\', \\'yts\\', \\'100\\', \\'mo \\', \\'o t\\', \\'960\\', \\'6-8\\', \\'o s\\', \\'ar \\', \\'alp\\', \\' SM\\', \\'SMK\\', \\'MK3\\', \\'K33\\', \\'436\\', \\'36-\\', \\'fon\\', \\'lma\\', \\'nam\\', \\'ayc\\', \\'ycu\\', \\'ush\\', \\'h s\\', \\'0-6\\', \\'990\\', \\'Eso\\', \\'x l\\', \\'Dal\\', \\' Um\\', \\'Umb\\', \\'mi \\', \\'b U\\', \\' Ul\\', \\'Uli\\', \\'mi_\\', \\' py\\', \\'pyg\\', \\'ygm\\', \\'aea\\', \\'nip\\', \\'Osm\\', \\'sme\\', \\' ep\\', \\'DM2\\', \\'M24\\', \\'-07\\', \\'4 T\\', \\'Tha\\', \\'UW1\\', \\'W15\\', \\'372\\', \\'075\\', \\' Re\\', \\'Ret\\', \\' GU\\', \\'GUB\\', \\'UB4\\', \\'B43\\', \\'Sau\\', \\'ndo\\', \\'osq\\', \\'squ\\', \\'uam\\', \\'hlo\\', \\' ag\\', \\'siz\\', \\'izi\\', \\':56\\', \\'-72\\', \\'220\\', \\'esp\\', \\'spl\\', \\' SI\\', \\'SIO\\', \\'IO:\\', \\'O:1\\', \\':1a\\', \\'1ad\\', \\'adf\\', \\'dfa\\', \\'fa4\\', \\'a41\\', \\'5-5\\', \\'-54\\', \\'43a\\', \\'3a-\\', \\'a-4\\', \\'48f\\', \\'8f-\\', \\'f-b\\', \\'-b0\\', \\'b0d\\', \\'0de\\', \\'de-\\', \\'e-3\\', \\'-33\\', \\'33f\\', \\'3fa\\', \\'fab\\', \\'ba0\\', \\'a0c\\', \\'0cb\\', \\'cb4\\', \\'b4e\\', \\'4e6\\', \\'e6 \\', \\'49.\\', \\'mex\\', \\'xic\\', \\'SUL\\', \\'ULA\\', \\'LA \\', \\'A 1\\', \\' 16\\', \\'Ben\\', \\' pt\\', \\'634\\', \\'874\\', \\'arl\\', \\'rls\\', \\'sbe\\', \\'gi \\', \\'Myc\\', \\'yct\\', \\'m a\\', \\'gut\\', \\'rco\\', \\' om\\', \\'556\\', \\'Aph\\', \\'phr\\', \\'red\\', \\'dod\\', \\'say\\', \\'aya\\', \\'All\\', \\'cyt\\', \\'ytt\\', \\'319\\', \\'7 Z\\', \\'Zeu\\', \\'tog\\', \\'gad\\', \\'adu\\', \\'Bor\\', \\'reo\\', \\'sai\\', \\'aid\\', \\' SA\\', \\'SAC\\', \\'ACD\\', \\'CD1\\', \\'D10\\', \\'995\\', \\'Gad\\', \\'lco\\', \\'cog\\', \\'ogr\\', \\'mmu\\', \\'hua\\', \\'Mic\\', \\'pou\\', \\'out\\', \\'sou\\', \\'ou \\', \\'Mel\\', \\'egl\\', \\'gle\\', \\'lef\\', \\'ire\\', \\'523\\', \\'Bro\\', \\'osm\\', \\'me \\', \\'DM8\\', \\'M85\\', \\'Lot\\', \\'Mol\\', \\'olv\\', \\' dy\\', \\'dyp\\', \\'ygi\\', \\'MUB\\', \\'UB:\\', \\'B:2\\', \\'hae\\', \\':40\\', \\'Coe\\', \\'oel\\', \\'ael\\', \\'513\\', \\'rlu\\', \\'hub\\', \\'ubb\\', \\'bbs\\', \\'bsi\\', \\'x d\\', \\'cad\\', \\'ada\\', \\'ylu\\', \\'x s\\', \\'n d\\', \\'iad\\', \\'22-\\', \\'981\\', \\'apu\\', \\' be\\', \\'rmu\\', \\'mud\\', \\'7 K\\', \\' Ku\\', \\'Kur\\', \\'urt\\', \\'Les\\', \\'sue\\', \\'ueu\\', \\'eur\\', \\'M41\\', \\' NR\\', \\'NRM\\', \\'RM:\\', \\'M:N\\', \\':NR\\', \\'RM6\\', \\'M69\\', \\'435\\', \\'bru\\', \\'unn\\', \\'rcc\\', \\'cot\\', \\'Bol\\', \\'nir\\', \\'432\\', \\'72 \\', \\'910\\', \\'Tae\\', \\'ioi\\', \\' CH\\', \\'CH1\\', \\'H1 \\', \\'Hip\\', \\'mpu\\', \\'kud\\', \\'s z\\', \\' zo\\', \\'zos\\', \\'hyl\\', \\'ngn\\', \\'hoi\\', \\'pax\\', \\' Fi\\', \\'759\\', \\'Mul\\', \\'mul\\', \\' Up\\', \\'Upe\\', \\'lph\\', \\'ure\\', \\' S1\\', \\'9 U\\', \\'met\\', \\'heu\\', \\'725\\', \\'r a\\', \\'r c\\', \\'r j\\', \\'773\\', \\'cyb\\', \\'ybi\\', \\'omo\\', \\'cav\\', \\'887\\', \\'sie\\', \\'CGR\\', \\'RAG\\', \\'NM \\', \\'M 4\\', \\' 44\\', \\'756\\', \\'M36\\', \\'631\\', \\'Aux\\', \\'xis\\', \\'632\\', \\'787\\', \\'haz\\', \\'aza\\', \\'rd \\', \\'d m\\', \\'Eut\\', \\'ynn\\', \\'1 K\\', \\'ats\\', \\'suw\\', \\'uwo\\', \\'won\\', \\'341\\', \\'891\\', \\'Thu\\', \\'hun\\', \\'lal\\', \\'lun\\', \\'ga \\', \\'Tal\\', \\'lt-\\', \\'t-U\\', \\'-UN\\', \\'UNA\\', \\'NAL\\', \\'AL-\\', \\'L-0\\', \\'coy\\', \\'oyi\\', \\'yii\\', \\'CTN\\', \\'TNT\\', \\'TAN\\', \\'ANC\\', \\'NCC\\', \\'TNG\\', \\'NGC\\', \\'TGN\\', \\'GNC\\', \\'NCA\\', \\'CCN\\', \\'CNG\\', \\'NGG\\', \\'GTN\\', \\'ATN\\', \\'TTN\\', \\'TN\\\\n\\', \\'N\\\\nA\\', \\'AAN\\', \\'NCT\\', \\'NGA\\', \\'1.2\\', \\'ngg\\', \\'ggo\\', \\'ol \\', \\'l m\\', \\'rbo\\', \\'bo \\', \\'791\\', \\'anh\\', \\'hai\\', \\'aie\\', \\'Ari\\', \\'Pam\\', \\'Pep\\', \\'epr\\', \\'562\\', \\'Arr\\', \\'Mas\\', \\'cem\\', \\'emb\\', \\'Mon\\', \\'Ana\\', \\'nab\\', \\'tud\\', \\'Bet\\', \\'2 O\\', \\'Osp\\', \\'my \\', \\'620\\', \\'uis\\', \\' dj\\', \\'dje\\', \\'jed\\', \\' kl\\', \\'kle\\', \\'622\\', \\'Atu\\', \\'anx\\', \\'nx \\', \\'x i\\', \\' ig\\', \\'gno\\', \\'Dec\\', \\'rua\\', \\'ads\\', \\'dsi\\', \\'rdy\\', \\'dyl\\', \\'Sel\\', \\'cru\\', \\'184\\', \\'roi\\', \\'Tra\\', \\' sy\\', \\'sym\\', \\'ymm\\', \\'O:2\\', \\'78a\\', \\'8a0\\', \\'a01\\', \\'17c\\', \\'7c-\\', \\'c-d\\', \\'-da\\', \\'da5\\', \\'a54\\', \\'-4e\\', \\'4e2\\', \\'e27\\', \\'7-a\\', \\'-aa\\', \\'aaa\\', \\'aad\\', \\'ad-\\', \\'d-3\\', \\'-31\\', \\'31e\\', \\'1e6\\', \\'e69\\', \\'69e\\', \\'9e5\\', \\'e5b\\', \\'5bd\\', \\'bd2\\', \\'d24\\', \\'681\\', \\'ucr\\', \\'uct\\', \\'870\\', \\'Ser\\', \\'869\\', \\'868\\', \\'inq\\', \\'nqu\\', \\'uer\\', \\'nei\\', \\'eis\\', \\'Lac\\', \\'Men\\', \\'Rac\\', \\'hyc\\', \\'nad\\', \\'cud\\', \\'jel\\', \\'o v\\', \\'r E\\', \\' EC\\', \\'ECS\\', \\'CSF\\', \\'SFR\\', \\'FRI\\', \\'RI-\\', \\'I-B\\', \\'-BM\\', \\'BMY\\', \\'MY0\\', \\'Y00\\', \\'6 X\\', \\' Xi\\', \\'Xip\\', \\'lad\\', \\'675\\', \\'Mak\\', \\'aka\\', \\'kai\\', \\'Ist\\', \\'678\\', \\'Tet\\', \\'A v\\', \\' MA\\', \\'MAN\\', \\'ANI\\', \\'NI0\\', \\'I00\\', \\'pfl\\', \\'lue\\', \\'ueg\\', \\'ege\\', \\'B v\\', \\' TE\\', \\'TEP\\', \\'EPF\\', \\'PF0\\', \\'F00\\', \\'rif\\', \\' A5\\', \\'A51\\', \\'922\\', \\'nol\\', \\'Rei\\', \\'dub\\', \\'sod\\', \\'765\\', \\'Ath\\', \\' ev\\', \\'eve\\', \\'Cle\\', \\'erz\\', \\'rze\\', \\'zen\\', \\' Eo\\', \\'Eop\\', \\' jo\\', \\'jor\\', \\'807\\', \\'chn\\', \\'hne\\', \\'lyx\\', \\'yxy\\', \\'xys\\', \\'vet\\', \\'Ple\\', \\'9 K\\', \\'Kar\\', \\'966\\', \\'nec\\', \\':42\\', \\'977\\', \\'777\\', \\' yo\\', \\'yok\\', \\'oko\\', \\'koh\\', \\'ham\\', \\'5 V\\', \\' Ve\\', \\'Ver\\', \\'6 V\\', \\'Col\\', \\':61\\', \\'-76\\', \\'Cyn\\', \\' ab\\', \\'abb\\', \\'bbr\\', \\'873\\', \\'915\\', \\' za\\', \\'anz\\', \\'zib\\', \\'ymp\\', \\'usa\\', \\'myc\\', \\'Sol\\', \\'zii\\', \\'Abu\\', \\'bud\\', \\'def\\', \\'efd\\', \\'fdu\\', \\'duf\\', \\'uf \\', \\'f v\\', \\'vai\\', \\'aig\\', \\'gie\\', \\'Ald\\', \\'ldr\\', \\'rst\\', \\'Che\\', \\'Mug\\', \\'l c\\', \\' Oe\\', \\'Oed\\', \\'dal\\', \\'382\\', \\'842\\', \\'Cic\\', \\'Cop\\', \\'n z\\', \\' zi\\', \\'zil\\', \\'3 O\\', \\'sam\\', \\'lil\\', \\'uno\\', \\'nui\\', \\'boe\\', \\'-02\\', \\'387\\', \\'Ory\\', \\'ryz\\', \\'yzi\\', \\'zia\\', \\'Abl\\', \\' Ty\\', \\'Tyl\\', \\'oco\\', \\'dil\\', \\'lol\\', \\'bis\\', \\'sig\\', \\'gni\\', \\'n u\\', \\'516\\', \\'obr\\', \\'urz\\', \\'zer\\', \\':60\\', \\'-75\\', \\'754\\', \\'7 F\\', \\' Fu\\', \\'Fun\\', \\'hax\\', \\'x g\\', \\'rdn\\', \\'dne\\', \\'n U\\', \\' Ud\\', \\'Udi\\', \\'mou\\', \\'oun\\', \\'unt\\', \\'tai\\', \\':62\\', \\'-77\\', \\'782\\', \\'2 K\\', \\' Kr\\', \\'Kry\\', \\'leb\\', \\'ebi\\', \\'855\\', \\'4-8\\', \\'Mil\\', \\'3 F\\', \\' CC\\', \\'CC-\\', \\'236\\', \\'9 F\\', \\'8 F\\', \\'isp\\', \\'312\\', \\'ocl\\', \\'cli\\', \\'1 F\\', \\'b F\\', \\' Fn\\', \\'Fno\\', \\'625\\', \\' ib\\', \\'bov\\', \\' N-\\', \\'N-3\\', \\'-32\\', \\'2 J\\', \\' Jo\\', \\'Jor\\', \\' ho\\', \\'hol\\', \\'olb\\', \\'lbr\\', \\'roo\\', \\'ook\\', \\'b G\\', \\' Gh\\', \\'Gho\\', \\'ki_\\', \\'Poe\\', \\'e 2\\', \\'3 X\\', \\'623\\', \\'Ger\\', \\' oy\\', \\'oye\\', \\'yen\\', \\'Amm\\', \\'mmo\\', \\'mod\\', \\'ody\\', \\'dyt\\', \\'hex\\', \\'xap\\', \\'Cen\\', \\'exo\\', \\'xol\\', \\'M34\\', \\'302\\', \\'612\\', \\'5 X\\', \\'hty\\', \\'nov\\', \\'ova\\', \\'eol\\', \\'x j\\', \\'Dic\\', \\' DL\\', \\'DLm\\', \\'Lmg\\', \\'mgm\\', \\'gm5\\', \\'m57\\', \\' DP\\', \\'DP4\\', \\'P4M\\', \\'4M \\', \\'M m\\', \\'e a\\', \\'sax\\', \\'axa\\', \\'aet\\', \\'x o\\', \\'rgy\\', \\'nib\\', \\'be \\', \\'e W\\', \\' WL\\', \\'WL2\\', \\'L20\\', \\'n j\\', \\'jam\\', \\'mai\\', \\'aic\\', \\'eia\\', \\'lya\\', \\'yac\\', \\'bea\\', \\'Sci\\', \\'Tot\\', \\'toa\\', \\'oab\\', \\'acd\\', \\'cdo\\', \\'ald\\', \\'ldi\\', \\'egu\\', \\'Zeb\\', \\'ebr\\', \\'aso\\', \\'Nas\\', \\'401\\', \\'xac\\', \\' Em\\', \\'Emm\\', \\'nit\\', \\'CSI\\', \\'SIR\\', \\'IRO\\', \\'RO \\', \\'O H\\', \\' H4\\', \\'H42\\', \\'4-0\\', \\'iog\\', \\'oge\\', \\'eio\\', \\' NZ\\', \\'NZ \\', \\'Z P\\', \\' P.\\', \\'P.0\\', \\'.04\\', \\'904\\', \\'Lei\\', \\'ruc\\', \\'7 G\\', \\'Gaz\\', \\'azz\\', \\'zza\\', \\'za \\', \\' im\\', \\'imp\\', \\'Con\\', \\'n n\\', \\'das\\', \\'sys\\', \\'kaa\\', \\'aak\\', \\'Lut\\', \\'utj\\', \\'tja\\', \\'jan\\', \\'rpo\\', \\'916\\', \\'lvi\\', \\'vif\\', \\'ifl\\', \\'kas\\', \\'737\\', \\'seb\\', \\'syn\\', \\'yna\\', \\'nag\\', \\'Ocy\\', \\'cyu\\', \\'ysu\\', \\'mbo\\', \\'ben\\', \\'Lob\\', \\'Nem\\', \\'624\\', \\'aeo\\', \\'o j\\', \\'sih\\', \\'iha\\', \\'854\\', \\'Den\\', \\'Pag\\', \\':67\\', \\'-83\\', \\'rav\\', \\'veo\\', \\'209\\', \\'185\\', \\'hle\\', \\' SZ\\', \\'SZN\\', \\'ZN-\\', \\'N-O\\', \\'-OS\\', \\'OST\\', \\'ST-\\', \\'T-0\\', \\'erv\\', \\'rvi\\', \\'fro\\', \\'GCR\\', \\'CRC\\', \\'maj\\', \\'ajo\\', \\'616\\', \\'Rha\\', \\'bdo\\', \\'Spa\\', \\'Sig\\', \\'389\\', \\'tay\\', \\'Cap\\', \\'tep\\', \\'ceo\\', \\'Doe\\', \\'oed\\', \\'rle\\', \\'ryc\\', \\'yco\\', \\'Pem\\', \\'emp\\', \\'chw\\', \\'hwe\\', \\'wen\\', \\'cim\\', \\'en_\\', \\'n_v\\', \\'_vo\\', \\'er:\\', \\'r: \\', \\': K\\', \\' KP\\', \\'KPM\\', \\'PM-\\', \\'M-N\\', \\'-NI\\', \\'NI:\\', \\'I:3\\', \\':37\\', \\'39\\\\n\\', \\'9\\\\nG\\', \\'ilb\\', \\'ert\\', \\'mox\\', \\' Pn\\', \\'Pni\\', \\'dol\\', \\'lom\\', \\'mie\\', \\'ieu\\', \\'eu \\', \\'moi\\', \\'b L\\', \\' Lg\\', \\'Lgi\\', \\'-21\\', \\'4.2\\', \\'SMC\\', \\'MCr\\', \\'Cr-\\', \\'r-1\\', \\'Ela\\', \\'Gir\\', \\'314\\', \\'neo\\', \\'Bos\\', \\'ock\\', \\'kia\\', \\' ik\\', \\'ike\\', \\'kei\\', \\'e E\\', \\' EF\\', \\'FC0\\', \\'pee\\', \\'eel\\', \\'ia,\\', \\'a, \\', \\'acq\\', \\'cqu\\', \\'uar\\', \\'igu\\', \\'vem\\', \\'Nan\\', \\'A21\\', \\'tsi\\', \\' kn\\', \\'kne\\', \\'Ter\\', \\'jar\\', \\'bua\\', \\'Cep\\', \\' Ep\\', \\'Epi\\', \\'niv\\', \\'vea\\', \\'tof\\', \\'ofa\\', \\'scr\\', \\'rib\\', \\'C-4\\', \\'cie\\', \\' WW\\', \\'WW-\\', \\'W-1\\', \\' sh\\', \\'shu\\', \\'W-8\\', \\'-8 \\', \\'pre\\', \\'heo\\', \\'eos\\', \\'F18\\', \\'28_\\', \\'8_ \\', \\'_ m\\', \\'olm\\', \\'lms\\', \\'mst\\', \\'San\\', \\'b S\\', \\' Sv\\', \\'Svi\\', \\' ir\\', \\'irw\\', \\'rwi\\', \\'iic\\', \\'Dol\\', \\'idr\\', \\'co \\', \\'o l\\', \\'ged\\', \\' sk\\', \\'sko\\', \\'kot\\', \\'tts\\', \\'tsb\\', \\'hea\\', \\'odr\\', \\'o w\\', \\'mps\\', \\'gun\\', \\'ysc\\', \\'dew\\', \\'wit\\', \\'mye\\', \\'ryo\\', \\'lov\\', \\'n R\\', \\' R0\\', \\'R01\\', \\'e I\\', \\'ICT\\', \\'CTI\\', \\'TI1\\', \\'I11\\', \\'bbe\\', \\'ndb\\', \\'dbe\\', \\'dif\\', \\'got\\', \\'bor\\', \\'orc\\', \\'chg\\', \\'hgr\\', \\'ink\\', \\'Tre\\', \\' eu\\', \\'eul\\', \\'nso\\', \\':76\\', \\'6-9\\', \\'loe\\', \\'nnb\\', \\'nbe\\', \\'new\\', \\'ewn\\', \\'wne\\', \\'826\\', \\'kum\\', \\'umu\\', \\'mu \\', \\'779\\', \\'Seb\\', \\' C0\\', \\'C0H\\', \\'0HG\\', \\'HG3\\', \\'G3A\\', \\'3AC\\', \\'AC \\', \\'bab\\', \\'abc\\', \\'bco\\', \\'coc\\', \\'776\\', \\' 40\\', \\'821\\', \\'roa\\', \\'817\\', \\'goo\\', \\'dei\\', \\' ko\\', \\'kor\\', \\'ean\\', \\'orv\\', \\'rve\\', \\'veg\\', \\'pau\\', \\'ysp\\', \\'ree\\', \\'eed\\', \\'enb\\', \\'nbl\\', \\'acz\\', \\'cza\\', \\'now\\', \\'wsk\\', \\'ski\\', \\' 26\\', \\'viv\\', \\'ipa\\', \\'zac\\', \\'ois\\', \\' In\\', \\'Ini\\', \\'nim\\', \\'nif\\', \\' BS\\', \\'BS0\\', \\'S02\\', \\'upu\\', \\'609\\', \\'r i\\', \\'LAB\\', \\'AB0\\', \\'B01\\', \\'9 Z\\', \\' Zo\\', \\'Zoa\\', \\'oar\\', \\'ces\\', \\'6 Z\\', \\'Sti\\', \\'orj\\', \\'rje\\', \\'jew\\', \\'wi \\', \\' SG\\', \\'SG1\\', \\'G17\\', \\'-7 \\', \\'fan\\', \\'TGR\\', \\'GRG\\', \\'RGC\\', \\'Gas\\', \\' Pu\\', \\'Pun\\', \\'Ape\\', \\'s q\\', \\'pty\\', \\'dyb\\', \\'bow\\', \\'Hex\\', \\'xag\\', \\'DMA\\', \\'MA,\\', \\', i\\', \\'te:\\', \\'e: \\', \\': H\\', \\' HA\\', \\'HA-\\', \\'A-Y\\', \\'-YT\\', \\'YT-\\', \\'T-2\\', \\'12\\\\n\\', \\'2\\\\nG\\', \\'ump\\', \\'16N\\', \\'6NC\\', \\'NCL\\', \\'CLU\\', \\'LU3\\', \\'U34\\', \\'Myo\\', \\'yox\\', \\'xoc\\', \\'Cot\\', \\'b C\\', \\' Cb\\', \\'Cba\\', \\'ii_\\', \\'onf\\', \\'nfu\\', \\'fus\\', \\'usu\\', \\'kla\\', \\'olk\\', \\'lki\\', \\' CV\\', \\'CVO\\', \\'VO4\\', \\'O45\\', \\'det\\', \\'rme\\', \\'Ble\\', \\'tim\\', \\'Bou\\', \\'oul\\', \\'Typ\\', \\'phl\\', \\'Der\\', \\'And\\', \\'dav\\', \\'913\\', \\'Hyn\\', \\'kim\\', \\'CIB\\', \\'IB-\\', \\'B-X\\', \\'-XM\\', \\'XM3\\', \\'M31\\', \\'elp\\', \\'lpa\\', \\'pae\\', \\'330\\', \\'hyh\\', \\'yhy\\', \\'ngc\\', \\'gch\\', \\'Ran\\', \\'sib\\', \\'ibi\\', \\'bir\\', \\'key\\', \\'eys\\', \\'rli\\', \\'sli\\', \\'680\\', \\'Gyr\\', \\' Gp\\', \\'Gpa\\', \\'-67\\', \\'Ane\\', \\'GNA\\', \\'NAC\\', \\'GNT\\', \\'Des\\', \\'esm\\', \\'mog\\', \\'Ens\\', \\'nsa\\', \\' es\\', \\'chs\\', \\'hsc\\', \\'olt\\', \\'ltz\\', \\'289\\', \\'Pha\\', \\'hti\\', \\'hya\\', \\'bys\\', \\'yci\\', \\'asa\\', \\'fi \\', \\'871\\', \\'dob\\', \\'ogi\\', \\'sot\\', \\'ngk\\', \\'gko\\', \\'kon\\', \\'Aly\\', \\'lyt\\', \\'bst\\', \\':96\\', \\'Fej\\', \\'jer\\', \\'rva\\', \\'r z\\', \\' zj\\', \\'zjb\\', \\'jbj\\', \\'bj3\\', \\'j3 \\', \\':73\\', \\'3-8\\', \\'-89\\', \\'1 X\\', \\' Xe\\', \\'Xen\\', \\'368\\', \\':80\\', \\'0-9\\', \\'-96\\', \\'Hyl\\', \\'axy\\', \\'yru\\', \\'841\\', \\'Buf\\', \\'ufo\\', \\'fo \\', \\'riz\\', \\'iza\\', \\'882\\', \\'2-9\\', \\'fot\\', \\'zam\\', \\'amd\\', \\'mda\\', \\'add\\', \\'dde\\', \\':69\\', \\'-84\\', \\'ohy\\', \\'Pyx\\', \\' ad\\', \\'dsp\\', \\'hly\\', \\'lyc\\', \\'xad\\', \\'rke\\', \\'aih\\', \\'eim\\', \\'Amo\\', \\'ntz\\', \\'tzo\\', \\'zor\\', \\'esb\\', \\'bei\\', \\' Od\\', \\'Odo\\', \\'aha\\', \\'bed\\', \\'edr\\', \\'iag\\', \\'e G\\', \\' GM\\', \\'GM-\\', \\'M-J\\', \\'-J0\\', \\'J01\\', \\':85\\', \\'e M\\', \\' MP\\', \\'MPF\\', \\'PFC\\', \\'FC1\\', \\'C13\\', \\':79\\', \\'ony\\', \\'nyx\\', \\'ubl\\', \\'Ema\\', \\'ac3\\', \\'c3 \\', \\'Cyr\\', \\'rto\\', \\'Gek\\', \\'ekk\\', \\'kko\\', \\'hok\\', \\'kou\\', \\'oue\\', \\'gec\\', \\'eck\\', \\'cko\\', \\'noe\\', \\'oei\\', \\'888\\', \\'835\\', \\'n e\\', \\'Asp\\', \\'exs\\', \\'xsa\\', \\' AS\\', \\'ASH\\', \\'SH0\\', \\'H07\\', \\'SH1\\', \\'H14\\', \\'824\\', \\'exl\\', \\'xli\\', \\' KL\\', \\'KLC\\', \\'LC1\\', \\'C15\\', \\'r A\\', \\' AK\\', \\'AKL\\', \\'KL2\\', \\'L28\\', \\'osk\\', \\' UJ\\', \\'UJ-\\', \\'J-L\\', \\'-La\\', \\'ac-\\', \\'c-0\\', \\'-04\\', \\'Ere\\', \\'Dar\\', \\'evs\\', \\'vsk\\', \\'rko\\', \\'erj\\', \\'rju\\', \\'jug\\', \\'arv\\', \\'rvu\\', \\'rud\\', \\'rta\\', \\'Pod\\', \\'243\\', \\':51\\', \\'-66\\', \\'Bas\\', \\'LB1\\', \\'B18\\', \\' Ig\\', \\'Igu\\', \\'wis\\', \\'liz\\', \\'ize\\', \\'Sce\\', \\'occ\\', \\' Ut\\', \\'Uta\\', \\'nsb\\', \\'sbu\\', \\'UWB\\', \\'WBM\\', \\'BM \\', \\' 76\\', \\'2-8\\', \\'Boa\\', \\'Pyt\\', \\'1 V\\', \\' Vi\\', \\'Vip\\', \\'Dab\\', \\'boi\\', \\'oia\\', \\' Ag\\', \\'Agk\\', \\'gki\\', \\'civ\\', \\'ivo\\', \\'vor\\', \\'Sis\\', \\'Ner\\', \\'lub\\', \\' PC\\', \\'PCC\\', \\'CCI\\', \\'CI_\\', \\'I_R\\', \\'_R4\\', \\'R4 \\', \\'Ort\\', \\'Emy\\', \\' ij\\', \\'iji\\', \\'jim\\', \\' EI\\', \\'EIJ\\', \\'IJ \\', \\'J m\\', \\'viu\\', \\'912\\', \\'sub\\', \\'ruf\\', \\'ufa\\', \\'fa \\', \\'384\\', \\'Els\\', \\'lse\\', \\'sey\\', \\'eya\\', \\'lb_\\', \\'b_1\\', \\'_18\\', \\'Eld\\', \\'n_2\\', \\'_25\\', \\'Elu\\', \\' MR\\', \\'MRT\\', \\'RT4\\', \\'T4 \\', \\'ydu\\', \\'ac_\\', \\'c_A\\', \\'_AA\\', \\'AA3\\', \\'A33\\', \\'vic\\', \\'Emv\\', \\'mvi\\', \\'ic_\\', \\'c_2\\', \\'_24\\', \\'Myu\\', \\'yuc\\', \\'ely\\', \\'Myb\\', \\'ybe\\', \\'el_\\', \\'l_1\\', \\'_17\\', \\'emy\\', \\'r P\\', \\'um_\\', \\'m_A\\', \\'AA6\\', \\'A65\\', \\'nsc\\', \\'lpt\\', \\'Apa\\', \\'iun\\', \\'198\\', \\'lyd\\', \\'ydr\\', \\'GG-\\', \\'G-0\\', \\'01L\\', \\'1Lo\\', \\'Nat\\', \\'dep\\', \\'rou\\', \\'oup\\', \\'up \\', \\'p A\\', \\'Au \\', \\'u (\\', \\' (X\\', \\'(X)\\', \\'X) \\', \\') m\\', \\'yda\\', \\'etm\\', \\'tmo\\', \\':93\\', \\'gac\\', \\'3.3\\', \\'.3:\\', \\'3:5\\', \\' Gr\\', \\'Gra\\', \\'uac\\', \\'onc\\', \\'nin\\', \\'lda\\', \\'tea\\', \\'e e\\', \\'Psa\\', \\'Tes\\', \\'aec\\', \\'Mau\\', \\'Cai\\', \\'Pal\\', \\'suc\\', \\'peb\\', \\'856\\', \\'Gav\\', \\'get\\', \\'Tom\\', \\'8.2\\', \\'321\\', \\'joh\\', \\'ohn\\', \\'hns\\', \\'TAR\\', \\'ART\\', \\'RTC\\', \\'CTK\\', \\'TKC\\', \\'KCT\\', \\'CCY\\', \\'CYC\\', \\'AAY\\', \\'AYC\\', \\'YC\\\\n\\', \\'CTR\\', \\'TRA\\', \\'RAA\\', \\'Mec\\', \\'aem\\', \\'Rhe\\', \\' Dr\\', \\'Dro\\', \\'aiu\\', \\'vae\\', \\'aeh\\', \\'eho\\', \\'sua\\', \\' Nu\\', \\'Num\\', \\'eag\\', \\' 19\\', \\'pep\\', \\'epl\\', \\' sq\\', \\'Lag\\', \\'mut\\', \\'M 5\\', \\' 51\\', \\'pav\\', \\'avo\\', \\'vo \\', \\'591\\', \\'655\\', \\'olc\\', \\'Pav\\', \\' bG\\', \\'bGa\\', \\'alG\\', \\'lGa\\', \\'al1\\', \\'l1 \\', \\'ce,\\', \\', w\\', \\' wh\\', \\'who\\', \\'sho\\', \\'otg\\', \\'tgu\\', \\'un \\', \\'huk\\', \\'uka\\', \\'nix\\', \\'aog\\', \\'lay\\', \\' TH\\', \\'THI\\', \\'HIM\\', \\'IM2\\', \\'M20\\', \\'hye\\', \\'yem\\', \\' RE\\', \\'REW\\', \\'EW5\\', \\'W53\\', \\' UA\\', \\'UAM\\', \\'AMX\\', \\'MX1\\', \\'X14\\', \\'Cyg\\', \\'gnu\\', \\'Ans\\', \\' Ay\\', \\'Ayt\\', \\'r J\\', \\' JS\\', \\'JS0\\', \\'S04\\', \\'Aix\\', \\'3 Z\\', \\'Zen\\', \\'nai\\', \\'our\\', \\'cao\\', \\'aoc\\', \\'to \\', \\'978\\', \\'hag\\', \\'see\\', \\'ccy\\', \\'cyx\\', \\'Ard\\', \\'rde\\', \\'deo\\', \\' Ot\\', \\'Oti\\', \\'Pso\\', \\'cre\\', \\'Gru\\', \\'Ant\\', \\'poi\\', \\'6 J\\', \\'Jac\\', \\' ST\\', \\'STR\\', \\'TRI\\', \\'RI:\\', \\'I:B\\', \\':BC\\', \\'BC3\\', \\'C33\\', \\'CCM\\', \\'MCC\\', \\'ACM\\', \\'mas\\', \\', p\\', \\'TNA\\', \\'NAA\\', \\'GNN\\', \\'NN\\\\n\\', \\'N\\\\nN\\', \\'\\\\nNN\\', \\'NNA\\', \\'NAG\\', \\'NAT\\', \\'2.2\\', \\'Are\\', \\'rpr\\', \\' JJ\\', \\'JJW\\', \\'JW1\\', \\'W11\\', \\'GCY\\', \\'CYA\\', \\'YAT\\', \\'pug\\', \\'ugn\\', \\'r D\\', \\' DD\\', \\'DDG\\', \\'DG1\\', \\'G19\\', \\'IN4\\', \\'N46\\', \\'Ony\\', \\'nyc\\', \\' NI\\', \\'NIB\\', \\'IBR\\', \\'RGR\\', \\'GR0\\', \\'R00\\', \\'sae\\', \\'Gel\\', \\'dib\\', \\'bun\\', \\'dom\\', \\'Ris\\', \\' MK\\', \\'MKP\\', \\'KP9\\', \\'P99\\', \\'0 v\\', \\' RO\\', \\'ROM\\', \\'OM:\\', \\'M:O\\', \\':OR\\', \\'ORN\\', \\'RN:\\', \\'N:1\\', \\'sit\\', \\'KP1\\', \\'P15\\', \\'9 v\\', \\'sku\\', \\'kua\\', \\'3 v\\', \\'ick\\', \\'Hae\\', \\'4 V\\', \\'Van\\', \\'van\\', \\'r 1\\', \\' 18\\', \\'-24\\', \\'voc\\', \\'oci\\', \\'Plu\\', \\'Aeg\\', \\'yps\\', \\'fum\\', \\' LG\\', \\'LGE\\', \\'GEM\\', \\'EMA\\', \\'MA \\', \\'Aer\\', \\'amu\\', \\'fuc\\', \\'Apu\\', \\'979\\', \\' ju\\', \\'jub\\', \\'899\\', \\'eip\\', \\' 15\\', \\'imm\\', \\'he \\', \\'Hyd\\', \\'Oce\\', \\'Apt\\', \\'old\\', \\'ldt\\', \\'Eud\\', \\'udy\\', \\'pua\\', \\' 12\\', \\':71\\', \\'-87\\', \\' Fr\\', \\'Fre\\', \\'Sul\\', \\'rex\\', \\'Bub\\', \\'ubu\\', \\'lcu\\', \\' Ny\\', \\'Nyc\\', \\'x n\\', \\' ny\\', \\' Ni\\', \\'Nip\\', \\'esk\\', \\'kio\\', \\'irc\\', \\'613\\', \\' Aq\\', \\'Aqu\\', \\'Acc\\', \\'ilv\\', \\'lvu\\', \\'IN1\\', \\'N15\\', \\'aee\\', \\'eet\\', \\'N17\\', \\'agy\\', \\' Vu\\', \\'Vul\\', \\'ltu\\', \\'ur \\', \\'gry\\', \\'Nin\\', \\'Asi\\', \\'o o\\', \\' ot\\', \\'IN8\\', \\'N83\\', \\'o f\\', \\'meu\\', \\'ubo\\', \\' D1\\', \\'D16\\', \\' X3\\', \\'X3 \\', \\'x u\\', \\' C5\\', \\'C5 \\', \\'Upu\\', \\'pup\\', \\'Ace\\', \\'ead\\', \\'adb\\', \\'390\\', \\'e r\\', \\'lcy\\', \\'cyo\\', \\'yon\\', \\' sm\\', \\'smy\\', \\'myr\\', \\'CMT\\', \\'MTA\\', \\'Pic\\', \\'pub\\', \\'Dry\\', \\'yoc\\', \\'4 J\\', \\' Jy\\', \\'Jyn\\', \\'ynx\\', \\'orq\\', \\'rqu\\', \\' Fa\\', \\'Fal\\', \\'o n\\', \\'aum\\', \\' bF\\', \\'bFa\\', \\'alN\\', \\'lNa\\', \\'au1\\', \\'u1 \\', \\'0 F\\', \\'nun\\', \\'Her\\', \\'cac\\', \\'-82\\', \\'Nes\\', \\'Nym\\', \\'Eol\\', \\'sei\\', \\'Cac\\', \\'tua\\', \\'cce\\', \\'aun\\', \\'una\\', \\'ogu\\', \\'ao \\', \\'Ama\\', \\'maz\\', \\'Myi\\', \\'yio\\', \\'For\\', \\'Psi\\', \\'ttr\\', \\'Aga\\', \\'hog\\', \\'ute\\', \\'sog\\', \\'Ecl\\', \\'eup\\', \\'Mio\\', \\' MJ\\', \\'MJM\\', \\'JM2\\', \\'Tyr\\', \\'sav\\', \\'Lan\\', \\'Cya\\', \\'e 7\\', \\'9.2\\', \\'awa\\', \\'aii\\', \\'iie\\', \\'SB3\\', \\'B33\\', \\'Phu\\', \\'ud-\\', \\'d-1\\', \\'Gar\\', \\'230\\', \\'psa\\', \\' B3\\', \\'B31\\', \\'MMN\\', \\'NH \\', \\'H 4\\', \\' 47\\', \\'e p\\', \\'CEH\\', \\'EH1\\', \\' PM\\', \\'PMO\\', \\'MON\\', \\'ON2\\', \\'N20\\', \\'04V\\', \\'4V1\\', \\'V1 \\', \\'e J\\', \\' J3\\', \\'J3 \\', \\'irp\\', \\'urb\\', \\'Tac\\', \\'eov\\', \\'olz\\', \\'lzm\\', \\'zma\\', \\'Hir\\', \\'cag\\', \\'o F\\', \\'Fie\\', \\'ld \\', \\'d M\\', \\'use\\', \\'m 4\\', \\' 46\\', \\'eox\\', \\'xen\\', \\' B-\\', \\'B-2\\', \\'-23\\', \\'32,\\', \\'2, \\', \\', L\\', \\'Lou\\', \\'oui\\', \\'a S\\', \\'Sta\\', \\'e U\\', \\'ity\\', \\'ytl\\', \\'tle\\', \\' NB\\', \\'NB0\\', \\'B02\\', \\'ahi\\', \\'LSU\\', \\'SU \\', \\'U B\\', \\'B-6\\', \\'Rip\\', \\' SQ\\', \\'SQS\\', \\'QSW\\', \\'SW0\\', \\'W00\\', \\'Syl\\', \\'ylv\\', \\'Zos\\', \\' FL\\', \\'FLD\\', \\'LDO\\', \\'DO-\\', \\'O-T\\', \\'-TT\\', \\'TT0\\', \\'T04\\', \\'lly\\', \\'bit\\', \\'T01\\', \\'Fic\\', \\'ced\\', \\'Oen\\', \\'e o\\', \\' oe\\', \\' Tu\\', \\'Tur\\', \\'urd\\', \\' TM\\', \\'TME\\', \\'MER\\', \\'ER2\\', \\'R20\\', \\'4V3\\', \\'V3 \\', \\'ufi\\', \\'fiv\\', \\'MCP\\', \\'CP \\', \\'P 3\\', \\' 32\\', \\'Bup\\', \\' sv\\', \\'sv0\\', \\'v00\\', \\'Reg\\', \\'Tic\\', \\'pyl\\', \\'BRU\\', \\'RUN\\', \\'UN2\\', \\'yot\\', \\'lud\\', \\'dov\\', \\'Sit\\', \\'Pad\\', \\'dda\\', \\'ziv\\', \\'Pas\\', \\'Mot\\', \\'mea\\', \\'avu\\', \\'Him\\', \\'CGN\\', \\'NNC\\', \\'xop\\', \\'eom\\', \\'yza\\', \\'hou\\', \\'ous\\', \\'ucl\\', \\'Pir\\', \\'e k\\', \\'ku2\\', \\'u26\\', \\'ku7\\', \\'u70\\', \\'upi\\', \\'piz\\', \\'zel\\', \\'Zon\\', \\'kir\\', \\'irt\\', \\'rtl\\', \\'bad\\', \\'Age\\', \\'9 Q\\', \\'Qui\\', \\'0 Q\\', \\'Orn\\', \\'hyg\\', \\'ygl\\', \\'Did\\', \\' Ad\\', \\'Ada\\', \\'dam\\', \\'am \\', \\'m A\\', \\'t m\\', \\'6 I\\', \\'Iso\\', \\'soo\\', \\'Tar\\', \\'irs\\', \\'oep\\', \\'epu\\', \\'Myr\\', \\'yrm\\', \\' IS\\', \\'ISE\\', \\'SEM\\', \\'EM_\\', \\'M_T\\', \\'_T-\\', \\'Tam\\', \\'dua\\', \\'MVZ\\', \\'VZ_\\', \\'Z_1\\', \\'_19\\', \\'T-N\\', \\'-NP\\', \\'NP3\\', \\'P39\\', \\'Tol\\', \\'peu\\', \\'syp\\', \\'emc\\', \\'mci\\', \\'T-3\\', \\'afe\\', \\'gee\\', \\'ees\\', \\'ska\\', \\'ufe\\', \\'fes\\', \\'SMN\\', \\'MNS\\', \\'NS2\\', \\'S23\\', \\'elf\\', \\'lfa\\', \\'fai\\', \\'hec\\', \\' Du\\', \\'Dug\\', \\'ugo\\', \\'ng \\', \\'g d\\', \\'dug\\', \\'Sun\\', \\'Bla\\', \\'pim\\', \\'g m\\', \\'fod\\', \\'ndy\\', \\'yre\\', \\'0.2\\', \\'Eid\\', \\'elv\\', \\'vum\\', \\'Rou\\', \\' CK\\', \\'CKM\\', \\'KM1\\', \\'M10\\', \\'dag\\', \\'UAD\\', \\'ADB\\', \\'DBA\\', \\'BA-\\', \\'A-4\\', \\'-43\\', \\'Epo\\', \\'bue\\', \\'uet\\', \\'tik\\', \\'iko\\', \\'kof\\', \\'ofe\\', \\' G0\\', \\'G09\\', \\'09X\\', \\'9X3\\', \\' MZ\\', \\'MZF\\', \\'ZF1\\', \\'F10\\', \\'meq\\', \\'m q\\', \\'rsh\\', \\' GX\\', \\'GX0\\', \\'X07\\', \\'Mys\\', \\'r Q\\', \\' QC\\', \\'QCA\\', \\'CAZ\\', \\'AZ:\\', \\'Z:1\\', \\':18\\', \\'ifu\\', \\'fug\\', \\'ugu\\', \\'myo\\', \\'CWT\\', \\'WTC\\', \\'GAR\\', \\'ARG\\', \\'CY\\\\n\\', \\'Y\\\\nG\\', \\'GCM\\', \\'GGY\\', \\'GYA\\', \\'GGS\\', \\'GST\\', \\'STG\\', \\'RAC\\', \\'ACW\\', \\'CWG\\', \\'WGT\\', \\'GTW\\', \\'TWT\\', \\'WTA\\', \\'YCC\\', \\'CCW\\', \\'WCT\\', \\'CTW\\', \\'TWG\\', \\'WGC\\', \\'CRG\\', \\'RGG\\', \\'GGW\\', \\'GWA\\', \\'WAA\\', \\'CAY\\', \\'AYG\\', \\'YGC\\', \\'MGT\\', \\'WGA\\', \\'YCT\\', \\'TYR\\', \\'YRC\\', \\'RCW\\', \\'CWA\\', \\'WAT\\', \\'TCY\\', \\'GKG\\', \\'KGT\\', \\'CAR\\', \\'RTY\\', \\'TYA\\', \\'YAA\\', \\'CYG\\', \\'YGG\\', \\'AAR\\', \\'ARA\\', \\'RGA\\', \\'GWT\\', \\'ATR\\', \\'TRG\\', \\'GTD\\', \\'TDT\\', \\'DTG\\', \\'TRK\\', \\'RKC\\', \\'KCW\\', \\'YTY\\', \\'GTM\\', \\'TMT\\', \\'MTG\\', \\'RTT\\', \\'WGG\\', \\'YGT\\', \\'AY\\\\n\\', \\'Y\\\\nA\\', \\'CGW\\', \\'CYT\\', \\'ACR\\', \\'CRT\\', \\'ATY\\', \\'WAC\\', \\'TM\\\\n\\', \\'M\\\\nT\\', \\'YTK\\', \\'TKG\\', \\'KGC\\', \\'MCT\\', \\'TTR\\', \\'ncy\\', \\'cyi\\', \\'Pip\\', \\'raf\\', \\'afi\\', \\'esq\\', \\'uii\\', \\'9 V\\', \\'Ves\\', \\'cr3\\', \\'r3 \\', \\'jav\\', \\' T2\\', \\'T29\\', \\'tad\\', \\' MT\\', \\'MT2\\', \\'T27\\', \\' GL\\', \\'GLC\\', \\'C14\\', \\'LC8\\', \\'C8 \\', \\'eof\\', \\'fel\\', \\'Unc\\', \\'moy\\', \\' on\\', \\'pum\\', \\'PMA\\', \\'l i\\', \\'CA \\', \\'ail\\', \\'LSE\\', \\'SE \\', \\'E m\\', \\'rof\\', \\' PA\\', \\'PAU\\', \\'AU \\', \\'U m\\', \\'Leo\\', \\'LPA\\', \\'PA \\', \\'wie\\', \\'ied\\', \\' LW\\', \\'LWI\\', \\'WI \\', \\'I m\\', \\'Lyn\\', \\' LC\\', \\'LCA\\', \\' ly\\', \\'lyn\\', \\' LY\\', \\'LYP\\', \\'YP \\', \\'P m\\', \\'x r\\', \\'ufu\\', \\'Pum\\', \\'yag\\', \\'gou\\', \\' HJ\\', \\'HJA\\', \\'JA \\', \\' PR\\', \\'PRU\\', \\'RU \\', \\' PV\\', \\'PVI\\', \\'VI \\', \\'Fel\\', \\'FCH\\', \\'CH \\', \\'H m\\', \\'Oto\\', \\'ul \\', \\'e O\\', \\' OM\\', \\'OMA\\', \\' FM\\', \\'FMA\\', \\' FN\\', \\'FNI\\', \\'NI \\', \\' FS\\', \\'FSI\\', \\'SI \\', \\'ntu\\', \\'g a\\', \\'ado\\', \\'dox\\', \\'oxu\\', \\'xur\\', \\'map\\', \\'Civ\\', \\'GNK\\', \\'NKC\\', \\'TCN\\', \\'NNG\\', \\'Viv\\', \\'CC8\\', \\'ahy\\', \\'yae\\', \\' BH\\', \\'BH_\\', \\'H_l\\', \\'_lo\\', \\'ve \\', \\'rza\\', \\'Ati\\', \\'Sur\\', \\'rox\\', \\'eoa\\', \\'e 0\\', \\' 01\\', \\'01P\\', \\'1PA\\', \\'PAN\\', \\'NT-\\', \\'6-A\\', \\'-An\\', \\'86_\\', \\'6_C\\', \\'_Ca\\', \\'CaA\\', \\'aAu\\', \\'8.4\\', \\'.4:\\', \\'4:5\\', \\'fam\\', \\'Cuo\\', \\'uon\\', \\'yca\\', \\'Spe\\', \\'8 V\\', \\' ze\\', \\'Urs\\', \\'7 U\\', \\'bet\\', \\'urs\\', \\'lge\\', \\'Mep\\', \\'r Y\\', \\' YP\\', \\'YP2\\', \\'P29\\', \\'uto\\', \\'Lon\\', \\'Enh\\', \\'nhy\\', \\'Aon\\', \\' 21\\', \\'OM1\\', \\'e 8\\', \\' 81\\', \\'YP1\\', \\'P1 \\', \\'0 I\\', \\'Gul\\', \\'MP4\\', \\'P41\\', \\'Tax\\', \\'xid\\', \\'axu\\', \\'xus\\', \\':77\\', \\'8-9\\', \\'-93\\', \\' MS\\', \\'MS2\\', \\'nsl\\', \\'Mir\\', \\'bod\\', \\'wed\\', \\'edd\\', \\'Cys\\', \\'rgh\\', \\'gha\\', \\'Pus\\', \\'enl\\', \\'nla\\', \\'5.3\\', \\'Eum\\', \\'Ota\\', \\' by\\', \\'byr\\', \\'hoo\\', \\'oke\\', \\'2 Z\\', \\'Zal\\', \\'1 Z\\', \\'wol\\', \\'aek\\', \\' NH\\', \\'NHM\\', \\'HMO\\', \\'MO:\\', \\'O:3\\', \\':30\\', \\' Eq\\', \\'Equ\\', \\'quu\\', \\'uus\\', \\'i q\\', \\'uag\\', \\'agg\\', \\'gga\\', \\'e Q\\', \\' QU\\', \\'QUA\\', \\'UAG\\', \\'GA \\', \\'Tap\\', \\'mum\\', \\'Vic\\', \\'cug\\', \\'Sus\\', \\'Pec\\', \\'i t\\', \\'taj\\', \\'jac\\', \\'cu \\', \\'nap\\', \\'BRM\\', \\'RMM\\', \\'MM0\\', \\'M00\\', \\' 14\\', \\'BS_\\', \\'S_0\\', \\'TNN\\', \\'TYG\\', \\'Sou\\', \\'oal\\', \\'e z\\', \\' z0\\', \\'z00\\', \\'CNC\\', \\' SR\\', \\'SRR\\', \\'RR1\\', \\'R16\\', \\'Lip\\', \\'vex\\', \\'ffr\\', \\'Pon\\', \\'4 Z\\', \\' Zi\\', \\'Zip\\', \\' SW\\', \\'SWF\\', \\'WFS\\', \\'FSC\\', \\'SC \\', \\'C I\\', \\' ID\\', \\'ID \\', \\'D z\\', \\'Gan\\', \\'es_\\', \\'s_R\\', \\'_Ri\\', \\'Riv\\', \\'er_\\', \\'r_D\\', \\'_Do\\', \\'olp\\', \\'in-\\', \\'n-S\\', \\'-S1\\', \\'S1 \\', \\'Kog\\', \\'eal\\', \\'cet\\', \\'lib\\', \\' CY\\', \\'YTO\\', \\'TO \\', \\'O m\\', \\'ffa\\', \\'Waz\\', \\'kap\\', \\'19F\\', \\'9FC\\', \\'C01\\', \\'n y\\', \\'yak\\', \\'aku\\', \\'Dam\\', \\'Mun\\', \\'mun\\', \\'ntj\\', \\'jak\\', \\'ak \\', \\'k m\\', \\'eev\\', \\'Rus\\', \\'4.3\\', \\' sw\\', \\'swi\\', \\'nho\\', \\'gif\\', \\':38\\', \\'TR\\\\n\\', \\'R\\\\nC\\', \\'CRA\\', \\'Alc\\', \\'lce\\', \\'Kaz\\', \\'zak\\', \\'akh\\', \\'khs\\', \\'hst\\', \\'Mos\\', \\'rez\\', \\'ezo\\', \\'zov\\', \\'ovs\\', \\' PH\\', \\'PHC\\', \\'HC1\\', \\'C11\\', \\'caf\\', \\'Bis\\', \\'0.3\\', \\'3:6\\', \\'aze\\', \\' AW\\', \\'AWW\\', \\'WWP\\', \\'WP \\', \\'ubg\\', \\'bgu\\', \\'PhC\\', \\'hC1\\', \\'C1 \\', \\'oms\\', \\'Sai\\', \\' KO\\', \\'KOL\\', \\'OLN\\', \\'LN \\', \\'N m\\', \\'Mad\\', \\'doq\\', \\'oqu\\', \\'irk\\', \\' SU\\', \\'SUN\\', \\'UN \\', \\' CA\\', \\'AR3\\', \\'R35\\', \\'fil\\', \\'th \\', \\'Red\\', \\'dun\\', \\'lvo\\', \\'C12\\', \\'Aep\\', \\'pyc\\', \\'hC2\\', \\' Ov\\', \\'Ovi\\', \\'vib\\', \\'ibo\\', \\'e V\\', \\' V0\\', \\'V07\\', \\'bex\\', \\'e h\\', \\' h7\\', \\'h77\\', \\'spu\\', \\'eam\\', \\'Rup\\', \\'ACY\\', \\' B8\\', \\'B8-\\', \\'-6 \\', \\'e Z\\', \\' ZA\\', \\'ZA4\\', \\'A41\\', \\'Add\\', \\' VZ\\', \\'VZ \\', \\'Z m\\', \\' gn\\', \\'u i\\', \\'UN6\\', \\'N61\\', \\'UN7\\', \\'N70\\', \\'Fuk\\', \\'uko\\', \\'kom\\', \\'Cav\\', \\' UF\\', \\'UF:\\', \\'F:3\\', \\'oyp\\', \\'deg\\', \\'Eli\\', \\'Gli\\', \\' av\\', \\'M33\\', \\'NM5\\', \\'M57\\', \\'TCR\\', \\'Gla\\', \\'M56\\', \\'4 U\\', \\' Ts\\', \\'Tst\\', \\'ri.\\', \\'i.#\\', \\'.#2\\', \\'#2 \\', \\' DZ\\', \\'DZT\\', \\'ZTM\\', \\'TM.\\', \\'M.8\\', \\'.87\\', \\'7 v\\', \\'DMN\\', \\'NS:\\', \\'S:M\\', \\':Ma\\', \\'Mam\\', \\'mm:\\', \\'m:1\\', \\' L1\\', \\'L19\\', \\'ece\\', \\'eml\\', \\'mli\\', \\'fib\\', \\'bi \\', \\'i 1\\', \\'21\\\\n\\', \\'1\\\\nA\\', \\'on_\\', \\'n_R\\', \\'_Ro\\', \\'Rod\\', \\'odL\\', \\'dL1\\', \\'L1_\\', \\'1_2\\', \\'_29\\', \\'5 v\\', \\'NEO\\', \\'EON\\', \\'01I\\', \\'1IH\\', \\'IHV\\', \\'HV \\', \\'V m\\', \\'CB1\\', \\'B1 \\', \\'TMY\\', \\'MYT\\', \\'YTR\\', \\'TMC\\', \\'TYY\\', \\'YYT\\', \\'TRC\\', \\'RCT\\', \\'YTM\\', \\'foc\\', \\'Ond\\', \\'AM:\\', \\'M:M\\', \\'m:8\\', \\'Cri\\', \\'dL2\\', \\'L2_\\', \\'2_2\\', \\'IHT\\', \\'HT \\', \\'FCR\\', \\'CR1\\', \\'R17\\', \\'76_\\', \\'6_M\\', \\'_MZ\\', \\'ZFC\\', \\'n G\\', \\' GS\\', \\'GS1\\', \\'S16\\', \\'16A\\', \\'6A1\\', \\'A1 \\', \\'1 s\\', \\'ck \\', \\'n B\\', \\' BW\\', \\'BW \\', \\'W s\\', \\'gmo\\', \\'Aco\\', \\'cah\\', \\' E0\\', \\'E03\\', \\'uic\\', \\'iby\\', \\'byc\\', \\'mom\\', \\'syl\\', \\'r V\\', \\' VN\\', \\'VN1\\', \\'maq\\', \\'aqu\\', \\'USB\\', \\'SB_\\', \\'B_M\\', \\'_MO\\', \\'MOZ\\', \\'OZ0\\', \\'Z05\\', \\'Lem\\', \\'emn\\', \\'Z00\\', \\'ymy\\', \\'omt\\', \\'mtu\\', \\' MN\\', \\'NHN\\', \\'HN-\\', \\'N-Z\\', \\'-ZM\\', \\'ZM-\\', \\'M-2\\', \\'CBG\\', \\'BGP\\', \\'GPR\\', \\'PR4\\', \\'R49\\', \\' TZ\\', \\'TZ2\\', \\'Z23\\', \\'rro\\', \\'HNV\\', \\'NVV\\', \\'VV2\\', \\'V20\\', \\'cou\\', \\'Pra\\', \\'aom\\', \\'MSP\\', \\'SP5\\', \\'P5 \\', \\'Ban\\', \\'Rat\\', \\'exu\\', \\'xul\\', \\' BN\\', \\'BN/\\', \\'N/S\\', \\'/Ss\\', \\'SsN\\', \\'sNH\\', \\'NHs\\', \\'Hsd\\', \\'sdM\\', \\'dMC\\', \\'MCW\\', \\'CW \\', \\'W m\\', \\' RT\\', \\'RT1\\', \\'T1 \\', \\'e t\\', \\'tow\\', \\'own\\', \\'wns\\', \\'i h\\', \\'ow \\', \\'w m\\', \\'Och\\', \\'Tup\\', \\'aia\\', \\'ZF8\\', \\'F89\\', \\'Dau\\', \\'aub\\', \\' AN\\', \\'ANJ\\', \\'NJZ\\', \\'JZ5\\', \\'Z5 \\', \\' KI\\', \\'KIB\\', \\'IBO\\', \\'BO7\\', \\'O7.\\', \\'7.9\\', \\'.9 \\', \\'ceb\\', \\'e 9\\', \\' 92\\', \\'20F\\', \\'0FA\\', \\'FAG\\', \\'AG \\', \\' mL\\', \\'mLe\\', \\'emC\\', \\'mCa\\', \\'at1\\', \\'t1 \\', \\'Var\\', \\'ANO\\', \\'NOS\\', \\'OSI\\', \\'SIB\\', \\'IB7\\', \\'B7 \\', \\'Lor\\', \\'syr\\', \\'hta\\', \\'goe\\', \\' FE\\', \\'FES\\', \\'ES5\\', \\'S50\\', \\'IDS\\', \\'DSM\\', \\'SM0\\', \\'M03\\', \\'Sag\\', \\'Aot\\', \\' JP\\', \\'JPB\\', \\'PB1\\', \\'B13\\', \\'4 v\\', \\'INP\\', \\'NPA\\', \\'PA:\\', \\'A:5\\', \\'cup\\', \\'upr\\', \\'Ceb\\', \\'Sap\\', \\'paj\\', \\'aju\\', \\'jus\\', \\' RV\\', \\'RVR\\', \\'VR1\\', \\'R19\\', \\'Ate\\', \\'roy\\', \\' KS\\', \\'KST\\', \\'TR5\\', \\'R5A\\', \\'5A \\', \\' TR\\', \\'TRO\\', \\'RO6\\', \\'O68\\', \\'A:7\\', \\'lou\\', \\'TR1\\', \\'GKA\\', \\'KAG\\', \\'TGK\\', \\'KAA\\', \\': M\\', \\'MRA\\', \\'RAD\\', \\'AD2\\', \\'D2\\\\n\\', \\'2\\\\nA\\', \\'Pap\\', \\'nub\\', \\' ea\\', \\'st \\', \\'dry\\', \\'yas\\', \\' aw\\', \\'was\\', \\'h:B\\', \\':BE\\', \\'BE9\\', \\'E97\\', \\'inx\\', \\'ypi\\', \\'ynd\\', \\'Gor\\'] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Prepare the data\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# Assuming 'Characteristic' is the column you want to predict\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Specify the columns you want to use for X\u001b[39;00m\n\u001b[0;32m     41\u001b[0m feature_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgc_content\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblast_score\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kmer_df\u001b[39m.\u001b[39mcolumns)  \u001b[39m# Add more features as needed\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m X \u001b[39m=\u001b[39m df[feature_columns]\n\u001b[0;32m     43\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mMod\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Replace with your target column\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[\\'>NC\\', \\'NC_\\', \\'C_0\\', \\'_03\\', \\'039\\', \\'399\\', \\'992\\', \\'929\\', \\'29.\\', \\'9.1\\', \\'.1:\\', \\'1:1\\', \\':16\\', \\'166\\', \\'668\\', \\'687\\', \\'87-\\', \\'7-1\\', \\'-19\\', \\'191\\', \\'911\\', \\'112\\', \\'12 \\', \\'2 A\\', \\' Ac\\', \\'Act\\', \\'cti\\', \\'tin\\', \\'ini\\', \\'nia\\', \\'ia \\', \\'a e\\', \\' eq\\', \\'equ\\', \\'qui\\', \\'uin\\', \\'ina\\', \\'na \\', \\'a m\\', \\' mi\\', \\'mit\\', \\'ito\\', \\'toc\\', \\'och\\', \\'cho\\', \\'hon\\', \\'ond\\', \\'ndr\\', \\'dri\\', \\'rio\\', \\'ion\\', \\'on,\\', \\'n, \\', \\', c\\', \\' co\\', \\'com\\', \\'omp\\', \\'mpl\\', \\'ple\\', \\'let\\', \\'ete\\', \\'te \\', \\'e g\\', \\' ge\\', \\'gen\\', \\'eno\\', \\'nom\\', \\'ome\\', \\'me\\\\n\\', \\'e\\\\nA\\', \\'\\\\nAT\\', \\'ATG\\', \\'TGA\\', \\'GAA\\', \\'AAT\\', \\'ATA\\', \\'TAA\\', \\'AAA\\', \\'ATT\\', \\'TTT\\', \\'TTA\\', \\'AAC\\', \\'ACT\\', \\'CTC\\', \\'TCG\\', \\'CGT\\', \\'GTT\\', \\'TTG\\', \\'GAG\\', \\'AGT\\', \\'GTA\\', \\'TAT\\', \\'TTC\\', \\'TCC\\', \\'CCA\\', \\'CAC\\', \\'CTA\\', \\'ATC\\', \\'TCA\\', \\'ACA\\', \\'CAA\\', \\'AAG\\', \\'AGA\\', \\'GAT\\', \\'CGG\\', \\'GGA\\', \\'CTT\\', \\'TA\\\\n\\', \\'A\\\\nT\\', \\'\\\\nTA\\', \\'TAG\\', \\'GTG\\', \\'TGT\\', \\'TGG\\', \\'AGG\\', \\'CCG\\', \\'GGT\\', \\'GGC\\', \\'GCA\\', \\'CAG\\', \\'AGC\\', \\'GCT\\', \\'GA\\\\n\\', \\'\\\\nTT\\', \\'TCT\\', \\'CTG\\', \\'TGC\\', \\'GCC\\', \\'CCC\\', \\'CCT\\', \\'TAC\\', \\'GGG\\', \\'GAC\\', \\'ACG\\', \\'CGA\\', \\'ACC\\', \\'CAT\\', \\'GTC\\', \\'TG\\\\n\\', \\'G\\\\nA\\', \\'\\\\nAC\\', \\'CGC\\', \\'TT\\\\n\\', \\'T\\\\nG\\', \\'\\\\nGG\\', \\'GCG\\', \\'AC\\\\n\\', \\'C\\\\nA\\', \\'\\\\nAA\\', \\'\\\\nGA\\', \\'C\\\\nT\\', \\'\\\\nTC\\', \\'G\\\\nG\\', \\'CC\\\\n\\', \\'C\\\\nC\\', \\'\\\\nCT\\', \\'CT\\\\n\\', \\'T\\\\nT\\', \\'A\\\\nC\\', \\'\\\\nCC\\', \\'GC\\\\n\\', \\'\\\\nCG\\', \\'A\\\\nA\\', \\'A\\\\nG\\', \\'\\\\nGC\\', \\'TC\\\\n\\', \\'\\\\nAG\\', \\'CG\\\\n\\', \\'G\\\\nC\\', \\'AA\\\\n\\', \\'C\\\\nG\\', \\'T\\\\nC\\', \\'T\\\\nA\\', \\'AG\\\\n\\', \\'\\\\nCA\\', \\'CA\\\\n\\', \\'G\\\\nT\\', \\'GG\\\\n\\', \\'\\\\nGT\\', \\'_00\\', \\'000\\', \\'009\\', \\'093\\', \\'933\\', \\'33.\\', \\'3.1\\', \\'1:3\\', \\':32\\', \\'326\\', \\'263\\', \\'63-\\', \\'3-5\\', \\'-57\\', \\'570\\', \\'708\\', \\'08 \\', \\'8 M\\', \\' Me\\', \\'Met\\', \\'etr\\', \\'tri\\', \\'rid\\', \\'idi\\', \\'diu\\', \\'ium\\', \\'um \\', \\'m s\\', \\' se\\', \\'sen\\', \\'eni\\', \\'nil\\', \\'ile\\', \\'le \\', \\'e m\\', \\'\\\\nTG\\', \\'GT\\\\n\\', \\'AT\\\\n\\', \\'_08\\', \\'080\\', \\'803\\', \\'035\\', \\'358\\', \\'58.\\', \\'8.1\\', \\'322\\', \\'221\\', \\'21-\\', \\'1-4\\', \\'-47\\', \\'479\\', \\'798\\', \\'98 \\', \\'8 P\\', \\' Pe\\', \\'Pel\\', \\'ela\\', \\'lag\\', \\'agi\\', \\'gia\\', \\'a n\\', \\' no\\', \\'noc\\', \\'oct\\', \\'til\\', \\'ilu\\', \\'luc\\', \\'uca\\', \\'ca \\', \\'e\\\\nC\\', \\'_01\\', \\'016\\', \\'164\\', \\'646\\', \\'466\\', \\'66.\\', \\'6.1\\', \\'1:2\\', \\':26\\', \\'268\\', \\'7-4\\', \\'-42\\', \\'426\\', \\'267\\', \\'67 \\', \\'7 C\\', \\' Ca\\', \\'Cas\\', \\'ass\\', \\'ssi\\', \\'sio\\', \\'iop\\', \\'ope\\', \\'pea\\', \\'ea \\', \\'a x\\', \\' xa\\', \\'xam\\', \\'ama\\', \\'mac\\', \\'ach\\', \\'cha\\', \\'han\\', \\'ana\\', \\'e\\\\nT\\', \\'161\\', \\'611\\', \\'117\\', \\'17.\\', \\'7.1\\', \\':1-\\', \\'1-1\\', \\'-15\\', \\'152\\', \\'524\\', \\'24 \\', \\'4 M\\', \\' Mn\\', \\'Mne\\', \\'nem\\', \\'emi\\', \\'mio\\', \\'ops\\', \\'psi\\', \\'sis\\', \\'is \\', \\'s l\\', \\' le\\', \\'lei\\', \\'eid\\', \\'idy\\', \\'dyi\\', \\'yi \\', \\'i m\\', \\'014\\', \\'145\\', \\'457\\', \\'578\\', \\'78.\\', \\'1:7\\', \\':7-\\', \\'155\\', \\'551\\', \\'51 \\', \\'1 S\\', \\' Sy\\', \\'Sym\\', \\'yms\\', \\'msa\\', \\'sag\\', \\'git\\', \\'itt\\', \\'tti\\', \\'tif\\', \\'ife\\', \\'fer\\', \\'era\\', \\'ra \\', \\'a r\\', \\' ro\\', \\'ros\\', \\'osc\\', \\'sco\\', \\'cof\\', \\'off\\', \\'ffe\\', \\'fen\\', \\'ens\\', \\'nsi\\', \\'s m\\', \\'010\\', \\'104\\', \\'048\\', \\'484\\', \\'84.\\', \\'4.1\\', \\'1 B\\', \\' Br\\', \\'Bra\\', \\'rac\\', \\'chi\\', \\'hio\\', \\'onu\\', \\'nus\\', \\'us \\', \\'s p\\', \\' pl\\', \\'pli\\', \\'lic\\', \\'ica\\', \\'cat\\', \\'ati\\', \\'ili\\', \\'lis\\', \\'on \\', \\'n p\\', \\' pa\\', \\'par\\', \\'art\\', \\'rt \\', \\'t I\\', \\' II\\', \\'II,\\', \\'I, \\', \\'001\\', \\'163\\', \\'636\\', \\'36.\\', \\'154\\', \\'548\\', \\'48 \\', \\'8 K\\', \\' Ka\\', \\'Kat\\', \\'ath\\', \\'tha\\', \\'har\\', \\'ari\\', \\'rin\\', \\'a t\\', \\' tu\\', \\'tun\\', \\'uni\\', \\'nic\\', \\'ata\\', \\'ta \\', \\'GCN\\', \\'CN\\\\n\\', \\'N\\\\nG\\', \\'_02\\', \\'026\\', \\'685\\', \\'850\\', \\'50.\\', \\'0.1\\', \\'153\\', \\'533\\', \\'33 \\', \\'3 C\\', \\' Cr\\', \\'Cry\\', \\'ryp\\', \\'ypt\\', \\'pto\\', \\'hit\\', \\'ton\\', \\'n s\\', \\' st\\', \\'ste\\', \\'tel\\', \\'ell\\', \\'lle\\', \\'ler\\', \\'eri\\', \\'ri \\', \\'007\\', \\'072\\', \\'723\\', \\'234\\', \\'34.\\', \\':14\\', \\'141\\', \\'410\\', \\'105\\', \\'05-\\', \\'5-1\\', \\'156\\', \\'561\\', \\'617\\', \\'17 \\', \\'7 P\\', \\' Pl\\', \\'Pla\\', \\'lac\\', \\'aco\\', \\'cop\\', \\'pec\\', \\'ect\\', \\'cte\\', \\'ten\\', \\'en \\', \\'n m\\', \\' ma\\', \\'mag\\', \\'age\\', \\'gel\\', \\'lla\\', \\'lan\\', \\'ani\\', \\'icu\\', \\'cus\\', \\'027\\', \\'279\\', \\'794\\', \\'943\\', \\'43.\\', \\'-16\\', \\'160\\', \\'602\\', \\'02 \\', \\' Ar\\', \\'Arg\\', \\'rgo\\', \\'gop\\', \\' pu\\', \\'pur\\', \\'urp\\', \\'rpu\\', \\'ura\\', \\'rat\\', \\'atu\\', \\'tus\\', \\'_06\\', \\'061\\', \\'174\\', \\'741\\', \\'41.\\', \\'1.1\\', \\'260\\', \\'604\\', \\'04-\\', \\'4-4\\', \\'-41\\', \\'412\\', \\'127\\', \\'27 \\', \\'7 M\\', \\' Mi\\', \\'Mim\\', \\'ima\\', \\'chl\\', \\'hla\\', \\'lam\\', \\'amy\\', \\'mys\\', \\'ys \\', \\'s v\\', \\' va\\', \\'var\\', \\'ria\\', \\'012\\', \\'276\\', \\'76.\\', \\':15\\', \\'559\\', \\'598\\', \\'98-\\', \\'8-1\\', \\'-17\\', \\'171\\', \\'711\\', \\'115\\', \\'15 \\', \\'5 C\\', \\'Cra\\', \\'ras\\', \\'sso\\', \\'sos\\', \\'ost\\', \\'str\\', \\'tre\\', \\'rea\\', \\'a g\\', \\' gi\\', \\'gig\\', \\'iga\\', \\'gas\\', \\'as \\', \\'618\\', \\'180\\', \\'80.\\', \\'566\\', \\'66 \\', \\'6 O\\', \\' Os\\', \\'Ost\\', \\' ed\\', \\'edu\\', \\'dul\\', \\'uli\\', \\'277\\', \\'772\\', \\'724\\', \\'24.\\', \\'165\\', \\'656\\', \\'56 \\', \\'6 S\\', \\' Sa\\', \\'Sac\\', \\'acc\\', \\'cco\\', \\'cos\\', \\'a c\\', \\' cu\\', \\'cuc\\', \\'ucu\\', \\'cul\\', \\'ull\\', \\'lat\\', \\'064\\', \\'641\\', \\'413\\', \\'131\\', \\'31.\\', \\'605\\', \\'05 \\', \\'5 B\\', \\'hid\\', \\'ido\\', \\'don\\', \\'ont\\', \\'nte\\', \\'tes\\', \\'es \\', \\' ph\\', \\'pha\\', \\'ara\\', \\'rao\\', \\'aon\\', \\'oni\\', \\'nis\\', \\'s i\\', \\' is\\', \\'iso\\', \\'sol\\', \\'ola\\', \\'ate\\', \\'e B\\', \\' BR\\', \\'BRS\\', \\'RS_\\', \\'S_A\\', \\'_A \\', \\'A m\\', \\'619\\', \\'190\\', \\'903\\', \\'03.\\', \\'1:5\\', \\':52\\', \\'529\\', \\'294\\', \\'94-\\', \\'4-6\\', \\'-68\\', \\'689\\', \\'895\\', \\'95 \\', \\'5 G\\', \\' Ge\\', \\'Geu\\', \\'euk\\', \\'uke\\', \\'ken\\', \\'sia\\', \\'a d\\', \\' de\\', \\'dem\\', \\'mis\\', \\'iss\\', \\'ssa\\', \\'sa \\', \\'a v\\', \\' vo\\', \\'vou\\', \\'ouc\\', \\'uch\\', \\'che\\', \\'her\\', \\'er \\', \\'r W\\', \\' WA\\', \\'WAM\\', \\'AM \\', \\'M 7\\', \\' 70\\', \\'706\\', \\'640\\', \\'40 \\', \\'0 m\\', \\'015\\', \\'159\\', \\'599\\', \\'993\\', \\'93.\\', \\'1:9\\', \\':90\\', \\'905\\', \\'051\\', \\'51-\\', \\'-10\\', \\'107\\', \\'070\\', \\'06 \\', \\'6 M\\', \\' My\\', \\'Myt\\', \\'yti\\', \\'lus\\', \\'s c\\', \\' ca\\', \\'cal\\', \\'ali\\', \\'lif\\', \\'ifo\\', \\'for\\', \\'orn\\', \\'rni\\', \\'ian\\', \\'anu\\', \\'006\\', \\'068\\', \\'688\\', \\'886\\', \\'86.\\', \\'6.2\\', \\'.2:\\', \\'2:9\\', \\'906\\', \\'68-\\', \\'073\\', \\'732\\', \\'32 \\', \\'2 M\\', \\'s g\\', \\' ga\\', \\'gal\\', \\'all\\', \\'llo\\', \\'lop\\', \\'opr\\', \\'pro\\', \\'rov\\', \\'ovi\\', \\'vin\\', \\'inc\\', \\'nci\\', \\'cia\\', \\'ial\\', \\'076\\', \\'768\\', \\'87.\\', \\':12\\', \\'122\\', \\'222\\', \\'229\\', \\'29-\\', \\'9-1\\', \\'-13\\', \\'138\\', \\'388\\', \\'884\\', \\'84 \\', \\'s t\\', \\' tr\\', \\'tro\\', \\'oss\\', \\'ssu\\', \\'sul\\', \\'ulu\\', \\'GGN\\', \\'GNG\\', \\'NGT\\', \\'018\\', \\'183\\', \\'836\\', \\'362\\', \\'62.\\', \\'2.1\\', \\'124\\', \\'245\\', \\'450\\', \\'50-\\', \\'0-1\\', \\'139\\', \\'398\\', \\'985\\', \\'85 \\', \\'5 P\\', \\'Per\\', \\'ern\\', \\'rna\\', \\' vi\\', \\'vir\\', \\'iri\\', \\'dis\\', \\'262\\', \\'628\\', \\'288\\', \\'88.\\', \\'565\\', \\'654\\', \\'54-\\', \\'4-1\\', \\'172\\', \\'728\\', \\'282\\', \\'82 \\', \\'2 P\\', \\'a p\\', \\' pe\\', \\'per\\', \\'e\\\\nG\\', \\'_05\\', \\'054\\', \\'542\\', \\'424\\', \\'242\\', \\'42.\\', \\'144\\', \\'444\\', \\'447\\', \\'47-\\', \\'600\\', \\'003\\', \\'03 \\', \\'3 P\\', \\'can\\', \\'nal\\', \\'069\\', \\'690\\', \\'060\\', \\'60.\\', \\'564\\', \\'64 \\', \\'ise\\', \\'sep\\', \\'ept\\', \\'pta\\', \\'irg\\', \\'rga\\', \\'gat\\', \\'022\\', \\'228\\', \\'284\\', \\'846\\', \\'46.\\', \\':55\\', \\'595\\', \\'95-\\', \\'5-7\\', \\'-71\\', \\'717\\', \\'175\\', \\'75 \\', \\'5 L\\', \\' La\\', \\'Lat\\', \\'ter\\', \\'rnu\\', \\'nul\\', \\'ula\\', \\'la \\', \\' el\\', \\'lli\\', \\'lip\\', \\'ipt\\', \\'pti\\', \\'tic\\', \\'357\\', \\'572\\', \\'28.\\', \\'61 \\', \\'1 C\\', \\' Ce\\', \\'Cer\\', \\'ast\\', \\'sto\\', \\'tod\\', \\'ode\\', \\'der\\', \\'erm\\', \\'rma\\', \\'ma \\', \\'ule\\', \\'e i\\', \\'e C\\', \\'Ced\\', \\'du.\\', \\'u.1\\', \\'.11\\', \\'11.\\', \\'.16\\', \\'16.\\', \\'6.N\\', \\'.N0\\', \\'N01\\', \\'01.\\', \\'1.0\\', \\'.02\\', \\'22 \\', \\'2 m\\', \\'\\\\nT\\\\n\\', \\'050\\', \\'506\\', \\'683\\', \\'83.\\', \\':24\\', \\'249\\', \\'49-\\', \\'-18\\', \\'186\\', \\'865\\', \\'65 \\', \\'5 T\\', \\' Tr\\', \\'Tri\\', \\'ida\\', \\'dac\\', \\'acn\\', \\'cna\\', \\'359\\', \\'85.\\', \\'5.1\\', \\':75\\', \\'750\\', \\'509\\', \\'09-\\', \\'9-9\\', \\'-92\\', \\'921\\', \\'218\\', \\'18 \\', \\'8 D\\', \\' Do\\', \\'Don\\', \\'ona\\', \\'nax\\', \\'ax \\', \\'x t\\', \\'tru\\', \\'run\\', \\'unc\\', \\'ncu\\', \\'987\\', \\':74\\', \\'740\\', \\'409\\', \\'-91\\', \\'118\\', \\'x v\\', \\'vit\\', \\'tta\\', \\'tat\\', \\'_04\\', \\'046\\', \\'465\\', \\'651\\', \\'519\\', \\'19.\\', \\'554\\', \\'54 \\', \\'4 L\\', \\' Li\\', \\'Lim\\', \\'ime\\', \\'mec\\', \\'eco\\', \\'col\\', \\'a b\\', \\' ba\\', \\'bal\\', \\'alt\\', \\'lth\\', \\'thi\\', \\'hic\\', \\'024\\', \\'247\\', \\'473\\', \\'738\\', \\'38.\\', \\'755\\', \\'55 \\', \\'5 M\\', \\'Mya\\', \\'ya \\', \\'a a\\', \\' ar\\', \\'are\\', \\'ren\\', \\'ena\\', \\'nar\\', \\'227\\', \\'270\\', \\'709\\', \\'09.\\', \\':33\\', \\'331\\', \\'315\\', \\'15-\\', \\'5-4\\', \\'-49\\', \\'498\\', \\'5 A\\', \\'Arc\\', \\'rct\\', \\'a i\\', \\'isl\\', \\'sla\\', \\'and\\', \\'ndi\\', \\'dic\\', \\' po\\', \\'pop\\', \\'op-\\', \\'p-v\\', \\'-va\\', \\'ant\\', \\'nt \\', \\'t 2\\', \\' 27\\', \\'766\\', \\'663\\', \\'63 \\', \\'3 m\\', \\'464\\', \\'10.\\', \\'614\\', \\'14 \\', \\'4 C\\', \\' Co\\', \\'Cor\\', \\'orb\\', \\'rbi\\', \\'bic\\', \\'a f\\', \\' fl\\', \\'flu\\', \\'lum\\', \\'umi\\', \\'min\\', \\'ine\\', \\'nea\\', \\'038\\', \\'380\\', \\'806\\', \\'063\\', \\'63.\\', \\'608\\', \\'Dos\\', \\'osi\\', \\'sin\\', \\'a j\\', \\' ja\\', \\'jap\\', \\'apo\\', \\'pon\\', \\'848\\', \\'487\\', \\':21\\', \\'210\\', \\'109\\', \\'9-3\\', \\'-36\\', \\'367\\', \\'677\\', \\'77 \\', \\'Mer\\', \\'erc\\', \\'rce\\', \\'cen\\', \\' me\\', \\'mer\\', \\'031\\', \\'313\\', \\'133\\', \\'332\\', \\'32.\\', \\'142\\', \\'427\\', \\'271\\', \\'71-\\', \\'989\\', \\'89 \\', \\'9 R\\', \\' Ru\\', \\'Rud\\', \\'udi\\', \\'dit\\', \\'ita\\', \\'tap\\', \\'ape\\', \\'pes\\', \\'phi\\', \\'hil\\', \\'ipp\\', \\'ppi\\', \\'pin\\', \\'aru\\', \\'rum\\', \\'m m\\', \\'AGY\\', \\'GYT\\', \\'YTT\\', \\'GGK\\', \\'GKT\\', \\'KTT\\', \\'GTR\\', \\'TRT\\', \\'RTG\\', \\'GTY\\', \\'TYT\\', \\'TTY\\', \\'YTG\\', \\'TGY\\', \\'YTA\\', \\'GGR\\', \\'GRA\\', \\'RAT\\', \\'GAY\\', \\'AYA\\', \\'YAC\\', \\'TAY\\', \\'AYT\\', \\'YTC\\', \\'575\\', \\'757\\', \\'57.\\', \\'716\\', \\'16 \\', \\'6 R\\', \\'s d\\', \\'dec\\', \\'ecu\\', \\'uss\\', \\'sat\\', \\'034\\', \\'348\\', \\'845\\', \\'45.\\', \\'539\\', \\'39 \\', \\'9 E\\', \\' Ec\\', \\'Ech\\', \\'chy\\', \\'hyr\\', \\'yri\\', \\'ide\\', \\'del\\', \\'men\\', \\'enz\\', \\'nzi\\', \\'zie\\', \\'ies\\', \\'esi\\', \\'sii\\', \\'ii \\', \\'i i\\', \\'e S\\', \\' SB\\', \\'SB1\\', \\'B11\\', \\'11 \\', \\'1 m\\', \\'545\\', \\'45 \\', \\' Cu\\', \\'Cum\\', \\'umb\\', \\'mbe\\', \\'ber\\', \\'erl\\', \\'rla\\', \\'dia\\', \\' mo\\', \\'mon\\', \\'ono\\', \\'nod\\', \\'odo\\', \\'nta\\', \\'e H\\', \\' H3\\', \\'H30\\', \\'301\\', \\'10 \\', \\'_07\\', \\'079\\', \\'796\\', \\'969\\', \\'691\\', \\'91.\\', \\' Ma\\', \\'Mar\\', \\'arg\\', \\'gar\\', \\'rit\\', \\'iti\\', \\'a l\\', \\' la\\', \\'lae\\', \\'aev\\', \\'evi\\', \\'vis\\', \\'r 2\\', \\' 20\\', \\'20 \\', \\'0 -\\', \\' - \\', \\'- M\\', \\' MM\\', \\'MMt\\', \\'Mt-\\', \\'t-t\\', \\'-tc\\', \\'tc0\\', \\'c01\\', \\'01 \\', \\'043\\', \\'438\\', \\'383\\', \\'mar\\', \\'r B\\', \\' B1\\', \\'B15\\', \\'55G\\', \\'5G \\', \\'G m\\', \\'500\\', \\'005\\', \\'056\\', \\'56.\\', \\' Am\\', \\'Amb\\', \\'mbl\\', \\'ble\\', \\'lem\\', \\'ema\\', \\' BI\\', \\'BIV\\', \\'IV2\\', \\'V24\\', \\'244\\', \\'448\\', \\'8 v\\', \\'r 0\\', \\' 06\\', \\'61T\\', \\'1TS\\', \\'TS \\', \\'S m\\', \\'013\\', \\'136\\', \\'365\\', \\'658\\', \\'42 \\', \\'2 Q\\', \\' Qu\\', \\'Qua\\', \\'uad\\', \\'adr\\', \\'dru\\', \\'rul\\', \\'a q\\', \\' qu\\', \\'qua\\', \\'044\\', \\'441\\', \\'411\\', \\'111\\', \\'5 U\\', \\' Un\\', \\'Uni\\', \\'nio\\', \\'io \\', \\'o b\\', \\' bo\\', \\'bon\\', \\'one\\', \\'nel\\', \\'lii\\', \\'i v\\', \\'r M\\', \\' MC\\', \\'MC2\\', \\'C28\\', \\'28 \\', \\'8 m\\', \\'030\\', \\'300\\', \\'73.\\', \\' Po\\', \\'Pot\\', \\'oto\\', \\'tom\\', \\'omi\\', \\'mid\\', \\'da \\', \\' li\\', \\'lit\\', \\'tto\\', \\'tor\\', \\'ora\\', \\'ral\\', \\'e P\\', \\' PL\\', \\'PL7\\', \\'L70\\', \\'702\\', \\'02F\\', \\'2F \\', \\'F m\\', \\'062\\', \\'287\\', \\'877\\', \\'77.\\', \\':39\\', \\'986\\', \\'86-\\', \\'6-5\\', \\'-55\\', \\'552\\', \\'527\\', \\'7 L\\', \\'Lam\\', \\'ame\\', \\'mel\\', \\'lid\\', \\'den\\', \\'ns \\', \\'rgi\\', \\'gin\\', \\'r C\\', \\' CI\\', \\'CIF\\', \\'IFE\\', \\'FEF\\', \\'EFG\\', \\'FGB\\', \\'GB-\\', \\'B-L\\', \\'-LM\\', \\'LM1\\', \\'M1 \\', \\'037\\', \\'374\\', \\'743\\', \\'431\\', \\'143\\', \\'434\\', \\'48-\\', \\'158\\', \\'588\\', \\'889\\', \\'9 A\\', \\' Al\\', \\'Ala\\', \\'las\\', \\'asm\\', \\'smi\\', \\'a h\\', \\' he\\', \\'het\\', \\'ero\\', \\'rod\\', \\'280\\', \\':53\\', \\'531\\', \\'316\\', \\'16-\\', \\'6-6\\', \\'857\\', \\'57 \\', \\'7 A\\', \\' An\\', \\'Ano\\', \\' an\\', \\'nat\\', \\'e 1\\', \\' 10\\', \\'106\\', \\'6 h\\', \\' ha\\', \\'hap\\', \\'apl\\', \\'plo\\', \\'lot\\', \\'oty\\', \\'typ\\', \\'ype\\', \\'pe \\', \\'e F\\', \\' F \\', \\'036\\', \\'364\\', \\'648\\', \\'488\\', \\'530\\', \\'308\\', \\'08-\\', \\'8-6\\', \\'684\\', \\'849\\', \\'49 \\', \\' cy\\', \\'cyg\\', \\'ygn\\', \\'gne\\', \\'057\\', \\'571\\', \\'12.\\', \\' Ps\\', \\'Pse\\', \\'seu\\', \\'eud\\', \\'uda\\', \\'dan\\', \\'ano\\', \\'pla\\', \\'IV0\\', \\'V01\\', \\'86 \\', \\'6 v\\', \\'6 m\\', \\'366\\', \\'661\\', \\'61.\\', \\':2-\\', \\'2-1\\', \\'540\\', \\'0 P\\', \\' Py\\', \\'Pyg\\', \\'yga\\', \\'gan\\', \\'n g\\', \\' gr\\', \\'gra\\', \\'ran\\', \\'494\\', \\'1:4\\', \\':49\\', \\'946\\', \\'46-\\', \\'-64\\', \\'87 \\', \\'7 S\\', \\' Si\\', \\'Sin\\', \\'nan\\', \\'a w\\', \\' wo\\', \\'woo\\', \\'ood\\', \\'odi\\', \\'201\\', \\'14-\\', \\'4-p\\', \\'-ph\\', \\'phc\\', \\'hc-\\', \\'c-s\\', \\'-si\\', \\'si-\\', \\'i-w\\', \\'-wo\\', \\'wo-\\', \\'o-0\\', \\'-00\\', \\'310\\', \\'339\\', \\'39-\\', \\'9-6\\', \\'892\\', \\'92 \\', \\'2 U\\', \\'o p\\', \\' pi\\', \\'pic\\', \\'ict\\', \\'cto\\', \\'oru\\', \\'356\\', \\'568\\', \\'682\\', \\'82.\\', \\':29\\', \\'295\\', \\'954\\', \\'-44\\', \\'489\\', \\'9 G\\', \\' Gi\\', \\'Gib\\', \\'ibb\\', \\'bbu\\', \\'bul\\', \\'a u\\', \\' um\\', \\'mbi\\', \\'bil\\', \\'059\\', \\'594\\', \\'940\\', \\'40.\\', \\'335\\', \\'352\\', \\'52-\\', \\'2-4\\', \\'-48\\', \\'893\\', \\'93 \\', \\'3 H\\', \\' Ha\\', \\'Hal\\', \\'lio\\', \\'iot\\', \\'oti\\', \\'tis\\', \\'s r\\', \\' ru\\', \\'rub\\', \\'ubr\\', \\'bra\\', \\'318\\', \\'189\\', \\':27\\', \\'273\\', \\'735\\', \\'35-\\', \\'428\\', \\'2 C\\', \\' Cl\\', \\'Cli\\', \\'ith\\', \\'tho\\', \\'n r\\', \\' re\\', \\'ret\\', \\'rop\\', \\'opi\\', \\'ctu\\', \\' CL\\', \\'CL2\\', \\'L24\\', \\'4 m\\', \\'458\\', \\'586\\', \\'536\\', \\'36 \\', \\'6 P\\', \\'Pom\\', \\'oma\\', \\'ace\\', \\'cea\\', \\'040\\', \\'094\\', \\'6 B\\', \\' Bu\\', \\'Buc\\', \\'ucc\\', \\'cci\\', \\'cin\\', \\'inu\\', \\'num\\', \\'m u\\', \\' un\\', \\'und\\', \\'nda\\', \\'dat\\', \\'tum\\', \\'705\\', \\'577\\', \\'ota\\', \\'tam\\', \\'amo\\', \\'mop\\', \\'opy\\', \\'pyr\\', \\'yrg\\', \\'rgu\\', \\'gus\\', \\'s a\\', \\'nti\\', \\'tip\\', \\'ipo\\', \\'pod\\', \\'oda\\', \\'dar\\', \\'058\\', \\'582\\', \\'827\\', \\'27.\\', \\':59\\', \\'59-\\', \\'603\\', \\'3 A\\', \\' Ap\\', \\'Apl\\', \\'ply\\', \\'lys\\', \\'ysi\\', \\'607\\', \\'98.\\', \\':10\\', \\'047\\', \\'471\\', \\'-11\\', \\'119\\', \\'199\\', \\'997\\', \\'97 \\', \\'7 B\\', \\'Bul\\', \\'lin\\', \\' gl\\', \\'glo\\', \\'lob\\', \\'obo\\', \\'bos\\', \\'osu\\', \\'sus\\', \\'BuG\\', \\'uGe\\', \\'Ge \\', \\'795\\', \\'95.\\', \\'19-\\', \\'-12\\', \\'120\\', \\'204\\', \\'045\\', \\'nca\\', \\'BuT\\', \\'uT \\', \\'T m\\', \\'088\\', \\'885\\', \\'852\\', \\'521\\', \\'21.\\', \\':58\\', \\'584\\', \\'843\\', \\'43-\\', \\'3-7\\', \\'-73\\', \\'355\\', \\'5 F\\', \\' Fe\\', \\'Fer\\', \\'err\\', \\'rri\\', \\'ris\\', \\' fr\\', \\'fra\\', \\'rag\\', \\'gil\\', \\'r F\\', \\'Fe2\\', \\'e2-\\', \\'2-e\\', \\'-e4\\', \\'e41\\', \\'41d\\', \\'1d4\\', \\'d4p\\', \\'4p2\\', \\'p2 \\', \\'543\\', \\'439\\', \\'39.\\', \\'474\\', \\'74-\\', \\'200\\', \\'00 \\', \\'0 B\\', \\' Bi\\', \\'Bio\\', \\'iom\\', \\'mph\\', \\'hal\\', \\'ala\\', \\'lar\\', \\'gla\\', \\'lab\\', \\'abr\\', \\'805\\', \\'59.\\', \\'041\\', \\'416\\', \\'6-1\\', \\'196\\', \\'963\\', \\'3 B\\', \\' pf\\', \\'pfe\\', \\'fei\\', \\'eif\\', \\'iff\\', \\'023\\', \\'232\\', \\'325\\', \\'253\\', \\'53.\\', \\' Ph\\', \\'Phy\\', \\'hys\\', \\'yse\\', \\'sel\\', \\' ac\\', \\'acu\\', \\'cut\\', \\'uta\\', \\'e A\\', \\' A \\', \\'90.\\', \\'8 S\\', \\' Su\\', \\'Suc\\', \\'put\\', \\'utr\\', \\'065\\', \\'657\\', \\'573\\', \\'731\\', \\'7 D\\', \\' Di\\', \\'Dis\\', \\'isc\\', \\'scu\\', \\'ers\\', \\'rsp\\', \\'spe\\', \\'tiv\\', \\'ivu\\', \\'vus\\', \\'r U\\', \\' UC\\', \\'UC0\\', \\'C06\\', \\'729\\', \\'54.\\', \\'big\\', \\'igo\\', \\'gol\\', \\'oli\\', \\'lim\\', \\'max\\', \\'val\\', \\'ale\\', \\'len\\', \\'ent\\', \\'tia\\', \\'47.\\', \\'30 \\', \\'0 H\\', \\' He\\', \\'Hel\\', \\'eli\\', \\'lix\\', \\'ix \\', \\'x p\\', \\'pom\\', \\'mat\\', \\'r R\\', \\' RM\\', \\'RMN\\', \\'MNH\\', \\'NH.\\', \\'H.5\\', \\'.50\\', \\'067\\', \\'670\\', \\'707\\', \\'07.\\', \\'.1 \\', \\'715\\', \\'15.\\', \\'3 N\\', \\' Na\\', \\'Nau\\', \\'aut\\', \\'uti\\', \\'mpi\\', \\'pil\\', \\'liu\\', \\'ius\\', \\'128\\', \\'840\\', \\'1:8\\', \\':88\\', \\'851\\', \\'103\\', \\'83 \\', \\'3 D\\', \\'Dor\\', \\'ory\\', \\'ryt\\', \\'yte\\', \\'teu\\', \\'eut\\', \\'uth\\', \\'his\\', \\'s o\\', \\' op\\', \\'opa\\', \\'pal\\', \\'les\\', \\'esc\\', \\'sce\\', \\'002\\', \\'025\\', \\'250\\', \\'507\\', \\':87\\', \\'878\\', \\'785\\', \\'85-\\', \\'317\\', \\' Lo\\', \\'Lol\\', \\'lig\\', \\'go \\', \\' bl\\', \\'lee\\', \\'eek\\', \\'eke\\', \\'ker\\', \\'078\\', \\'789\\', \\'894\\', \\'94.\\', \\'580\\', \\'733\\', \\'337\\', \\'37 \\', \\' Se\\', \\'Sep\\', \\'epi\\', \\'pio\\', \\'ote\\', \\'ess\\', \\'son\\', \\'028\\', \\'281\\', \\'818\\', \\'89.\\', \\'896\\', \\'96-\\', \\'042\\', \\'8 U\\', \\' Ur\\', \\'Uro\\', \\'rot\\', \\' ch\\', \\'hin\\', \\'nen\\', \\'900\\', \\'008\\', \\'0 U\\', \\' du\\', \\'duv\\', \\'uva\\', \\'vau\\', \\'auc\\', \\'uce\\', \\'cel\\', \\'017\\', \\'177\\', \\'774\\', \\'746\\', \\'844\\', \\'44-\\', \\'376\\', \\'76 \\', \\'6 U\\', \\'s e\\', \\'082\\', \\'823\\', \\'26.\\', \\'65-\\', \\'397\\', \\'Lio\\', \\'ioc\\', \\'ocr\\', \\'cra\\', \\'anc\\', \\'nch\\', \\'hia\\', \\'rei\\', \\'ein\\', \\'inh\\', \\'nha\\', \\'ard\\', \\'rdt\\', \\'dti\\', \\'tii\\', \\' CE\\', \\'CEP\\', \\'EP2\\', \\'P21\\', \\'214\\', \\'233\\', \\':89\\', \\'898\\', \\'89-\\', \\'052\\', \\'21 \\', \\'1 A\\', \\' Ab\\', \\'Abr\\', \\'mor\\', \\'ori\\', \\'isi\\', \\'EP3\\', \\'P32\\', \\'323\\', \\'23 \\', \\'150\\', \\'098\\', \\'630\\', \\'0 W\\', \\' Wa\\', \\'Wat\\', \\'tas\\', \\'ase\\', \\'a s\\', \\' sc\\', \\'sci\\', \\'int\\', \\'ill\\', \\'ans\\', \\'918\\', \\'187\\', \\' Hi\\', \\'His\\', \\'ist\\', \\'sti\\', \\'tio\\', \\'s b\\', \\'onn\\', \\'nne\\', \\'EP0\\', \\'P01\\', \\'019\\', \\'19 \\', \\'9 m\\', \\'269\\', \\'908\\', \\'08.\\', \\'901\\', \\'8 I\\', \\' Il\\', \\'Ill\\', \\'lex\\', \\'ex \\', \\'x a\\', \\'rge\\', \\'097\\', \\'973\\', \\'734\\', \\':84\\', \\'454\\', \\'4-9\\', \\'-99\\', \\'998\\', \\'6 D\\', \\'sid\\', \\'421\\', \\'1-2\\', \\'-29\\', \\'953\\', \\'53 \\', \\'3 S\\', \\' St\\', \\'Sth\\', \\'the\\', \\'hen\\', \\'not\\', \\' ou\\', \\'oua\\', \\'ual\\', \\'nie\\', \\'ien\\', \\'583\\', \\'830\\', \\'404\\', \\'169\\', \\'693\\', \\'936\\', \\'6 T\\', \\' Th\\', \\'Thy\\', \\'ysa\\', \\'san\\', \\' rh\\', \\'rho\\', \\'hom\\', \\'omb\\', \\'mbu\\', \\'bus\\', \\'224\\', \\'246\\', \\':20\\', \\'206\\', \\'5-3\\', \\'-35\\', \\'597\\', \\'pia\\', \\' ap\\', \\'apa\\', \\'pam\\', \\'ele\\', \\'leg\\', \\'ega\\', \\'e T\\', \\' TO\\', \\'TON\\', \\'ON0\\', \\'N00\\', \\'004\\', \\'04 \\', \\'205\\', \\'58-\\', \\'8-3\\', \\'590\\', \\'90 \\', \\'0 S\\', \\'a o\\', \\' of\\', \\'ffi\\', \\'fic\\', \\'ici\\', \\'188\\', \\' or\\', \\'ign\\', \\'gny\\', \\'nya\\', \\'yan\\', \\'P02\\', \\'25 \\', \\'5 m\\', \\'021\\', \\'211\\', \\'114\\', \\'146\\', \\'69-\\', \\'360\\', \\'601\\', \\'226\\', \\'61-\\', \\'1-3\\', \\'593\\', \\'pie\\', \\'iel\\', \\' in\\', \\'ner\\', \\'rmi\\', \\'48.\\', \\'241\\', \\'12-\\', \\'2-3\\', \\'-39\\', \\'394\\', \\'944\\', \\'44 \\', \\'4 S\\', \\'iet\\', \\'ett\\', \\' ob\\', \\'obs\\', \\'bsc\\', \\'cur\\', \\'r I\\', \\' IC\\', \\'ICM\\', \\'CM:\\', \\'M:C\\', \\':C0\\', \\'C00\\', \\'642\\', \\'11-\\', \\'43 \\', \\'3 R\\', \\' Ro\\', \\'Ros\\', \\'acr\\', \\'cro\\', \\'oso\\', \\'som\\', \\'032\\', \\'329\\', \\'29 \\', \\'346\\', \\'468\\', \\'84-\\', \\'216\\', \\' Sp\\', \\'Spi\\', \\'pir\\', \\'iru\\', \\' sp\\', \\'spi\\', \\'r N\\', \\' NM\\', \\'NMV\\', \\'MV:\\', \\'V:Z\\', \\':Z7\\', \\'Z79\\', \\'46 \\', \\'699\\', \\'999\\', \\'996\\', \\'96.\\', \\'gon\\', \\'nau\\', \\'o i\\', \\' A2\\', \\'A20\\', \\'108\\', \\'CMC\\', \\'MC0\\', \\'31 \\', \\'363\\', \\'635\\', \\'354\\', \\' hi\\', \\'866\\', \\':25\\', \\'259\\', \\'93-\\', \\'3-4\\', \\'125\\', \\'5 J\\', \\' Ja\\', \\'Jap\\', \\'pet\\', \\' di\\', \\'iap\\', \\'aph\\', \\'97.\\', \\'3 E\\', \\' El\\', \\'Ele\\', \\'led\\', \\'edo\\', \\'ne \\', \\'e c\\', \\' ci\\', \\'cir\\', \\'irr\\', \\'rrh\\', \\'hos\\', \\'osa\\', \\'09 \\', \\'563\\', \\'638\\', \\'385\\', \\'256\\', \\'569\\', \\'9-4\\', \\'101\\', \\'1 E\\', \\' En\\', \\'Ent\\', \\'roc\\', \\'top\\', \\'opu\\', \\'pus\\', \\' do\\', \\'dof\\', \\'ofl\\', \\'fle\\', \\'ni \\', \\'029\\', \\'297\\', \\'970\\', \\'02.\\', \\'257\\', \\'75-\\', \\'07 \\', \\'Amp\\', \\' ae\\', \\'aeg\\', \\'egi\\', \\'254\\', \\'42-\\', \\'-40\\', \\'407\\', \\'074\\', \\'74 \\', \\'4 O\\', \\' Oc\\', \\'Oct\\', \\' oc\\', \\'oce\\', \\'972\\', \\'23.\\', \\'255\\', \\'557\\', \\'57-\\', \\'408\\', \\'089\\', \\'9 O\\', \\' bi\\', \\'bim\\', \\'ulo\\', \\'loi\\', \\'oid\\', \\'des\\', \\'984\\', \\'847\\', \\'086\\', \\'cya\\', \\'ane\\', \\'e X\\', \\' XX\\', \\'XX \\', \\'X m\\', \\'440\\', \\'66-\\', \\'6-4\\', \\'8 O\\', \\'mim\\', \\'imu\\', \\'mus\\', \\'353\\', \\'64-\\', \\'096\\', \\'96 \\', \\' vu\\', \\'vul\\', \\'ulg\\', \\'lga\\', \\'919\\', \\'193\\', \\' Pt\\', \\'Pte\\', \\' te\\', \\'tet\\', \\'tra\\', \\'aci\\', \\'rhu\\', \\'hus\\', \\'EP1\\', \\'P11\\', \\'968\\', \\'558\\', \\'8-4\\', \\'090\\', \\'0 V\\', \\' Va\\', \\'Vam\\', \\'amp\\', \\'mpy\\', \\'yro\\', \\'inf\\', \\'nfe\\', \\'167\\', \\'672\\', \\'722\\', \\'22.\\', \\':13\\', \\'137\\', \\'377\\', \\'77-\\', \\'7-2\\', \\'292\\', \\'926\\', \\'26 \\', \\'6 F\\', \\' Fl\\', \\'Flu\\', \\'ust\\', \\' fo\\', \\'fol\\', \\'lia\\', \\'iac\\', \\'74.\\', \\'130\\', \\'307\\', \\'72-\\', \\'-14\\', \\'460\\', \\'606\\', \\'6 H\\', \\'Hed\\', \\'edi\\', \\'e d\\', \\'div\\', \\'ive\\', \\'ver\\', \\'rsi\\', \\'sic\\', \\'ico\\', \\'olo\\', \\'lor\\', \\'or \\', \\'r m\\', \\'637\\', \\'379\\', \\'79.\\', \\'3 U\\', \\'Ure\\', \\'rec\\', \\'ech\\', \\'cau\\', \\'aup\\', \\'upo\\', \\'po \\', \\'o m\\', \\'673\\', \\'0 L\\', \\' Lu\\', \\'Lum\\', \\'mbr\\', \\'bri\\', \\'ric\\', \\'rre\\', \\'res\\', \\'est\\', \\'ACN\\', \\'CNN\\', \\'NNN\\', \\'NNT\\', \\'NTT\\', \\'066\\', \\'664\\', \\'400\\', \\'00.\\', \\'0 A\\', \\'Apo\\', \\'por\\', \\'orr\\', \\'dea\\', \\'igi\\', \\'ino\\', \\'nos\\', \\'e 4\\', \\' 42\\', \\'420\\', \\'20R\\', \\'0Ra\\', \\'Ra \\', \\'652\\', \\'212\\', \\'0 E\\', \\' Ei\\', \\'Eis\\', \\'dre\\', \\'ei \\', \\'213\\', \\'13.\\', \\' fe\\', \\'fet\\', \\'eti\\', \\'tid\\', \\'534\\', \\'34 \\', \\'4 B\\', \\' Ba\\', \\'Bar\\', \\'arb\\', \\'rbr\\', \\'bro\\', \\'ron\\', \\' we\\', \\'web\\', \\'ebe\\', \\' CS\\', \\'CSU\\', \\'SU-\\', \\'U-M\\', \\'-MG\\', \\'MG-\\', \\'G-1\\', \\'-1 \\', \\'692\\', \\'920\\', \\'203\\', \\':98\\', \\'980\\', \\'804\\', \\'113\\', \\'134\\', \\'340\\', \\'0 T\\', \\'The\\', \\'rom\\', \\'omy\\', \\'myz\\', \\'yzo\\', \\'zon\\', \\'n t\\', \\'3 L\\', \\'Lin\\', \\'neu\\', \\'eus\\', \\'132\\', \\'328\\', \\':78\\', \\'784\\', \\'45-\\', \\'5-9\\', \\'-94\\', \\'942\\', \\'422\\', \\'Cae\\', \\'aen\\', \\'nor\\', \\'orh\\', \\'rha\\', \\'hab\\', \\'abd\\', \\'bdi\\', \\' Rh\\', \\'Rhi\\', \\'hiz\\', \\'izo\\', \\'zog\\', \\'ogl\\', \\'gly\\', \\'lyp\\', \\'yph\\', \\'phu\\', \\'rob\\', \\'obi\\', \\'bin\\', \\'710\\', \\'4 A\\', \\'Art\\', \\'rte\\', \\'tem\\', \\'mia\\', \\' sa\\', \\'sal\\', \\'686\\', \\'665\\', \\'65.\\', \\' ur\\', \\'urm\\', \\' mt\\', \\'mtA\\', \\'tAr\\', \\'rt_\\', \\'t_1\\', \\'_1 \\', \\'503\\', \\':11\\', \\'147\\', \\'73-\\', \\'3-1\\', \\'6 E\\', \\' Eu\\', \\'Eub\\', \\'hip\\', \\'ipu\\', \\'gru\\', \\'ubi\\', \\'bii\\', \\'e D\\', \\' DM\\', \\'DM1\\', \\'M11\\', \\'704\\', \\'04.\\', \\'Str\\', \\'rep\\', \\'cep\\', \\'eph\\', \\'alu\\', \\'s s\\', \\' si\\', \\'sir\\', \\'ind\\', \\'ndh\\', \\'dho\\', \\'hor\\', \\'nae\\', \\'ae \\', \\'425\\', \\'345\\', \\'5-2\\', \\'-28\\', \\'875\\', \\'a k\\', \\' ku\\', \\'kug\\', \\'uge\\', \\'enu\\', \\'uma\\', \\'mae\\', \\'815\\', \\'52.\\', \\'34-\\', \\'4-2\\', \\'296\\', \\'967\\', \\' Da\\', \\'Dap\\', \\'phn\\', \\'hni\\', \\'car\\', \\'914\\', \\'14.\\', \\'13-\\', \\'3-2\\', \\'9 D\\', \\'agn\\', \\'gna\\', \\'084\\', \\'44.\\', \\'97-\\', \\'293\\', \\'934\\', \\'4 D\\', \\'pul\\', \\'x m\\', \\'747\\', \\'18-\\', \\'8-2\\', \\'285\\', \\'Sim\\', \\'imo\\', \\'moc\\', \\'ser\\', \\'rru\\', \\'596\\', \\'694\\', \\'696\\', \\'223\\', \\'231\\', \\'1 D\\', \\'Dia\\', \\' ex\\', \\'exc\\', \\'xci\\', \\'cis\\', \\'isu\\', \\'sum\\', \\'m c\\', \\' cl\\', \\'clo\\', \\'lon\\', \\' 1 \\', \\'446\\', \\'88-\\', \\'924\\', \\' Le\\', \\'Lep\\', \\'pid\\', \\'idu\\', \\'dur\\', \\'uru\\', \\'rus\\', \\'arc\\', \\'e L\\', \\'Lar\\', \\'rt-\\', \\'t-F\\', \\'-F3\\', \\'F3 \\', \\'478\\', \\'781\\', \\'81.\\', \\'373\\', \\'290\\', \\'909\\', \\'9 T\\', \\'ps \\', \\'riu\\', \\'291\\', \\'8 T\\', \\' lo\\', \\'ong\\', \\'ngi\\', \\'gic\\', \\'aud\\', \\'148\\', \\'4-3\\', \\'-30\\', \\'9 P\\', \\'Pol\\', \\'oll\\', \\'cip\\', \\'ipe\\', \\'pol\\', \\'oly\\', \\'lym\\', \\'yme\\', \\'eru\\', \\'452\\', \\'525\\', \\'25.\\', \\'550\\', \\'50 \\', \\'hib\\', \\'iba\\', \\' am\\', \\'itr\\', \\'ite\\', \\'669\\', \\'Eur\\', \\'ury\\', \\'emo\\', \\' af\\', \\'aff\\', \\'fin\\', \\'567\\', \\'676\\', \\'769\\', \\'69.\\', \\':82\\', \\'829\\', \\'91-\\', \\'1-9\\', \\'-98\\', \\'982\\', \\'9 L\\', \\'epe\\', \\'peo\\', \\'eop\\', \\'oph\\', \\'pht\\', \\'hth\\', \\'hei\\', \\'eir\\', \\'alm\\', \\'lmo\\', \\'860\\', \\'6 G\\', \\' Go\\', \\'Gon\\', \\'act\\', \\'cty\\', \\'tyl\\', \\'yla\\', \\'ceu\\', \\'s f\\', \\' fa\\', \\'fal\\', \\'alc\\', \\'lca\\', \\'349\\', \\'493\\', \\'937\\', \\'37.\\', \\'4 G\\', \\' Ga\\', \\'Gam\\', \\'amm\\', \\'mma\\', \\'fos\\', \\'sar\\', \\'748\\', \\'481\\', \\'3 G\\', \\'roe\\', \\'oes\\', \\'ese\\', \\'403\\', \\'828\\', \\'28-\\', \\'8-7\\', \\'736\\', \\'4 H\\', \\' Hy\\', \\'Hya\\', \\'yal\\', \\'lel\\', \\' az\\', \\'azt\\', \\'zte\\', \\'tec\\', \\'eca\\', \\'123\\', \\'32-\\', \\'2-2\\', \\'-27\\', \\'770\\', \\'70 \\', \\'Eup\\', \\'uph\\', \\'hau\\', \\'aus\\', \\'usi\\', \\' su\\', \\'sup\\', \\'upe\\', \\'erb\\', \\'rba\\', \\'ba \\', \\'60-\\', \\'0-2\\', \\'299\\', \\'8 L\\', \\'Lit\\', \\'pen\\', \\'aeu\\', \\'sty\\', \\'yli\\', \\'lir\\', \\'iro\\', \\'701\\', \\'463\\', \\'ars\\', \\'rsu\\', \\'s j\\', \\'679\\', \\'4 F\\', \\'Fen\\', \\'enn\\', \\'760\\', \\' Pa\\', \\'Par\\', \\'aty\\', \\'tya\\', \\' au\\', \\'lie\\', \\'rai\\', \\'ain\\', \\'in \\', \\'n A\\', \\' AP\\', \\'APR\\', \\'PR1\\', \\'R12\\', \\'020\\', \\'20.\\', \\' Ho\\', \\'Hom\\', \\'gam\\', \\'560\\', \\'537\\', \\'7 H\\', \\'033\\', \\'350\\', \\'Pac\\', \\'cif\\', \\'ifa\\', \\'fas\\', \\'sta\\', \\'tac\\', \\'niu\\', \\'usc\\', \\' AU\\', \\'AUG\\', \\'UG2\\', \\'G2 \\', \\'504\\', \\'535\\', \\'35 \\', \\' Au\\', \\'Aus\\', \\'opo\\', \\'pot\\', \\'mob\\', \\'biu\\', \\' to\\', \\'tiu\\', \\'m i\\', \\' F1\\', \\'F11\\', \\' Pr\\', \\'Pro\\', \\'oca\\', \\'cam\\', \\'amb\\', \\'mba\\', \\'bar\\', \\'cla\\', \\'ark\\', \\'rki\\', \\'kii\\', \\'286\\', \\'862\\', \\'627\\', \\'4 P\\', \\'Pan\\', \\' ve\\', \\'hod\\', \\'amt\\', \\'mts\\', \\'tsc\\', \\'sch\\', \\'hat\\', \\'091\\', \\'Bir\\', \\'atr\\', \\'ro \\', \\' TN\\', \\'TN1\\', \\'N16\\', \\'07D\\', \\'7D2\\', \\'D20\\', \\'202\\', \\'962\\', \\'700\\', \\'00-\\', \\'239\\', \\'9 C\\', \\'Can\\', \\'nce\\', \\'cer\\', \\'r p\\', \\'pag\\', \\'agu\\', \\'gur\\', \\'695\\', \\' Ch\\', \\'Cha\\', \\'ary\\', \\'ryb\\', \\'ybd\\', \\'Por\\', \\'ort\\', \\'rtu\\', \\'unu\\', \\'itu\\', \\'tub\\', \\'ube\\', \\'rcu\\', \\'643\\', \\'419\\', \\'9-2\\', \\'952\\', \\'52 \\', \\'2 F\\', \\' Fo\\', \\'Fol\\', \\'ols\\', \\'lso\\', \\'did\\', \\'n D\\', \\' DK\\', \\'DK \\', \\'K v\\', \\' FC\\', \\'FCD\\', \\'CDK\\', \\'K m\\', \\'TCM\\', \\'CMG\\', \\'MGG\\', \\'283\\', \\':95\\', \\'541\\', \\'41-\\', \\'110\\', \\' Or\\', \\'Orc\\', \\'rch\\', \\'hes\\', \\'nct\\', \\'cta\\', \\'744\\', \\'445\\', \\'116\\', \\'pis\\', \\'ism\\', \\'sma\\', \\'sac\\', \\'cch\\', \\'712\\', \\'433\\', \\'33-\\', \\'68 \\', \\'Loc\\', \\'ocu\\', \\'mig\\', \\'igr\\', \\'ato\\', \\' Ex\\', \\'Ext\\', \\'xta\\', \\'tos\\', \\' ti\\', \\'iar\\', \\' Be\\', \\'Bem\\', \\' ta\\', \\'tab\\', \\'aba\\', \\'bac\\', \\'ci \\', \\'011\\', \\'Acy\\', \\'cyr\\', \\'yrt\\', \\'rth\\', \\'sip\\', \\'iph\\', \\'pho\\', \\'55.\\', \\'140\\', \\'406\\', \\'06-\\', \\'6-2\\', \\'2 N\\', \\' Ne\\', \\'Nez\\', \\'eza\\', \\'zar\\', \\'351\\', \\'515\\', \\'129\\', \\'298\\', \\'834\\', \\' Ae\\', \\'Aed\\', \\'ede\\', \\'egy\\', \\'gyp\\', \\'ti \\', \\'i s\\', \\'n L\\', \\' LV\\', \\'LVP\\', \\'VP_\\', \\'P_A\\', \\'_AG\\', \\'AGW\\', \\'GWG\\', \\'WG \\', \\'Cul\\', \\'pip\\', \\'ipi\\', \\'961\\', \\'7-3\\', \\'Plo\\', \\'lod\\', \\'erp\\', \\'pun\\', \\'235\\', \\'831\\', \\'31-\\', \\'336\\', \\'361\\', \\' Bo\\', \\'Bom\\', \\'mby\\', \\'byx\\', \\'yx \\', \\'102\\', \\'266\\', \\'483\\', \\'83-\\', \\'3-3\\', \\'13 \\', \\'3 M\\', \\'Man\\', \\'ndu\\', \\'duc\\', \\'sex\\', \\'ext\\', \\'278\\', \\'783\\', \\'461\\', \\'991\\', \\'91 \\', \\'Spo\\', \\'dop\\', \\'opt\\', \\'pte\\', \\'fru\\', \\'rug\\', \\'ugi\\', \\'gip\\', \\'erd\\', \\'rda\\', \\'68.\\', \\'994\\', \\'94 \\', \\'cov\\', \\'ove\\', \\'rpa\\', \\'pa \\', \\'arm\\', \\'ige\\', \\'ger\\', \\'505\\', \\'528\\', \\'nep\\', \\'pit\\', \\'hem\\', \\' hu\\', \\'hum\\', \\'mil\\', \\'e v\\', \\'r L\\', \\' LH\\', \\'LH2\\', \\'H20\\', \\'510\\', \\'5 O\\', \\' Op\\', \\'Oph\\', \\'hiu\\', \\'iur\\', \\' al\\', \\'alb\\', \\'lbi\\', \\'bid\\', \\'274\\', \\':31\\', \\'178\\', \\'78-\\', \\'1 P\\', \\' Pi\\', \\'Pis\\', \\'isa\\', \\'sas\\', \\'r o\\', \\'chr\\', \\'hra\\', \\' M0\\', \\'M0D\\', \\'0D0\\', \\'D05\\', \\'055\\', \\'518\\', \\'89C\\', \\'9C \\', \\'C m\\', \\'077\\', \\'778\\', \\'788\\', \\':46\\', \\'5-6\\', \\'-62\\', \\'621\\', \\'217\\', \\'Aca\\', \\'nth\\', \\'has\\', \\':48\\', \\'812\\', \\'2-6\\', \\'-63\\', \\'ore\\', \\'eas\\', \\'r n\\', \\'dos\\', \\'r H\\', \\' HS\\', \\'HS0\\', \\'S00\\', \\'053\\', \\'Cro\\', \\'pap\\', \\'app\\', \\'ppo\\', \\'pos\\', \\'832\\', \\'2-7\\', \\'5 S\\', \\'Ste\\', \\'ere\\', \\'s n\\', \\' ne\\', \\'eum\\', \\'may\\', \\'aye\\', \\'yer\\', \\'417\\', \\'585\\', \\'1-7\\', \\'-74\\', \\'Mes\\', \\'eso\\', \\'soc\\', \\'ntr\\', \\'otu\\', \\'sca\\', \\'099\\', \\'405\\', \\'ngy\\', \\'gyl\\', \\'ylo\\', \\'loc\\', \\' dr\\', \\'dro\\', \\'oeb\\', \\'eba\\', \\'hie\\', \\'941\\', \\'6-7\\', \\'739\\', \\'99 \\', \\'9 S\\', \\'dus\\', \\'453\\', \\':57\\', \\'338\\', \\'38 \\', \\'27-\\', \\'7-7\\', \\'80 \\', \\' Ly\\', \\'Lyt\\', \\'rie\\', \\'ieg\\', \\' Lv\\', \\'Lv4\\', \\'v4 \\', \\'157\\', \\'72.\\', \\'838\\', \\'38-\\', \\'391\\', \\'liv\\', \\'ivi\\', \\'vid\\', \\'237\\', \\'70.\\', \\'40-\\', \\'0-7\\', \\'393\\', \\'Lox\\', \\'oxe\\', \\'xec\\', \\'lbu\\', \\'881\\', \\'549\\', \\'2 E\\', \\'rdi\\', \\'cor\\', \\'ord\\', \\'Hol\\', \\'oth\\', \\'thu\\', \\'hur\\', \\'uri\\', \\'cab\\', \\'083\\', \\'8 B\\', \\'ios\\', \\'flo\\', \\'dae\\', \\'469\\', \\':34\\', \\'344\\', \\'442\\', \\'2-5\\', \\'-50\\', \\'501\\', \\'6 A\\', \\' As\\', \\'Asc\\', \\'cid\\', \\'die\\', \\' as\\', \\'asp\\', \\'rsa\\', \\'al \\', \\'l g\\', \\'179\\', \\'792\\', \\'272\\', \\' Ci\\', \\'Cio\\', \\'s B\\', \\' B \\', \\'B C\\', \\' CG\\', \\'CG-\\', \\'G-2\\', \\'-20\\', \\'Bot\\', \\'otr\\', \\'try\\', \\'ryl\\', \\'yll\\', \\'vio\\', \\'iol\\', \\'135\\', \\':35\\', \\'8-5\\', \\'Sty\\', \\'tye\\', \\'yel\\', \\'639\\', \\'Myx\\', \\'yxi\\', \\'xin\\', \\'glu\\', \\'lut\\', \\'Geo\\', \\'eot\\', \\'930\\', \\':70\\', \\'703\\', \\'37-\\', \\'7-8\\', \\'-85\\', \\'858\\', \\'587\\', \\' Mo\\', \\'Mor\\', \\'dax\\', \\'l D\\', \\' DN\\', \\'DNA\\', \\'NA,\\', \\'A, \\', \\'162\\', \\'626\\', \\'1:6\\', \\':66\\', \\'610\\', \\'10-\\', \\'0-8\\', \\'-81\\', \\'816\\', \\'Pet\\', \\'555\\', \\'7 I\\', \\' Ic\\', \\'Ich\\', \\'cht\\', \\'thy\\', \\'hyo\\', \\'yom\\', \\'n f\\', \\'sor\\', \\'342\\', \\'429\\', \\':65\\', \\'589\\', \\'9-8\\', \\'814\\', \\'5 I\\', \\'gag\\', \\'gei\\', \\'902\\', \\'343\\', \\'3-6\\', \\'nto\\', \\'osp\\', \\'sph\\', \\'phe\\', \\'mpe\\', \\'ppe\\', \\'end\\', \\'dix\\', \\'2 L\\', \\'Let\\', \\'eth\\', \\'n c\\', \\'cum\\', \\'917\\', \\'aep\\', \\'epy\\', \\'pyp\\', \\'415\\', \\'luv\\', \\'uvi\\', \\'via\\', \\'iat\\', \\':54\\', \\'24-\\', \\'-69\\', \\'698\\', \\'983\\', \\'Cal\\', \\'rhi\\', \\'chu\\', \\'cap\\', \\'456\\', \\'56-\\', \\'-70\\', \\'Chi\\', \\'him\\', \\'aer\\', \\'ons\\', \\'nst\\', \\'544\\', \\'4-7\\', \\' fu\\', \\'ful\\', \\'ulv\\', \\'lva\\', \\'va \\', \\':28\\', \\'883\\', \\'2 R\\', \\'pac\\', \\'ifi\\', \\'745\\', \\'546\\', \\'Hem\\', \\'scy\\', \\'cyl\\', \\'m o\\', \\'0 C\\', \\'ilo\\', \\'los\\', \\'m p\\', \\'gio\\', \\'948\\', \\'480\\', \\'490\\', \\'90-\\', \\'teg\\', \\'ego\\', \\'gos\\', \\'asc\\', \\'455\\', \\'547\\', \\'79-\\', \\'9-7\\', \\'5 R\\', \\'nco\\', \\'cod\\', \\' ty\\', \\'ypu\\', \\'475\\', \\'1 G\\', \\'Gin\\', \\'ing\\', \\'ngl\\', \\'ymo\\', \\'mos\\', \\'rra\\', \\'049\\', \\'988\\', \\'Gal\\', \\'leu\\', \\'omu\\', \\'DM4\\', \\'M43\\', \\'CTY\\', \\'TYC\\', \\'YCA\\', \\'195\\', \\'950\\', \\'418\\', \\' Sc\\', \\'Scy\\', \\'ior\\', \\'275\\', \\'751\\', \\'51.\\', \\'476\\', \\'76-\\', \\'r v\\', \\' US\\', \\'USN\\', \\'SNM\\', \\'NM:\\', \\'M:F\\', \\':FI\\', \\'FIS\\', \\'ISH\\', \\'SH:\\', \\'H:4\\', \\':45\\', \\'790\\', \\'890\\', \\' Mu\\', \\'Mus\\', \\'elu\\', \\'man\\', \\'naz\\', \\'azo\\', \\'zo \\', \\'396\\', \\'629\\', \\' mu\\', \\'462\\', \\'1 T\\', \\'iak\\', \\'aki\\', \\'kis\\', \\'meg\\', \\'alo\\', \\'775\\', \\'758\\', \\'62-\\', \\'sem\\', \\'mif\\', \\'437\\', \\'55-\\', \\'leo\\', \\'eor\\', \\'r G\\', \\' GA\\', \\'AG_\\', \\'G_O\\', \\'_OL\\', \\'OLH\\', \\'LHA\\', \\'HAO\\', \\'AO \\', \\'O O\\', \\' OB\\', \\'OBS\\', \\'BS2\\', \\'S2 \\', \\'459\\', \\'5 H\\', \\'pan\\', \\'240\\', \\'Car\\', \\'arh\\', \\'472\\', \\'6 C\\', \\'ICS\\', \\'CST\\', \\'ST:\\', \\'T:0\\', \\':02\\', \\'208\\', \\'238\\', \\'8 C\\', \\'bly\\', \\'lyr\\', \\'yrh\\', \\'rhy\\', \\'hyn\\', \\'ync\\', \\'os \\', \\'085\\', \\'859\\', \\'971\\', \\'71 \\', \\'752\\', \\' br\\', \\'hyu\\', \\'yur\\', \\'r S\\', \\' SN\\', \\'SNU\\', \\'NU-\\', \\'-MO\\', \\'MO-\\', \\'O-0\\', \\'081\\', \\'bre\\', \\'rev\\', \\'vip\\', \\'inn\\', \\'nna\\', \\'225\\', \\'lci\\', \\'orm\\', \\'522\\', \\'euc\\', \\'cas\\', \\'520\\', \\'gim\\', \\'248\\', \\'486\\', \\'acl\\', \\'nop\\', \\'plu\\', \\'beu\\', \\' so\\', \\'rah\\', \\'ah \\', \\'h m\\', \\'219\\', \\'2 G\\', \\'eoc\\', \\'rdo\\', \\'do \\', \\'o c\\', \\'cuv\\', \\'vie\\', \\'ier\\', \\'0 R\\', \\'zop\\', \\'pri\\', \\'n a\\', \\'utu\\', \\'819\\', \\'Pri\\', \\'nac\\', \\'ce \\', \\'lau\\', \\'309\\', \\'095\\', \\'5 N\\', \\'Neg\\', \\'gap\\', \\'apr\\', \\'n b\\', \\'oxo\\', \\'xod\\', \\'ror\\', \\'Sco\\', \\'iod\\', \\'n l\\', \\'udu\\', \\'iae\\', \\'n o\\', \\'obe\\', \\'bes\\', \\'esu\\', \\'320\\', \\'1 H\\', \\'mip\\', \\'ipr\\', \\'elo\\', \\'nga\\', \\'Sph\\', \\'phy\\', \\'yrn\\', \\'lew\\', \\'ewi\\', \\'win\\', \\'491\\', \\'mok\\', \\'oka\\', \\'kar\\', \\'arr\\', \\'an \\', \\'n v\\', \\'r O\\', \\' OC\\', \\'OC-\\', \\'C-2\\', \\'-22\\', \\'508\\', \\'tib\\', \\'ibu\\', \\'bur\\', \\'uro\\', \\'a z\\', \\' zy\\', \\'zyg\\', \\'gae\\', \\'181\\', \\'8 E\\', \\'Eus\\', \\'usp\\', \\'yra\\', \\'blo\\', \\'hii\\', \\'ias\\', \\'tau\\', \\'aur\\', \\'amn\\', \\'mna\\', \\' na\\', \\'nas\\', \\'asu\\', \\'4 I\\', \\' Is\\', \\'Isu\\', \\'sur\\', \\' ox\\', \\'oxy\\', \\'xyr\\', \\'aro\\', \\'udo\\', \\'doc\\', \\'s k\\', \\' ka\\', \\'kam\\', \\'moh\\', \\'oha\\', \\'ai \\', \\'822\\', \\'Alo\\', \\'pel\\', \\'443\\', \\'rci\\', \\'cil\\', \\'ulp\\', \\'lpi\\', \\'DM5\\', \\'M51\\', \\'Cet\\', \\'eto\\', \\'axi\\', \\'xim\\', \\'182\\', \\'825\\', \\'Mit\\', \\'its\\', \\'tsu\\', \\'suk\\', \\'uku\\', \\'kur\\', \\' ow\\', \\'ows\\', \\'wst\\', \\'449\\', \\'Chl\\', \\'myd\\', \\'ydo\\', \\'ose\\', \\'ang\\', \\'ngu\\', \\'gui\\', \\'730\\', \\'30.\\', \\'Hep\\', \\'ptr\\', \\'rlo\\', \\'lo \\', \\'6 N\\', \\' No\\', \\'Not\\', \\'ryn\\', \\' ce\\', \\'ped\\', \\' Sq\\', \\'Squ\\', \\'aca\\', \\'470\\', \\'70-\\', \\'bla\\', \\'lai\\', \\'inv\\', \\'nvi\\', \\'vil\\', \\'853\\', \\'467\\', \\'67-\\', \\'tal\\', \\'lba\\', \\'ban\\', \\'864\\', \\'64.\\', \\' So\\', \\'Som\\', \\'omn\\', \\'mni\\', \\'mic\\', \\'icr\\', \\'DM3\\', \\'M35\\', \\'59 \\', \\'451\\', \\'uat\\', \\'dum\\', \\'ume\\', \\'ril\\', \\'il \\', \\'l v\\', \\'C-0\\', \\'797\\', \\'974\\', \\'raj\\', \\'aja\\', \\'ja \\', \\'geo\\', \\'org\\', \\'r e\\', \\' ef\\', \\'efi\\', \\'fis\\', \\'ish\\', \\'sh-\\', \\'h-1\\', \\'121\\', \\'7 m\\', \\' ra\\', \\'rad\\', \\'adi\\', \\'808\\', \\'2 B\\', \\'Ber\\', \\'ngr\\', \\' UW\\', \\'UW:\\', \\'W:4\\', \\':47\\', \\'477\\', \\' Ra\\', \\'Raj\\', \\'ulc\\', \\'lch\\', \\'964\\', \\'793\\', \\'9 B\\', \\'llu\\', \\'lul\\', \\'W:1\\', \\'Dip\\', \\'ptu\\', \\'tur\\', \\'bat\\', \\'nno\\', \\' eF\\', \\'eFi\\', \\'Fis\\', \\'05.\\', \\'5.2\\', \\'2:5\\', \\'2 D\\', \\' kw\\', \\'kwa\\', \\'wan\\', \\'ngt\\', \\'gtu\\', \\'ung\\', \\'nge\\', \\'67.\\', \\'170\\', \\'hyd\\', \\'yde\\', \\'Leu\\', \\'uco\\', \\' er\\', \\'evu\\', \\'81 \\', \\'071\\', \\'173\\', \\'1 O\\', \\' Ok\\', \\'Oka\\', \\'mej\\', \\'eje\\', \\'jei\\', \\'i k\\', \\' ke\\', \\'noj\\', \\'oje\\', \\'81-\\', \\'7 R\\', \\'lav\\', \\'ava\\', \\'vat\\', \\'197\\', \\'mir\\', \\'ira\\', \\'etu\\', \\'71.\\', \\'yst\\', \\'tig\\', \\'igm\\', \\'gma\\', \\'939\\', \\'0 Z\\', \\' Ze\\', \\'Zea\\', \\'ear\\', \\'sut\\', \\'Bat\\', \\'lbo\\', \\'bom\\', \\'087\\', \\'799\\', \\'99.\\', \\'965\\', \\'gri\\', \\'seo\\', \\'88 \\', \\'809\\', \\'rup\\', \\'upt\\', \\'720\\', \\'800\\', \\'932\\', \\'801\\', \\'tar\\', \\'net\\', \\'etz\\', \\'tzi\\', \\'zi \\', \\'949\\', \\' At\\', \\'Atl\\', \\'tla\\', \\'eln\\', \\'lna\\', \\'aui\\', \\'ui \\', \\' IN\\', \\'INI\\', \\'NID\\', \\'IDE\\', \\'DEP\\', \\'EP-\\', \\'P-T\\', \\'-T \\', \\'T 0\\', \\' 04\\', \\'3 T\\', \\' To\\', \\'Tor\\', \\'orp\\', \\'rpe\\', \\'rmo\\', \\'347\\', \\'771\\', \\'502\\', \\'02-\\', \\'1 N\\', \\'Nar\\', \\'e b\\', \\'asi\\', \\'sil\\', \\'nox\\', \\'xyp\\', \\'ypr\\', \\'718\\', \\'Rhy\\', \\'hob\\', \\'oba\\', \\'897\\', \\'Acr\\', \\'iob\\', \\'ann\\', \\'nnu\\', \\' MV\\', \\'MVS\\', \\'VS1\\', \\'S12\\', \\'482\\', \\'82-\\', \\'8 Z\\', \\' Za\\', \\'Zap\\', \\'apt\\', \\'ery\\', \\'ryx\\', \\'x e\\', \\'exa\\', \\'xas\\', \\'579\\', \\'976\\', \\'5 D\\', \\'Das\\', \\'asy\\', \\'sya\\', \\'yat\\', \\'pas\\', \\' CB\\', \\'CBR\\', \\'BRG\\', \\'RG-\\', \\'G-D\\', \\'-Dp\\', \\'Dpa\\', \\'as1\\', \\'s17\\', \\'176\\', \\'767\\', \\'517\\', \\'17-\\', \\'79 \\', \\'9 N\\', \\'Neo\\', \\'ryg\\', \\'ygo\\', \\'n k\\', \\'kuh\\', \\'uhl\\', \\'hli\\', \\'512\\', \\'opl\\', \\'tyt\\', \\'ytr\\', \\'938\\', \\' Gy\\', \\'Gym\\', \\'ymn\\', \\'mnu\\', \\'nur\\', \\'lta\\', \\'tav\\', \\'ave\\', \\'vel\\', \\'837\\', \\'62 \\', \\'Aet\\', \\'tob\\', \\'fla\\', \\'n 0\\', \\' 09\\', \\'09A\\', \\'9A0\\', \\'A06\\', \\'Mob\\', \\'obu\\', \\'4 R\\', \\':43\\', \\'311\\', \\'126\\', \\'251\\', \\' Er\\', \\'Erp\\', \\'toi\\', \\'oic\\', \\'ich\\', \\'18.\\', \\'697\\', \\'975\\', \\'ene\\', \\'neg\\', \\'lyo\\', \\'yod\\', \\'spa\\', \\'pat\\', \\'hul\\', \\'Aci\\', \\'nse\\', \\'r b\\', \\'bae\\', \\'rii\\', \\'327\\', \\'07-\\', \\'60 \\', \\'m v\\', \\'USF\\', \\'SFW\\', \\'FWS\\', \\'WS-\\', \\'S-1\\', \\'03-\\', \\'r d\\', \\' da\\', \\'dab\\', \\'bry\\', \\'rya\\', \\'303\\', \\'r f\\', \\'lve\\', \\'ves\\', \\' LS\\', \\'LSN\\', \\'SNF\\', \\'NFC\\', \\'FC-\\', \\'C-1\\', \\'5-0\\', \\'576\\', \\'r g\\', \\' gu\\', \\'gue\\', \\'uel\\', \\'eld\\', \\'lde\\', \\'tae\\', \\'aed\\', \\'edt\\', \\'med\\', \\'dir\\', \\' nu\\', \\'nud\\', \\'ven\\', \\'e N\\', \\' NU\\', \\'NUD\\', \\'UD2\\', \\'D2_\\', \\'2_B\\', \\'_Ba\\', \\'Bal\\', \\'alh\\', \\'lha\\', \\'ash\\', \\'sh \\', \\'Lod\\', \\'odg\\', \\'dge\\', \\'geL\\', \\'eLa\\', \\'Lab\\', \\'ab \\', \\'b A\\', \\' Ao\\', \\'Aox\\', \\'us_\\', \\'s_1\\', \\'r s\\', \\'hre\\', \\'enc\\', \\'nck\\', \\'cki\\', \\'264\\', \\'01-\\', \\'stu\\', \\'r t\\', \\'nsm\\', \\'smo\\', \\'tan\\', \\'252\\', \\' Hu\\', \\'Hus\\', \\'uso\\', \\'so \\', \\'o h\\', \\'o d\\', \\'dau\\', \\'324\\', \\'58 \\', \\'Sca\\', \\'hir\\', \\'irh\\', \\'Stu\\', \\'urg\\', \\'rg-\\', \\'g-8\\', \\'-86\\', \\'863\\', \\'utt\\', \\'ttk\\', \\'tku\\', \\'kus\\', \\'si \\', \\' NF\\', \\'NFW\\', \\'FWF\\', \\'WFL\\', \\'FLH\\', \\'LH1\\', \\'H10\\', \\'742\\', \\'20-\\', \\'Ami\\', \\'alv\\', \\'813\\', \\'Atr\\', \\'tul\\', \\'810\\', \\' os\\', \\'sse\\', \\'tyr\\', \\'4 E\\', \\'Elo\\', \\'sau\\', \\'1 M\\', \\'Meg\\', \\' at\\', \\'atl\\', \\'92.\\', \\'Alb\\', \\'lpe\\', \\':41\\', \\'592\\', \\'ir \\', \\'r Z\\', \\' ZM\\', \\'ZMU\\', \\'MUC\\', \\'UC:\\', \\'C:P\\', \\':P3\\', \\'P33\\', \\'369\\', \\'69 \\', \\'653\\', \\'Ang\\', \\'uil\\', \\'7.2\\', \\'511\\', \\'Mur\\', \\'rae\\', \\'nes\\', \\'sox\\', \\'ox \\', \\'x b\\', \\'bag\\', \\'574\\', \\'749\\', \\'492\\', \\'x c\\', \\'reu\\', \\'430\\', \\'30-\\', \\'mno\\', \\'rax\\', \\'x k\\', \\' ki\\', \\'kid\\', \\'dak\\', \\'ako\\', \\'ko \\', \\'9 H\\', \\'Hio\\', \\'erg\\', \\'gis\\', \\'514\\', \\'soi\\', \\'teo\\', \\'eog\\', \\'m b\\', \\'41 \\', \\'713\\', \\'Ara\\', \\'rap\\', \\'pai\\', \\'aim\\', \\'Het\\', \\' ni\\', \\'644\\', \\'Coi\\', \\'oil\\', \\' my\\', \\'957\\', \\'2 S\\', \\'Set\\', \\'ty \\', \\'y m\\', \\'2 T\\', \\'Thr\\', \\'hry\\', \\'rys\\', \\'yss\\', \\'tax\\', \\'381\\', \\'set\\', \\'tir\\', \\'Anc\\', \\'hoa\\', \\'oa \\', \\'itc\\', \\'tch\\', \\'li \\', \\'928\\', \\'879\\', \\'958\\', \\'581\\', \\'80-\\', \\'Eng\\', \\'rau\\', \\'aul\\', \\' en\\', \\'ncr\\', \\'olu\\', \\'5 E\\', \\' ri\\', \\'1 L\\', \\'Lyc\\', \\'yce\\', \\'eng\\', \\'gro\\', \\'Sto\\', \\'tol\\', \\'ole\\', \\'lep\\', \\'omm\\', \\'mme\\', \\'rso\\', \\'nni\\', \\'nii\\', \\'ins\\', \\'nsu\\', \\'s w\\', \\' wa\\', \\'wai\\', \\'ait\\', \\'tei\\', \\'0 J\\', \\' Je\\', \\'Jen\\', \\'enk\\', \\'nki\\', \\'kin\\', \\'mpr\\', \\'Spr\\', \\'pra\\', \\'9 I\\', \\'Ili\\', \\'sha\\', \\'ha \\', \\'afr\\', \\'fri\\', \\'3 I\\', \\'7 O\\', \\'Opi\\', \\'sth\\', \\'hop\\', \\'doo\\', \\'oor\\', \\'re \\', \\'e s\\', \\'seq\\', \\'que\\', \\'uen\\', \\'ce\\\\n\\', \\'Clu\\', \\'lup\\', \\'671\\', \\'8 G\\', \\' Gu\\', \\'Gud\\', \\'667\\', \\'Hyp\\', \\'674\\', \\'mal\\', \\'chm\\', \\'hmo\\', \\'959\\', \\'att\\', \\'ttu\\', \\'spr\\', \\'pei\\', \\'eic\\', \\'aes\\', \\'esa\\', \\'arn\\', \\'rne\\', \\'151\\', \\'eon\\', \\'ult\\', \\'ltr\\', \\'riv\\', \\'370\\', \\'8 A\\', \\'iva\\', \\' NE\\', \\'NEF\\', \\'EFC\\', \\'FC \\', \\'C F\\', \\'F17\\', \\'75.\\', \\'bam\\', \\' Aa\\', \\'Aal\\', \\'ae_\\', \\'e_1\\', \\'dio\\', \\'cri\\', \\'sap\\', \\'api\\', \\'sim\\', \\' ps\\', \\'pse\\', \\'doh\\', \\'Bre\\', \\'evo\\', \\'voo\\', \\'rti\\', \\'Sar\\', \\'din\\', \\'ilc\\', \\'rdu\\', \\'aga\\', \\'gax\\', \\'872\\', \\'imn\\', \\'thr\\', \\'hri\\', \\'n i\\', \\' D2\\', \\'D2 \\', \\'cae\\', \\' D7\\', \\'D7 \\', \\'hac\\', \\'cun\\', \\'7 T\\', \\' Te\\', \\'Ten\\', \\'nua\\', \\' il\\', \\'me,\\', \\'e, \\', \\', s\\', \\'in:\\', \\'n: \\', \\': c\\', \\'cl1\\', \\'l10\\', \\'10\\\\n\\', \\'0\\\\nG\\', \\'lyg\\', \\'irm\\', \\'rm \\', \\'upa\\', \\' th\\', \\'oro\\', \\'0 D\\', \\'se \\', \\'06.\\', \\'485\\', \\' Es\\', \\'Esc\\', \\'cua\\', \\' Et\\', \\'Eth\\', \\'thm\\', \\'hma\\', \\' fi\\', \\'fim\\', \\'imb\\', \\'0 K\\', \\' Ko\\', \\'Kon\\', \\' og\\', \\'gli\\', \\'763\\', \\'880\\', \\'802\\', \\'726\\', \\'lbe\\', \\'bel\\', \\'371\\', \\'gib\\', \\'bbo\\', \\'395\\', \\'955\\', \\'553\\', \\'495\\', \\'emu\\', \\'mur\\', \\'ru \\', \\'u m\\', \\'334\\', \\'ice\\', \\'eps\\', \\'mad\\', \\'ade\\', \\'666\\', \\'Har\\', \\'gul\\', \\'jag\\', \\'gua\\', \\'uan\\', \\'Ale\\', \\'epo\\', \\'poc\\', \\'bai\\', \\'air\\', \\'ird\\', \\'dii\\', \\'Cir\\', \\'CBM\\', \\'BM:\\', \\'M:Z\\', \\':ZF\\', \\'ZF \\', \\'F 1\\', \\' 11\\', \\'647\\', \\'47 \\', \\'761\\', \\':64\\', \\'423\\', \\'23-\\', \\'-79\\', \\'73 \\', \\' mr\\', \\'mri\\', \\'rig\\', \\'abe\\', \\'beo\\', \\'eo \\', \\'bas\\', \\'su \\', \\'168\\', \\'Cat\\', \\'6 L\\', \\'o r\\', \\'roh\\', \\'ohi\\', \\'tit\\', \\' Cy\\', \\'Cyp\\', \\'arp\\', \\'rpi\\', \"o \\'\", \" \\'c\", \"\\'co\", \"or\\'\", \"r\\' \", \"\\' m\", \\'402\\', \\'siu\\', \\'ibe\\', \\'rbu\\', \\'532\\', \\'Luc\\', \\'uci\\', \\'cio\\', \\'scl\\', \\'0 O\\', \\' Ox\\', \\'Oxy\\', \\'xyg\\', \\'ygy\\', \\'gym\\', \\'ocy\\', \\'cyp\\', \\'tew\\', \\'ewa\\', \\'war\\', \\'820\\', \\'Ore\\', \\'Sch\\', \\'zot\\', \\'x w\\', \\'wal\\', \\'lto\\', \\'Pty\\', \\'tyc\\', \\'ych\\', \\'dip\\', \\'pog\\', \\'ogo\\', \\'496\\', \\'lte\\', \\'r l\\', \\'333\\', \\'3.2\\', \\'2:6\\', \\'25-\\', \\'Dan\\', \\'rer\\', \\'ypo\\', \\'lmi\\', \\'mol\\', \\'rix\\', \\'194\\', \\'nob\\', \\'92-\\', \\' Ct\\', \\'Cte\\', \\'yng\\', \\'ngo\\', \\'god\\', \\' id\\', \\' Ti\\', \\'Tin\\', \\'538\\', \\'Rho\\', \\'deu\\', \\'378\\', \\'Abb\\', \\'bot\\', \\'ott\\', \\'662\\', \\'Gob\\', \\'bio\\', \\'o g\\', \\' go\\', \\'gob\\', \\'Pho\\', \\'hox\\', \\'oxi\\', \\'Chr\\', \\'hro\\', \\'yth\\', \\'rog\\', \\'oga\\', \\'CAN\\', \\'ANT\\', \\'NTA\\', \\'Gil\\', \\'ila\\', \\'coe\\', \\'oer\\', \\'lea\\', \\'0 G\\', \\'SNA\\', \\'NAR\\', \\'ARR\\', \\'RRC\\', \\'RC1\\', \\'C18\\', \\'8-0\\', \\'-01\\', \\'414\\', \\'hoc\\', \\'eil\\', \\' lu\\', \\'ciu\\', \\'ARC\\', \\'RCC\\', \\'CC1\\', \\'reg\\', \\'Sip\\', \\'392\\', \\'927\\', \\'Lav\\', \\'avi\\', \\'exi\\', \\'xil\\', \\'659\\', \\'urn\\', \\'0 N\\', \\' cr\\', \\'cry\\', \\'yso\\', \\'ram\\', \\'ami\\', \\'Cho\\', \\'emm\\', \\'mmi\\', \\'gii\\', \\'lyl\\', \\'yle\\', \\'867\\', \\'Rut\\', \\'rut\\', \\'FC_\\', \\'C_F\\', \\'_F2\\', \\'F20\\', \\'lmu\\', \\'Med\\', \\'eda\\', \\'lgi\\', \\'gid\\', \\'b M\\', \\' Mf\\', \\'Mfu\\', \\'da_\\', \\'a_9\\', \\'_9 \\', \\'Sem\\', \\'mot\\', \\'727\\', \\'xyc\\', \\' IH\\', \\'IHB\\', \\'HB-\\', \\'-LH\\', \\'LHG\\', \\'HG2\\', \\'G20\\', \\'306\\', \\'9 M\\', \\'Myl\\', \\'Pog\\', \\'rol\\', \\'dot\\', \\'951\\', \\' Ri\\', \\'Ric\\', \\'rds\\', \\'dso\\', \\' eg\\', \\'egr\\', \\'gre\\', \\'giu\\', \\'7 E\\', \\'Exo\\', \\'xog\\', \\'ua \\', \\'7-0\\', \\'-06\\', \\'8 R\\', \\'Cam\\', \\'mpo\\', \\' Bl\\', \\'Bli\\', \\'icc\\', \\'cca\\', \\' bj\\', \\'bjo\\', \\'joe\\', \\'erk\\', \\'rkn\\', \\'kna\\', \\'499\\', \\'99-\\', \\' BC\\', \\'BC-\\', \\'C-3\\', \\'-34\\', \\'261\\', \\'Dio\\', \\'iab\\', \\'abo\\', \\'bol\\', \\'-08\\', \\'2 H\\', \\'Hyb\\', \\'ybo\\', \\'bog\\', \\'ogn\\', \\'nuc\\', \\'cit\\', \\'907\\', \\'8 H\\', \\'bop\\', \\'923\\', \\'Lux\\', \\'uxi\\', \\'931\\', \\'nut\\', \\'ils\\', \\'lsb\\', \\'sbr\\', \\'ryi\\', \\' LB\\', \\'LBC\\', \\'935\\', \\'35.\\', \\'hru\\', \\'rur\\', \\'s u\\', \\'660\\', \\'1-8\\', \\'Mac\\', \\'crh\\', \\'hyb\\', \\'s h\\', \\' hy\\', \\'yos\\', \\'mee\\', \\'eki\\', \\'ki \\', \\'304\\', \\':44\\', \\'-60\\', \\'925\\', \\'8 N\\', \\'noi\\', \\'bif\\', \\'ifr\\', \\'fre\\', \\'4 N\\', \\'boo\\', \\'oop\\', \\' DF\\', \\'DF-\\', \\'F-4\\', \\'-4 \\', \\'786\\', \\' bu\\', \\'buc\\', \\'ccu\\', \\'r T\\', \\' TC\\', \\'TCW\\', \\'CWC\\', \\'WC:\\', \\'C:F\\', \\':Fi\\', \\'sh:\\', \\'h:2\\', \\'0.0\\', \\'e R\\', \\' RA\\', \\'RAH\\', \\'AH-\\', \\'H-1\\', \\'aly\\', \\'lyb\\', \\'yba\\', \\'F16\\', \\'6-0\\', \\'-05\\', \\'947\\', \\'7 N\\', \\'gir\\', \\'rar\\', \\'di \\', \\'RC2\\', \\'C20\\', \\'0-0\\', \\'-03\\', \\'hud\\', \\'uds\\', \\'-61\\', \\' je\\', \\'jem\\', \\'eme\\', \\'mez\\', \\'zan\\', \\'811\\', \\'092\\', \\'tex\\', \\'xan\\', \\'vol\\', \\'Ops\\', \\'pso\\', \\'sop\\', \\'poe\\', \\'oeo\\', \\'eod\\', \\'odu\\', \\' em\\', \\'Phe\\', \\'cob\\', \\'rab\\', \\'abi\\', \\'Pim\\', \\'mep\\', \\' pr\\', \\'tyg\\', \\'-59\\', \\'bia\\', \\'945\\', \\'rim\\', \\'imi\\', \\'tah\\', \\'aho\\', \\'hoe\\', \\'oen\\', \\'258\\', \\' De\\', \\'Del\\', \\'elt\\', \\'lti\\', \\'lux\\', \\'uxa\\', \\'xat\\', \\'9 X\\', \\' Xy\\', \\'Xyr\\', \\'Eri\\', \\'imy\\', \\'obl\\', \\'0 M\\', \\'Min\\', \\'iny\\', \\'nyt\\', \\'rem\\', \\'m n\\', \\'nig\\', \\'633\\', \\'Tho\\', \\'hot\\', \\'oec\\', \\'Mox\\', \\'xos\\', \\'con\\', \\'ges\\', \\'duq\\', \\'uqu\\', \\'ues\\', \\'esn\\', \\'sni\\', \\' LP\\', \\'LP-\\', \\'P-2\\', \\'-2 \\', \\'P-1\\', \\'eci\\', \\'lur\\', \\'645\\', \\'Cyc\\', \\'ycl\\', \\'cle\\', \\'F19\\', \\'265\\', \\'Ict\\', \\'bub\\', \\'uba\\', \\'719\\', \\'192\\', \\'rip\\', \\'ipl\\', \\'a y\\', \\' ya\\', \\'yar\\', \\'rka\\', \\'kan\\', \\'nde\\', \\'dor\\', \\'ors\\', \\'753\\', \\'Hop\\', \\' LA\\', \\'LAG\\', \\'AGE\\', \\'GEN\\', \\'ENP\\', \\'NPE\\', \\'PE_\\', \\'E_1\\', \\'_11\\', \\'Pia\\', \\'hyp\\', \\'mes\\', \\'goc\\', \\'tte\\', \\'eat\\', \\'obt\\', \\'btu\\', \\'Sal\\', \\'b P\\', \\'Pin\\', \\'si_\\', \\'i_1\\', \\'780\\', \\'ryd\\', \\'isj\\', \\'sju\\', \\'jun\\', \\'agr\\', \\'Hor\\', \\'53-\\', \\'Bag\\', \\'s y\\', \\'rel\\', \\'526\\', \\'26-\\', \\'Cre\\', \\'log\\', \\'215\\', \\'Euc\\', \\'shi\\', \\'nou\\', \\'ouy\\', \\'uye\\', \\'yei\\', \\' Gl\\', \\'Gly\\', \\'rno\\', \\'non\\', \\'876\\', \\'tot\\', \\'x f\\', \\'fok\\', \\'oki\\', \\'kie\\', \\'956\\', \\'375\\', \\'Syn\\', \\'yno\\', \\'833\\', \\'Mal\\', \\'lap\\', \\'lec\\', \\'ctr\\', \\'Sil\\', \\'2 W\\', \\'Wal\\', \\'ago\\', \\'o a\\', \\'tu \\', \\'Cla\\', \\'iep\\', \\'714\\', \\'7-6\\', \\' Ta\\', \\'Tan\\', \\'CES\\', \\'ES-\\', \\'S-0\\', \\'opn\\', \\'pne\\', \\'649\\', \\'497\\', \\' Ai\\', \\'Ail\\', \\'coi\\', \\'Gen\\', \\'nid\\', \\'Net\\', \\' RB\\', \\'RB1\\', \\'B14\\', \\'4-A\\', \\'-A0\\', \\'A04\\', \\'eob\\', \\'vac\\', \\'hel\\', \\'1-6\\', \\'1 R\\', \\'Rit\\', \\'721\\', \\'dig\\', \\'n h\\', \\':50\\', \\'-65\\', \\'tys\\', \\'Sor\\', \\'im \\', \\'m l\\', \\'Lop\\', \\'nog\\', \\'bou\\', \\'oud\\', \\'ude\\', \\'2 I\\', \\'fur\\', \\'urc\\', \\'rca\\', \\':63\\', \\'-78\\', \\'386\\', \\'Pyl\\', \\' ol\\', \\'n N\\', \\'_F1\\', \\'78 \\', \\'Ame\\', \\'mei\\', \\'eiu\\', \\'-37\\', \\'neb\\', \\'ebu\\', \\'650\\', \\' gy\\', \\'gyr\\', \\'Glo\\', \\'lax\\', \\'xia\\', \\'ted\\', \\'6-3\\', \\'umn\\', \\'207\\', \\'762\\', \\'clu\\', \\'eaf\\', \\'afo\\', \\'764\\', \\'piu\\', \\'dra\\', \\'m w\\', \\' wi\\', \\'wil\\', \\'iam\\', \\'ams\\', \\'mso\\', \\'cic\\', \\'305\\', \\'hym\\', \\'yma\\', \\'e K\\', \\' K-\\', \\'K-2\\', \\'2 v\\', \\'r K\\', \\'-80\\', \\'tug\\', \\'uga\\', \\' On\\', \\'Onc\\', \\'gor\\', \\'ket\\', \\'eta\\', \\'utc\\', \\'ch \\', \\'8-8\\', \\'myk\\', \\'yki\\', \\'ss \\', \\'861\\', \\'615\\', \\'ka \\', \\'5-8\\', \\' ts\\', \\'tsh\\', \\'haw\\', \\'awy\\', \\'wyt\\', \\'yts\\', \\'100\\', \\'mo \\', \\'o t\\', \\'960\\', \\'6-8\\', \\'o s\\', \\'ar \\', \\'alp\\', \\' SM\\', \\'SMK\\', \\'MK3\\', \\'K33\\', \\'436\\', \\'36-\\', \\'fon\\', \\'lma\\', \\'nam\\', \\'ayc\\', \\'ycu\\', \\'ush\\', \\'h s\\', \\'0-6\\', \\'990\\', \\'Eso\\', \\'x l\\', \\'Dal\\', \\' Um\\', \\'Umb\\', \\'mi \\', \\'b U\\', \\' Ul\\', \\'Uli\\', \\'mi_\\', \\' py\\', \\'pyg\\', \\'ygm\\', \\'aea\\', \\'nip\\', \\'Osm\\', \\'sme\\', \\' ep\\', \\'DM2\\', \\'M24\\', \\'-07\\', \\'4 T\\', \\'Tha\\', \\'UW1\\', \\'W15\\', \\'372\\', \\'075\\', \\' Re\\', \\'Ret\\', \\' GU\\', \\'GUB\\', \\'UB4\\', \\'B43\\', \\'Sau\\', \\'ndo\\', \\'osq\\', \\'squ\\', \\'uam\\', \\'hlo\\', \\' ag\\', \\'siz\\', \\'izi\\', \\':56\\', \\'-72\\', \\'220\\', \\'esp\\', \\'spl\\', \\' SI\\', \\'SIO\\', \\'IO:\\', \\'O:1\\', \\':1a\\', \\'1ad\\', \\'adf\\', \\'dfa\\', \\'fa4\\', \\'a41\\', \\'5-5\\', \\'-54\\', \\'43a\\', \\'3a-\\', \\'a-4\\', \\'48f\\', \\'8f-\\', \\'f-b\\', \\'-b0\\', \\'b0d\\', \\'0de\\', \\'de-\\', \\'e-3\\', \\'-33\\', \\'33f\\', \\'3fa\\', \\'fab\\', \\'ba0\\', \\'a0c\\', \\'0cb\\', \\'cb4\\', \\'b4e\\', \\'4e6\\', \\'e6 \\', \\'49.\\', \\'mex\\', \\'xic\\', \\'SUL\\', \\'ULA\\', \\'LA \\', \\'A 1\\', \\' 16\\', \\'Ben\\', \\' pt\\', \\'634\\', \\'874\\', \\'arl\\', \\'rls\\', \\'sbe\\', \\'gi \\', \\'Myc\\', \\'yct\\', \\'m a\\', \\'gut\\', \\'rco\\', \\' om\\', \\'556\\', \\'Aph\\', \\'phr\\', \\'red\\', \\'dod\\', \\'say\\', \\'aya\\', \\'All\\', \\'cyt\\', \\'ytt\\', \\'319\\', \\'7 Z\\', \\'Zeu\\', \\'tog\\', \\'gad\\', \\'adu\\', \\'Bor\\', \\'reo\\', \\'sai\\', \\'aid\\', \\' SA\\', \\'SAC\\', \\'ACD\\', \\'CD1\\', \\'D10\\', \\'995\\', \\'Gad\\', \\'lco\\', \\'cog\\', \\'ogr\\', \\'mmu\\', \\'hua\\', \\'Mic\\', \\'pou\\', \\'out\\', \\'sou\\', \\'ou \\', \\'Mel\\', \\'egl\\', \\'gle\\', \\'lef\\', \\'ire\\', \\'523\\', \\'Bro\\', \\'osm\\', \\'me \\', \\'DM8\\', \\'M85\\', \\'Lot\\', \\'Mol\\', \\'olv\\', \\' dy\\', \\'dyp\\', \\'ygi\\', \\'MUB\\', \\'UB:\\', \\'B:2\\', \\'hae\\', \\':40\\', \\'Coe\\', \\'oel\\', \\'ael\\', \\'513\\', \\'rlu\\', \\'hub\\', \\'ubb\\', \\'bbs\\', \\'bsi\\', \\'x d\\', \\'cad\\', \\'ada\\', \\'ylu\\', \\'x s\\', \\'n d\\', \\'iad\\', \\'22-\\', \\'981\\', \\'apu\\', \\' be\\', \\'rmu\\', \\'mud\\', \\'7 K\\', \\' Ku\\', \\'Kur\\', \\'urt\\', \\'Les\\', \\'sue\\', \\'ueu\\', \\'eur\\', \\'M41\\', \\' NR\\', \\'NRM\\', \\'RM:\\', \\'M:N\\', \\':NR\\', \\'RM6\\', \\'M69\\', \\'435\\', \\'bru\\', \\'unn\\', \\'rcc\\', \\'cot\\', \\'Bol\\', \\'nir\\', \\'432\\', \\'72 \\', \\'910\\', \\'Tae\\', \\'ioi\\', \\' CH\\', \\'CH1\\', \\'H1 \\', \\'Hip\\', \\'mpu\\', \\'kud\\', \\'s z\\', \\' zo\\', \\'zos\\', \\'hyl\\', \\'ngn\\', \\'hoi\\', \\'pax\\', \\' Fi\\', \\'759\\', \\'Mul\\', \\'mul\\', \\' Up\\', \\'Upe\\', \\'lph\\', \\'ure\\', \\' S1\\', \\'9 U\\', \\'met\\', \\'heu\\', \\'725\\', \\'r a\\', \\'r c\\', \\'r j\\', \\'773\\', \\'cyb\\', \\'ybi\\', \\'omo\\', \\'cav\\', \\'887\\', \\'sie\\', \\'CGR\\', \\'RAG\\', \\'NM \\', \\'M 4\\', \\' 44\\', \\'756\\', \\'M36\\', \\'631\\', \\'Aux\\', \\'xis\\', \\'632\\', \\'787\\', \\'haz\\', \\'aza\\', \\'rd \\', \\'d m\\', \\'Eut\\', \\'ynn\\', \\'1 K\\', \\'ats\\', \\'suw\\', \\'uwo\\', \\'won\\', \\'341\\', \\'891\\', \\'Thu\\', \\'hun\\', \\'lal\\', \\'lun\\', \\'ga \\', \\'Tal\\', \\'lt-\\', \\'t-U\\', \\'-UN\\', \\'UNA\\', \\'NAL\\', \\'AL-\\', \\'L-0\\', \\'coy\\', \\'oyi\\', \\'yii\\', \\'CTN\\', \\'TNT\\', \\'TAN\\', \\'ANC\\', \\'NCC\\', \\'TNG\\', \\'NGC\\', \\'TGN\\', \\'GNC\\', \\'NCA\\', \\'CCN\\', \\'CNG\\', \\'NGG\\', \\'GTN\\', \\'ATN\\', \\'TTN\\', \\'TN\\\\n\\', \\'N\\\\nA\\', \\'AAN\\', \\'NCT\\', \\'NGA\\', \\'1.2\\', \\'ngg\\', \\'ggo\\', \\'ol \\', \\'l m\\', \\'rbo\\', \\'bo \\', \\'791\\', \\'anh\\', \\'hai\\', \\'aie\\', \\'Ari\\', \\'Pam\\', \\'Pep\\', \\'epr\\', \\'562\\', \\'Arr\\', \\'Mas\\', \\'cem\\', \\'emb\\', \\'Mon\\', \\'Ana\\', \\'nab\\', \\'tud\\', \\'Bet\\', \\'2 O\\', \\'Osp\\', \\'my \\', \\'620\\', \\'uis\\', \\' dj\\', \\'dje\\', \\'jed\\', \\' kl\\', \\'kle\\', \\'622\\', \\'Atu\\', \\'anx\\', \\'nx \\', \\'x i\\', \\' ig\\', \\'gno\\', \\'Dec\\', \\'rua\\', \\'ads\\', \\'dsi\\', \\'rdy\\', \\'dyl\\', \\'Sel\\', \\'cru\\', \\'184\\', \\'roi\\', \\'Tra\\', \\' sy\\', \\'sym\\', \\'ymm\\', \\'O:2\\', \\'78a\\', \\'8a0\\', \\'a01\\', \\'17c\\', \\'7c-\\', \\'c-d\\', \\'-da\\', \\'da5\\', \\'a54\\', \\'-4e\\', \\'4e2\\', \\'e27\\', \\'7-a\\', \\'-aa\\', \\'aaa\\', \\'aad\\', \\'ad-\\', \\'d-3\\', \\'-31\\', \\'31e\\', \\'1e6\\', \\'e69\\', \\'69e\\', \\'9e5\\', \\'e5b\\', \\'5bd\\', \\'bd2\\', \\'d24\\', \\'681\\', \\'ucr\\', \\'uct\\', \\'870\\', \\'Ser\\', \\'869\\', \\'868\\', \\'inq\\', \\'nqu\\', \\'uer\\', \\'nei\\', \\'eis\\', \\'Lac\\', \\'Men\\', \\'Rac\\', \\'hyc\\', \\'nad\\', \\'cud\\', \\'jel\\', \\'o v\\', \\'r E\\', \\' EC\\', \\'ECS\\', \\'CSF\\', \\'SFR\\', \\'FRI\\', \\'RI-\\', \\'I-B\\', \\'-BM\\', \\'BMY\\', \\'MY0\\', \\'Y00\\', \\'6 X\\', \\' Xi\\', \\'Xip\\', \\'lad\\', \\'675\\', \\'Mak\\', \\'aka\\', \\'kai\\', \\'Ist\\', \\'678\\', \\'Tet\\', \\'A v\\', \\' MA\\', \\'MAN\\', \\'ANI\\', \\'NI0\\', \\'I00\\', \\'pfl\\', \\'lue\\', \\'ueg\\', \\'ege\\', \\'B v\\', \\' TE\\', \\'TEP\\', \\'EPF\\', \\'PF0\\', \\'F00\\', \\'rif\\', \\' A5\\', \\'A51\\', \\'922\\', \\'nol\\', \\'Rei\\', \\'dub\\', \\'sod\\', \\'765\\', \\'Ath\\', \\' ev\\', \\'eve\\', \\'Cle\\', \\'erz\\', \\'rze\\', \\'zen\\', \\' Eo\\', \\'Eop\\', \\' jo\\', \\'jor\\', \\'807\\', \\'chn\\', \\'hne\\', \\'lyx\\', \\'yxy\\', \\'xys\\', \\'vet\\', \\'Ple\\', \\'9 K\\', \\'Kar\\', \\'966\\', \\'nec\\', \\':42\\', \\'977\\', \\'777\\', \\' yo\\', \\'yok\\', \\'oko\\', \\'koh\\', \\'ham\\', \\'5 V\\', \\' Ve\\', \\'Ver\\', \\'6 V\\', \\'Col\\', \\':61\\', \\'-76\\', \\'Cyn\\', \\' ab\\', \\'abb\\', \\'bbr\\', \\'873\\', \\'915\\', \\' za\\', \\'anz\\', \\'zib\\', \\'ymp\\', \\'usa\\', \\'myc\\', \\'Sol\\', \\'zii\\', \\'Abu\\', \\'bud\\', \\'def\\', \\'efd\\', \\'fdu\\', \\'duf\\', \\'uf \\', \\'f v\\', \\'vai\\', \\'aig\\', \\'gie\\', \\'Ald\\', \\'ldr\\', \\'rst\\', \\'Che\\', \\'Mug\\', \\'l c\\', \\' Oe\\', \\'Oed\\', \\'dal\\', \\'382\\', \\'842\\', \\'Cic\\', \\'Cop\\', \\'n z\\', \\' zi\\', \\'zil\\', \\'3 O\\', \\'sam\\', \\'lil\\', \\'uno\\', \\'nui\\', \\'boe\\', \\'-02\\', \\'387\\', \\'Ory\\', \\'ryz\\', \\'yzi\\', \\'zia\\', \\'Abl\\', \\' Ty\\', \\'Tyl\\', \\'oco\\', \\'dil\\', \\'lol\\', \\'bis\\', \\'sig\\', \\'gni\\', \\'n u\\', \\'516\\', \\'obr\\', \\'urz\\', \\'zer\\', \\':60\\', \\'-75\\', \\'754\\', \\'7 F\\', \\' Fu\\', \\'Fun\\', \\'hax\\', \\'x g\\', \\'rdn\\', \\'dne\\', \\'n U\\', \\' Ud\\', \\'Udi\\', \\'mou\\', \\'oun\\', \\'unt\\', \\'tai\\', \\':62\\', \\'-77\\', \\'782\\', \\'2 K\\', \\' Kr\\', \\'Kry\\', \\'leb\\', \\'ebi\\', \\'855\\', \\'4-8\\', \\'Mil\\', \\'3 F\\', \\' CC\\', \\'CC-\\', \\'236\\', \\'9 F\\', \\'8 F\\', \\'isp\\', \\'312\\', \\'ocl\\', \\'cli\\', \\'1 F\\', \\'b F\\', \\' Fn\\', \\'Fno\\', \\'625\\', \\' ib\\', \\'bov\\', \\' N-\\', \\'N-3\\', \\'-32\\', \\'2 J\\', \\' Jo\\', \\'Jor\\', \\' ho\\', \\'hol\\', \\'olb\\', \\'lbr\\', \\'roo\\', \\'ook\\', \\'b G\\', \\' Gh\\', \\'Gho\\', \\'ki_\\', \\'Poe\\', \\'e 2\\', \\'3 X\\', \\'623\\', \\'Ger\\', \\' oy\\', \\'oye\\', \\'yen\\', \\'Amm\\', \\'mmo\\', \\'mod\\', \\'ody\\', \\'dyt\\', \\'hex\\', \\'xap\\', \\'Cen\\', \\'exo\\', \\'xol\\', \\'M34\\', \\'302\\', \\'612\\', \\'5 X\\', \\'hty\\', \\'nov\\', \\'ova\\', \\'eol\\', \\'x j\\', \\'Dic\\', \\' DL\\', \\'DLm\\', \\'Lmg\\', \\'mgm\\', \\'gm5\\', \\'m57\\', \\' DP\\', \\'DP4\\', \\'P4M\\', \\'4M \\', \\'M m\\', \\'e a\\', \\'sax\\', \\'axa\\', \\'aet\\', \\'x o\\', \\'rgy\\', \\'nib\\', \\'be \\', \\'e W\\', \\' WL\\', \\'WL2\\', \\'L20\\', \\'n j\\', \\'jam\\', \\'mai\\', \\'aic\\', \\'eia\\', \\'lya\\', \\'yac\\', \\'bea\\', \\'Sci\\', \\'Tot\\', \\'toa\\', \\'oab\\', \\'acd\\', \\'cdo\\', \\'ald\\', \\'ldi\\', \\'egu\\', \\'Zeb\\', \\'ebr\\', \\'aso\\', \\'Nas\\', \\'401\\', \\'xac\\', \\' Em\\', \\'Emm\\', \\'nit\\', \\'CSI\\', \\'SIR\\', \\'IRO\\', \\'RO \\', \\'O H\\', \\' H4\\', \\'H42\\', \\'4-0\\', \\'iog\\', \\'oge\\', \\'eio\\', \\' NZ\\', \\'NZ \\', \\'Z P\\', \\' P.\\', \\'P.0\\', \\'.04\\', \\'904\\', \\'Lei\\', \\'ruc\\', \\'7 G\\', \\'Gaz\\', \\'azz\\', \\'zza\\', \\'za \\', \\' im\\', \\'imp\\', \\'Con\\', \\'n n\\', \\'das\\', \\'sys\\', \\'kaa\\', \\'aak\\', \\'Lut\\', \\'utj\\', \\'tja\\', \\'jan\\', \\'rpo\\', \\'916\\', \\'lvi\\', \\'vif\\', \\'ifl\\', \\'kas\\', \\'737\\', \\'seb\\', \\'syn\\', \\'yna\\', \\'nag\\', \\'Ocy\\', \\'cyu\\', \\'ysu\\', \\'mbo\\', \\'ben\\', \\'Lob\\', \\'Nem\\', \\'624\\', \\'aeo\\', \\'o j\\', \\'sih\\', \\'iha\\', \\'854\\', \\'Den\\', \\'Pag\\', \\':67\\', \\'-83\\', \\'rav\\', \\'veo\\', \\'209\\', \\'185\\', \\'hle\\', \\' SZ\\', \\'SZN\\', \\'ZN-\\', \\'N-O\\', \\'-OS\\', \\'OST\\', \\'ST-\\', \\'T-0\\', \\'erv\\', \\'rvi\\', \\'fro\\', \\'GCR\\', \\'CRC\\', \\'maj\\', \\'ajo\\', \\'616\\', \\'Rha\\', \\'bdo\\', \\'Spa\\', \\'Sig\\', \\'389\\', \\'tay\\', \\'Cap\\', \\'tep\\', \\'ceo\\', \\'Doe\\', \\'oed\\', \\'rle\\', \\'ryc\\', \\'yco\\', \\'Pem\\', \\'emp\\', \\'chw\\', \\'hwe\\', \\'wen\\', \\'cim\\', \\'en_\\', \\'n_v\\', \\'_vo\\', \\'er:\\', \\'r: \\', \\': K\\', \\' KP\\', \\'KPM\\', \\'PM-\\', \\'M-N\\', \\'-NI\\', \\'NI:\\', \\'I:3\\', \\':37\\', \\'39\\\\n\\', \\'9\\\\nG\\', \\'ilb\\', \\'ert\\', \\'mox\\', \\' Pn\\', \\'Pni\\', \\'dol\\', \\'lom\\', \\'mie\\', \\'ieu\\', \\'eu \\', \\'moi\\', \\'b L\\', \\' Lg\\', \\'Lgi\\', \\'-21\\', \\'4.2\\', \\'SMC\\', \\'MCr\\', \\'Cr-\\', \\'r-1\\', \\'Ela\\', \\'Gir\\', \\'314\\', \\'neo\\', \\'Bos\\', \\'ock\\', \\'kia\\', \\' ik\\', \\'ike\\', \\'kei\\', \\'e E\\', \\' EF\\', \\'FC0\\', \\'pee\\', \\'eel\\', \\'ia,\\', \\'a, \\', \\'acq\\', \\'cqu\\', \\'uar\\', \\'igu\\', \\'vem\\', \\'Nan\\', \\'A21\\', \\'tsi\\', \\' kn\\', \\'kne\\', \\'Ter\\', \\'jar\\', \\'bua\\', \\'Cep\\', \\' Ep\\', \\'Epi\\', \\'niv\\', \\'vea\\', \\'tof\\', \\'ofa\\', \\'scr\\', \\'rib\\', \\'C-4\\', \\'cie\\', \\' WW\\', \\'WW-\\', \\'W-1\\', \\' sh\\', \\'shu\\', \\'W-8\\', \\'-8 \\', \\'pre\\', \\'heo\\', \\'eos\\', \\'F18\\', \\'28_\\', \\'8_ \\', \\'_ m\\', \\'olm\\', \\'lms\\', \\'mst\\', \\'San\\', \\'b S\\', \\' Sv\\', \\'Svi\\', \\' ir\\', \\'irw\\', \\'rwi\\', \\'iic\\', \\'Dol\\', \\'idr\\', \\'co \\', \\'o l\\', \\'ged\\', \\' sk\\', \\'sko\\', \\'kot\\', \\'tts\\', \\'tsb\\', \\'hea\\', \\'odr\\', \\'o w\\', \\'mps\\', \\'gun\\', \\'ysc\\', \\'dew\\', \\'wit\\', \\'mye\\', \\'ryo\\', \\'lov\\', \\'n R\\', \\' R0\\', \\'R01\\', \\'e I\\', \\'ICT\\', \\'CTI\\', \\'TI1\\', \\'I11\\', \\'bbe\\', \\'ndb\\', \\'dbe\\', \\'dif\\', \\'got\\', \\'bor\\', \\'orc\\', \\'chg\\', \\'hgr\\', \\'ink\\', \\'Tre\\', \\' eu\\', \\'eul\\', \\'nso\\', \\':76\\', \\'6-9\\', \\'loe\\', \\'nnb\\', \\'nbe\\', \\'new\\', \\'ewn\\', \\'wne\\', \\'826\\', \\'kum\\', \\'umu\\', \\'mu \\', \\'779\\', \\'Seb\\', \\' C0\\', \\'C0H\\', \\'0HG\\', \\'HG3\\', \\'G3A\\', \\'3AC\\', \\'AC \\', \\'bab\\', \\'abc\\', \\'bco\\', \\'coc\\', \\'776\\', \\' 40\\', \\'821\\', \\'roa\\', \\'817\\', \\'goo\\', \\'dei\\', \\' ko\\', \\'kor\\', \\'ean\\', \\'orv\\', \\'rve\\', \\'veg\\', \\'pau\\', \\'ysp\\', \\'ree\\', \\'eed\\', \\'enb\\', \\'nbl\\', \\'acz\\', \\'cza\\', \\'now\\', \\'wsk\\', \\'ski\\', \\' 26\\', \\'viv\\', \\'ipa\\', \\'zac\\', \\'ois\\', \\' In\\', \\'Ini\\', \\'nim\\', \\'nif\\', \\' BS\\', \\'BS0\\', \\'S02\\', \\'upu\\', \\'609\\', \\'r i\\', \\'LAB\\', \\'AB0\\', \\'B01\\', \\'9 Z\\', \\' Zo\\', \\'Zoa\\', \\'oar\\', \\'ces\\', \\'6 Z\\', \\'Sti\\', \\'orj\\', \\'rje\\', \\'jew\\', \\'wi \\', \\' SG\\', \\'SG1\\', \\'G17\\', \\'-7 \\', \\'fan\\', \\'TGR\\', \\'GRG\\', \\'RGC\\', \\'Gas\\', \\' Pu\\', \\'Pun\\', \\'Ape\\', \\'s q\\', \\'pty\\', \\'dyb\\', \\'bow\\', \\'Hex\\', \\'xag\\', \\'DMA\\', \\'MA,\\', \\', i\\', \\'te:\\', \\'e: \\', \\': H\\', \\' HA\\', \\'HA-\\', \\'A-Y\\', \\'-YT\\', \\'YT-\\', \\'T-2\\', \\'12\\\\n\\', \\'2\\\\nG\\', \\'ump\\', \\'16N\\', \\'6NC\\', \\'NCL\\', \\'CLU\\', \\'LU3\\', \\'U34\\', \\'Myo\\', \\'yox\\', \\'xoc\\', \\'Cot\\', \\'b C\\', \\' Cb\\', \\'Cba\\', \\'ii_\\', \\'onf\\', \\'nfu\\', \\'fus\\', \\'usu\\', \\'kla\\', \\'olk\\', \\'lki\\', \\' CV\\', \\'CVO\\', \\'VO4\\', \\'O45\\', \\'det\\', \\'rme\\', \\'Ble\\', \\'tim\\', \\'Bou\\', \\'oul\\', \\'Typ\\', \\'phl\\', \\'Der\\', \\'And\\', \\'dav\\', \\'913\\', \\'Hyn\\', \\'kim\\', \\'CIB\\', \\'IB-\\', \\'B-X\\', \\'-XM\\', \\'XM3\\', \\'M31\\', \\'elp\\', \\'lpa\\', \\'pae\\', \\'330\\', \\'hyh\\', \\'yhy\\', \\'ngc\\', \\'gch\\', \\'Ran\\', \\'sib\\', \\'ibi\\', \\'bir\\', \\'key\\', \\'eys\\', \\'rli\\', \\'sli\\', \\'680\\', \\'Gyr\\', \\' Gp\\', \\'Gpa\\', \\'-67\\', \\'Ane\\', \\'GNA\\', \\'NAC\\', \\'GNT\\', \\'Des\\', \\'esm\\', \\'mog\\', \\'Ens\\', \\'nsa\\', \\' es\\', \\'chs\\', \\'hsc\\', \\'olt\\', \\'ltz\\', \\'289\\', \\'Pha\\', \\'hti\\', \\'hya\\', \\'bys\\', \\'yci\\', \\'asa\\', \\'fi \\', \\'871\\', \\'dob\\', \\'ogi\\', \\'sot\\', \\'ngk\\', \\'gko\\', \\'kon\\', \\'Aly\\', \\'lyt\\', \\'bst\\', \\':96\\', \\'Fej\\', \\'jer\\', \\'rva\\', \\'r z\\', \\' zj\\', \\'zjb\\', \\'jbj\\', \\'bj3\\', \\'j3 \\', \\':73\\', \\'3-8\\', \\'-89\\', \\'1 X\\', \\' Xe\\', \\'Xen\\', \\'368\\', \\':80\\', \\'0-9\\', \\'-96\\', \\'Hyl\\', \\'axy\\', \\'yru\\', \\'841\\', \\'Buf\\', \\'ufo\\', \\'fo \\', \\'riz\\', \\'iza\\', \\'882\\', \\'2-9\\', \\'fot\\', \\'zam\\', \\'amd\\', \\'mda\\', \\'add\\', \\'dde\\', \\':69\\', \\'-84\\', \\'ohy\\', \\'Pyx\\', \\' ad\\', \\'dsp\\', \\'hly\\', \\'lyc\\', \\'xad\\', \\'rke\\', \\'aih\\', \\'eim\\', \\'Amo\\', \\'ntz\\', \\'tzo\\', \\'zor\\', \\'esb\\', \\'bei\\', \\' Od\\', \\'Odo\\', \\'aha\\', \\'bed\\', \\'edr\\', \\'iag\\', \\'e G\\', \\' GM\\', \\'GM-\\', \\'M-J\\', \\'-J0\\', \\'J01\\', \\':85\\', \\'e M\\', \\' MP\\', \\'MPF\\', \\'PFC\\', \\'FC1\\', \\'C13\\', \\':79\\', \\'ony\\', \\'nyx\\', \\'ubl\\', \\'Ema\\', \\'ac3\\', \\'c3 \\', \\'Cyr\\', \\'rto\\', \\'Gek\\', \\'ekk\\', \\'kko\\', \\'hok\\', \\'kou\\', \\'oue\\', \\'gec\\', \\'eck\\', \\'cko\\', \\'noe\\', \\'oei\\', \\'888\\', \\'835\\', \\'n e\\', \\'Asp\\', \\'exs\\', \\'xsa\\', \\' AS\\', \\'ASH\\', \\'SH0\\', \\'H07\\', \\'SH1\\', \\'H14\\', \\'824\\', \\'exl\\', \\'xli\\', \\' KL\\', \\'KLC\\', \\'LC1\\', \\'C15\\', \\'r A\\', \\' AK\\', \\'AKL\\', \\'KL2\\', \\'L28\\', \\'osk\\', \\' UJ\\', \\'UJ-\\', \\'J-L\\', \\'-La\\', \\'ac-\\', \\'c-0\\', \\'-04\\', \\'Ere\\', \\'Dar\\', \\'evs\\', \\'vsk\\', \\'rko\\', \\'erj\\', \\'rju\\', \\'jug\\', \\'arv\\', \\'rvu\\', \\'rud\\', \\'rta\\', \\'Pod\\', \\'243\\', \\':51\\', \\'-66\\', \\'Bas\\', \\'LB1\\', \\'B18\\', \\' Ig\\', \\'Igu\\', \\'wis\\', \\'liz\\', \\'ize\\', \\'Sce\\', \\'occ\\', \\' Ut\\', \\'Uta\\', \\'nsb\\', \\'sbu\\', \\'UWB\\', \\'WBM\\', \\'BM \\', \\' 76\\', \\'2-8\\', \\'Boa\\', \\'Pyt\\', \\'1 V\\', \\' Vi\\', \\'Vip\\', \\'Dab\\', \\'boi\\', \\'oia\\', \\' Ag\\', \\'Agk\\', \\'gki\\', \\'civ\\', \\'ivo\\', \\'vor\\', \\'Sis\\', \\'Ner\\', \\'lub\\', \\' PC\\', \\'PCC\\', \\'CCI\\', \\'CI_\\', \\'I_R\\', \\'_R4\\', \\'R4 \\', \\'Ort\\', \\'Emy\\', \\' ij\\', \\'iji\\', \\'jim\\', \\' EI\\', \\'EIJ\\', \\'IJ \\', \\'J m\\', \\'viu\\', \\'912\\', \\'sub\\', \\'ruf\\', \\'ufa\\', \\'fa \\', \\'384\\', \\'Els\\', \\'lse\\', \\'sey\\', \\'eya\\', \\'lb_\\', \\'b_1\\', \\'_18\\', \\'Eld\\', \\'n_2\\', \\'_25\\', \\'Elu\\', \\' MR\\', \\'MRT\\', \\'RT4\\', \\'T4 \\', \\'ydu\\', \\'ac_\\', \\'c_A\\', \\'_AA\\', \\'AA3\\', \\'A33\\', \\'vic\\', \\'Emv\\', \\'mvi\\', \\'ic_\\', \\'c_2\\', \\'_24\\', \\'Myu\\', \\'yuc\\', \\'ely\\', \\'Myb\\', \\'ybe\\', \\'el_\\', \\'l_1\\', \\'_17\\', \\'emy\\', \\'r P\\', \\'um_\\', \\'m_A\\', \\'AA6\\', \\'A65\\', \\'nsc\\', \\'lpt\\', \\'Apa\\', \\'iun\\', \\'198\\', \\'lyd\\', \\'ydr\\', \\'GG-\\', \\'G-0\\', \\'01L\\', \\'1Lo\\', \\'Nat\\', \\'dep\\', \\'rou\\', \\'oup\\', \\'up \\', \\'p A\\', \\'Au \\', \\'u (\\', \\' (X\\', \\'(X)\\', \\'X) \\', \\') m\\', \\'yda\\', \\'etm\\', \\'tmo\\', \\':93\\', \\'gac\\', \\'3.3\\', \\'.3:\\', \\'3:5\\', \\' Gr\\', \\'Gra\\', \\'uac\\', \\'onc\\', \\'nin\\', \\'lda\\', \\'tea\\', \\'e e\\', \\'Psa\\', \\'Tes\\', \\'aec\\', \\'Mau\\', \\'Cai\\', \\'Pal\\', \\'suc\\', \\'peb\\', \\'856\\', \\'Gav\\', \\'get\\', \\'Tom\\', \\'8.2\\', \\'321\\', \\'joh\\', \\'ohn\\', \\'hns\\', \\'TAR\\', \\'ART\\', \\'RTC\\', \\'CTK\\', \\'TKC\\', \\'KCT\\', \\'CCY\\', \\'CYC\\', \\'AAY\\', \\'AYC\\', \\'YC\\\\n\\', \\'CTR\\', \\'TRA\\', \\'RAA\\', \\'Mec\\', \\'aem\\', \\'Rhe\\', \\' Dr\\', \\'Dro\\', \\'aiu\\', \\'vae\\', \\'aeh\\', \\'eho\\', \\'sua\\', \\' Nu\\', \\'Num\\', \\'eag\\', \\' 19\\', \\'pep\\', \\'epl\\', \\' sq\\', \\'Lag\\', \\'mut\\', \\'M 5\\', \\' 51\\', \\'pav\\', \\'avo\\', \\'vo \\', \\'591\\', \\'655\\', \\'olc\\', \\'Pav\\', \\' bG\\', \\'bGa\\', \\'alG\\', \\'lGa\\', \\'al1\\', \\'l1 \\', \\'ce,\\', \\', w\\', \\' wh\\', \\'who\\', \\'sho\\', \\'otg\\', \\'tgu\\', \\'un \\', \\'huk\\', \\'uka\\', \\'nix\\', \\'aog\\', \\'lay\\', \\' TH\\', \\'THI\\', \\'HIM\\', \\'IM2\\', \\'M20\\', \\'hye\\', \\'yem\\', \\' RE\\', \\'REW\\', \\'EW5\\', \\'W53\\', \\' UA\\', \\'UAM\\', \\'AMX\\', \\'MX1\\', \\'X14\\', \\'Cyg\\', \\'gnu\\', \\'Ans\\', \\' Ay\\', \\'Ayt\\', \\'r J\\', \\' JS\\', \\'JS0\\', \\'S04\\', \\'Aix\\', \\'3 Z\\', \\'Zen\\', \\'nai\\', \\'our\\', \\'cao\\', \\'aoc\\', \\'to \\', \\'978\\', \\'hag\\', \\'see\\', \\'ccy\\', \\'cyx\\', \\'Ard\\', \\'rde\\', \\'deo\\', \\' Ot\\', \\'Oti\\', \\'Pso\\', \\'cre\\', \\'Gru\\', \\'Ant\\', \\'poi\\', \\'6 J\\', \\'Jac\\', \\' ST\\', \\'STR\\', \\'TRI\\', \\'RI:\\', \\'I:B\\', \\':BC\\', \\'BC3\\', \\'C33\\', \\'CCM\\', \\'MCC\\', \\'ACM\\', \\'mas\\', \\', p\\', \\'TNA\\', \\'NAA\\', \\'GNN\\', \\'NN\\\\n\\', \\'N\\\\nN\\', \\'\\\\nNN\\', \\'NNA\\', \\'NAG\\', \\'NAT\\', \\'2.2\\', \\'Are\\', \\'rpr\\', \\' JJ\\', \\'JJW\\', \\'JW1\\', \\'W11\\', \\'GCY\\', \\'CYA\\', \\'YAT\\', \\'pug\\', \\'ugn\\', \\'r D\\', \\' DD\\', \\'DDG\\', \\'DG1\\', \\'G19\\', \\'IN4\\', \\'N46\\', \\'Ony\\', \\'nyc\\', \\' NI\\', \\'NIB\\', \\'IBR\\', \\'RGR\\', \\'GR0\\', \\'R00\\', \\'sae\\', \\'Gel\\', \\'dib\\', \\'bun\\', \\'dom\\', \\'Ris\\', \\' MK\\', \\'MKP\\', \\'KP9\\', \\'P99\\', \\'0 v\\', \\' RO\\', \\'ROM\\', \\'OM:\\', \\'M:O\\', \\':OR\\', \\'ORN\\', \\'RN:\\', \\'N:1\\', \\'sit\\', \\'KP1\\', \\'P15\\', \\'9 v\\', \\'sku\\', \\'kua\\', \\'3 v\\', \\'ick\\', \\'Hae\\', \\'4 V\\', \\'Van\\', \\'van\\', \\'r 1\\', \\' 18\\', \\'-24\\', \\'voc\\', \\'oci\\', \\'Plu\\', \\'Aeg\\', \\'yps\\', \\'fum\\', \\' LG\\', \\'LGE\\', \\'GEM\\', \\'EMA\\', \\'MA \\', \\'Aer\\', \\'amu\\', \\'fuc\\', \\'Apu\\', \\'979\\', \\' ju\\', \\'jub\\', \\'899\\', \\'eip\\', \\' 15\\', \\'imm\\', \\'he \\', \\'Hyd\\', \\'Oce\\', \\'Apt\\', \\'old\\', \\'ldt\\', \\'Eud\\', \\'udy\\', \\'pua\\', \\' 12\\', \\':71\\', \\'-87\\', \\' Fr\\', \\'Fre\\', \\'Sul\\', \\'rex\\', \\'Bub\\', \\'ubu\\', \\'lcu\\', \\' Ny\\', \\'Nyc\\', \\'x n\\', \\' ny\\', \\' Ni\\', \\'Nip\\', \\'esk\\', \\'kio\\', \\'irc\\', \\'613\\', \\' Aq\\', \\'Aqu\\', \\'Acc\\', \\'ilv\\', \\'lvu\\', \\'IN1\\', \\'N15\\', \\'aee\\', \\'eet\\', \\'N17\\', \\'agy\\', \\' Vu\\', \\'Vul\\', \\'ltu\\', \\'ur \\', \\'gry\\', \\'Nin\\', \\'Asi\\', \\'o o\\', \\' ot\\', \\'IN8\\', \\'N83\\', \\'o f\\', \\'meu\\', \\'ubo\\', \\' D1\\', \\'D16\\', \\' X3\\', \\'X3 \\', \\'x u\\', \\' C5\\', \\'C5 \\', \\'Upu\\', \\'pup\\', \\'Ace\\', \\'ead\\', \\'adb\\', \\'390\\', \\'e r\\', \\'lcy\\', \\'cyo\\', \\'yon\\', \\' sm\\', \\'smy\\', \\'myr\\', \\'CMT\\', \\'MTA\\', \\'Pic\\', \\'pub\\', \\'Dry\\', \\'yoc\\', \\'4 J\\', \\' Jy\\', \\'Jyn\\', \\'ynx\\', \\'orq\\', \\'rqu\\', \\' Fa\\', \\'Fal\\', \\'o n\\', \\'aum\\', \\' bF\\', \\'bFa\\', \\'alN\\', \\'lNa\\', \\'au1\\', \\'u1 \\', \\'0 F\\', \\'nun\\', \\'Her\\', \\'cac\\', \\'-82\\', \\'Nes\\', \\'Nym\\', \\'Eol\\', \\'sei\\', \\'Cac\\', \\'tua\\', \\'cce\\', \\'aun\\', \\'una\\', \\'ogu\\', \\'ao \\', \\'Ama\\', \\'maz\\', \\'Myi\\', \\'yio\\', \\'For\\', \\'Psi\\', \\'ttr\\', \\'Aga\\', \\'hog\\', \\'ute\\', \\'sog\\', \\'Ecl\\', \\'eup\\', \\'Mio\\', \\' MJ\\', \\'MJM\\', \\'JM2\\', \\'Tyr\\', \\'sav\\', \\'Lan\\', \\'Cya\\', \\'e 7\\', \\'9.2\\', \\'awa\\', \\'aii\\', \\'iie\\', \\'SB3\\', \\'B33\\', \\'Phu\\', \\'ud-\\', \\'d-1\\', \\'Gar\\', \\'230\\', \\'psa\\', \\' B3\\', \\'B31\\', \\'MMN\\', \\'NH \\', \\'H 4\\', \\' 47\\', \\'e p\\', \\'CEH\\', \\'EH1\\', \\' PM\\', \\'PMO\\', \\'MON\\', \\'ON2\\', \\'N20\\', \\'04V\\', \\'4V1\\', \\'V1 \\', \\'e J\\', \\' J3\\', \\'J3 \\', \\'irp\\', \\'urb\\', \\'Tac\\', \\'eov\\', \\'olz\\', \\'lzm\\', \\'zma\\', \\'Hir\\', \\'cag\\', \\'o F\\', \\'Fie\\', \\'ld \\', \\'d M\\', \\'use\\', \\'m 4\\', \\' 46\\', \\'eox\\', \\'xen\\', \\' B-\\', \\'B-2\\', \\'-23\\', \\'32,\\', \\'2, \\', \\', L\\', \\'Lou\\', \\'oui\\', \\'a S\\', \\'Sta\\', \\'e U\\', \\'ity\\', \\'ytl\\', \\'tle\\', \\' NB\\', \\'NB0\\', \\'B02\\', \\'ahi\\', \\'LSU\\', \\'SU \\', \\'U B\\', \\'B-6\\', \\'Rip\\', \\' SQ\\', \\'SQS\\', \\'QSW\\', \\'SW0\\', \\'W00\\', \\'Syl\\', \\'ylv\\', \\'Zos\\', \\' FL\\', \\'FLD\\', \\'LDO\\', \\'DO-\\', \\'O-T\\', \\'-TT\\', \\'TT0\\', \\'T04\\', \\'lly\\', \\'bit\\', \\'T01\\', \\'Fic\\', \\'ced\\', \\'Oen\\', \\'e o\\', \\' oe\\', \\' Tu\\', \\'Tur\\', \\'urd\\', \\' TM\\', \\'TME\\', \\'MER\\', \\'ER2\\', \\'R20\\', \\'4V3\\', \\'V3 \\', \\'ufi\\', \\'fiv\\', \\'MCP\\', \\'CP \\', \\'P 3\\', \\' 32\\', \\'Bup\\', \\' sv\\', \\'sv0\\', \\'v00\\', \\'Reg\\', \\'Tic\\', \\'pyl\\', \\'BRU\\', \\'RUN\\', \\'UN2\\', \\'yot\\', \\'lud\\', \\'dov\\', \\'Sit\\', \\'Pad\\', \\'dda\\', \\'ziv\\', \\'Pas\\', \\'Mot\\', \\'mea\\', \\'avu\\', \\'Him\\', \\'CGN\\', \\'NNC\\', \\'xop\\', \\'eom\\', \\'yza\\', \\'hou\\', \\'ous\\', \\'ucl\\', \\'Pir\\', \\'e k\\', \\'ku2\\', \\'u26\\', \\'ku7\\', \\'u70\\', \\'upi\\', \\'piz\\', \\'zel\\', \\'Zon\\', \\'kir\\', \\'irt\\', \\'rtl\\', \\'bad\\', \\'Age\\', \\'9 Q\\', \\'Qui\\', \\'0 Q\\', \\'Orn\\', \\'hyg\\', \\'ygl\\', \\'Did\\', \\' Ad\\', \\'Ada\\', \\'dam\\', \\'am \\', \\'m A\\', \\'t m\\', \\'6 I\\', \\'Iso\\', \\'soo\\', \\'Tar\\', \\'irs\\', \\'oep\\', \\'epu\\', \\'Myr\\', \\'yrm\\', \\' IS\\', \\'ISE\\', \\'SEM\\', \\'EM_\\', \\'M_T\\', \\'_T-\\', \\'Tam\\', \\'dua\\', \\'MVZ\\', \\'VZ_\\', \\'Z_1\\', \\'_19\\', \\'T-N\\', \\'-NP\\', \\'NP3\\', \\'P39\\', \\'Tol\\', \\'peu\\', \\'syp\\', \\'emc\\', \\'mci\\', \\'T-3\\', \\'afe\\', \\'gee\\', \\'ees\\', \\'ska\\', \\'ufe\\', \\'fes\\', \\'SMN\\', \\'MNS\\', \\'NS2\\', \\'S23\\', \\'elf\\', \\'lfa\\', \\'fai\\', \\'hec\\', \\' Du\\', \\'Dug\\', \\'ugo\\', \\'ng \\', \\'g d\\', \\'dug\\', \\'Sun\\', \\'Bla\\', \\'pim\\', \\'g m\\', \\'fod\\', \\'ndy\\', \\'yre\\', \\'0.2\\', \\'Eid\\', \\'elv\\', \\'vum\\', \\'Rou\\', \\' CK\\', \\'CKM\\', \\'KM1\\', \\'M10\\', \\'dag\\', \\'UAD\\', \\'ADB\\', \\'DBA\\', \\'BA-\\', \\'A-4\\', \\'-43\\', \\'Epo\\', \\'bue\\', \\'uet\\', \\'tik\\', \\'iko\\', \\'kof\\', \\'ofe\\', \\' G0\\', \\'G09\\', \\'09X\\', \\'9X3\\', \\' MZ\\', \\'MZF\\', \\'ZF1\\', \\'F10\\', \\'meq\\', \\'m q\\', \\'rsh\\', \\' GX\\', \\'GX0\\', \\'X07\\', \\'Mys\\', \\'r Q\\', \\' QC\\', \\'QCA\\', \\'CAZ\\', \\'AZ:\\', \\'Z:1\\', \\':18\\', \\'ifu\\', \\'fug\\', \\'ugu\\', \\'myo\\', \\'CWT\\', \\'WTC\\', \\'GAR\\', \\'ARG\\', \\'CY\\\\n\\', \\'Y\\\\nG\\', \\'GCM\\', \\'GGY\\', \\'GYA\\', \\'GGS\\', \\'GST\\', \\'STG\\', \\'RAC\\', \\'ACW\\', \\'CWG\\', \\'WGT\\', \\'GTW\\', \\'TWT\\', \\'WTA\\', \\'YCC\\', \\'CCW\\', \\'WCT\\', \\'CTW\\', \\'TWG\\', \\'WGC\\', \\'CRG\\', \\'RGG\\', \\'GGW\\', \\'GWA\\', \\'WAA\\', \\'CAY\\', \\'AYG\\', \\'YGC\\', \\'MGT\\', \\'WGA\\', \\'YCT\\', \\'TYR\\', \\'YRC\\', \\'RCW\\', \\'CWA\\', \\'WAT\\', \\'TCY\\', \\'GKG\\', \\'KGT\\', \\'CAR\\', \\'RTY\\', \\'TYA\\', \\'YAA\\', \\'CYG\\', \\'YGG\\', \\'AAR\\', \\'ARA\\', \\'RGA\\', \\'GWT\\', \\'ATR\\', \\'TRG\\', \\'GTD\\', \\'TDT\\', \\'DTG\\', \\'TRK\\', \\'RKC\\', \\'KCW\\', \\'YTY\\', \\'GTM\\', \\'TMT\\', \\'MTG\\', \\'RTT\\', \\'WGG\\', \\'YGT\\', \\'AY\\\\n\\', \\'Y\\\\nA\\', \\'CGW\\', \\'CYT\\', \\'ACR\\', \\'CRT\\', \\'ATY\\', \\'WAC\\', \\'TM\\\\n\\', \\'M\\\\nT\\', \\'YTK\\', \\'TKG\\', \\'KGC\\', \\'MCT\\', \\'TTR\\', \\'ncy\\', \\'cyi\\', \\'Pip\\', \\'raf\\', \\'afi\\', \\'esq\\', \\'uii\\', \\'9 V\\', \\'Ves\\', \\'cr3\\', \\'r3 \\', \\'jav\\', \\' T2\\', \\'T29\\', \\'tad\\', \\' MT\\', \\'MT2\\', \\'T27\\', \\' GL\\', \\'GLC\\', \\'C14\\', \\'LC8\\', \\'C8 \\', \\'eof\\', \\'fel\\', \\'Unc\\', \\'moy\\', \\' on\\', \\'pum\\', \\'PMA\\', \\'l i\\', \\'CA \\', \\'ail\\', \\'LSE\\', \\'SE \\', \\'E m\\', \\'rof\\', \\' PA\\', \\'PAU\\', \\'AU \\', \\'U m\\', \\'Leo\\', \\'LPA\\', \\'PA \\', \\'wie\\', \\'ied\\', \\' LW\\', \\'LWI\\', \\'WI \\', \\'I m\\', \\'Lyn\\', \\' LC\\', \\'LCA\\', \\' ly\\', \\'lyn\\', \\' LY\\', \\'LYP\\', \\'YP \\', \\'P m\\', \\'x r\\', \\'ufu\\', \\'Pum\\', \\'yag\\', \\'gou\\', \\' HJ\\', \\'HJA\\', \\'JA \\', \\' PR\\', \\'PRU\\', \\'RU \\', \\' PV\\', \\'PVI\\', \\'VI \\', \\'Fel\\', \\'FCH\\', \\'CH \\', \\'H m\\', \\'Oto\\', \\'ul \\', \\'e O\\', \\' OM\\', \\'OMA\\', \\' FM\\', \\'FMA\\', \\' FN\\', \\'FNI\\', \\'NI \\', \\' FS\\', \\'FSI\\', \\'SI \\', \\'ntu\\', \\'g a\\', \\'ado\\', \\'dox\\', \\'oxu\\', \\'xur\\', \\'map\\', \\'Civ\\', \\'GNK\\', \\'NKC\\', \\'TCN\\', \\'NNG\\', \\'Viv\\', \\'CC8\\', \\'ahy\\', \\'yae\\', \\' BH\\', \\'BH_\\', \\'H_l\\', \\'_lo\\', \\'ve \\', \\'rza\\', \\'Ati\\', \\'Sur\\', \\'rox\\', \\'eoa\\', \\'e 0\\', \\' 01\\', \\'01P\\', \\'1PA\\', \\'PAN\\', \\'NT-\\', \\'6-A\\', \\'-An\\', \\'86_\\', \\'6_C\\', \\'_Ca\\', \\'CaA\\', \\'aAu\\', \\'8.4\\', \\'.4:\\', \\'4:5\\', \\'fam\\', \\'Cuo\\', \\'uon\\', \\'yca\\', \\'Spe\\', \\'8 V\\', \\' ze\\', \\'Urs\\', \\'7 U\\', \\'bet\\', \\'urs\\', \\'lge\\', \\'Mep\\', \\'r Y\\', \\' YP\\', \\'YP2\\', \\'P29\\', \\'uto\\', \\'Lon\\', \\'Enh\\', \\'nhy\\', \\'Aon\\', \\' 21\\', \\'OM1\\', \\'e 8\\', \\' 81\\', \\'YP1\\', \\'P1 \\', \\'0 I\\', \\'Gul\\', \\'MP4\\', \\'P41\\', \\'Tax\\', \\'xid\\', \\'axu\\', \\'xus\\', \\':77\\', \\'8-9\\', \\'-93\\', \\' MS\\', \\'MS2\\', \\'nsl\\', \\'Mir\\', \\'bod\\', \\'wed\\', \\'edd\\', \\'Cys\\', \\'rgh\\', \\'gha\\', \\'Pus\\', \\'enl\\', \\'nla\\', \\'5.3\\', \\'Eum\\', \\'Ota\\', \\' by\\', \\'byr\\', \\'hoo\\', \\'oke\\', \\'2 Z\\', \\'Zal\\', \\'1 Z\\', \\'wol\\', \\'aek\\', \\' NH\\', \\'NHM\\', \\'HMO\\', \\'MO:\\', \\'O:3\\', \\':30\\', \\' Eq\\', \\'Equ\\', \\'quu\\', \\'uus\\', \\'i q\\', \\'uag\\', \\'agg\\', \\'gga\\', \\'e Q\\', \\' QU\\', \\'QUA\\', \\'UAG\\', \\'GA \\', \\'Tap\\', \\'mum\\', \\'Vic\\', \\'cug\\', \\'Sus\\', \\'Pec\\', \\'i t\\', \\'taj\\', \\'jac\\', \\'cu \\', \\'nap\\', \\'BRM\\', \\'RMM\\', \\'MM0\\', \\'M00\\', \\' 14\\', \\'BS_\\', \\'S_0\\', \\'TNN\\', \\'TYG\\', \\'Sou\\', \\'oal\\', \\'e z\\', \\' z0\\', \\'z00\\', \\'CNC\\', \\' SR\\', \\'SRR\\', \\'RR1\\', \\'R16\\', \\'Lip\\', \\'vex\\', \\'ffr\\', \\'Pon\\', \\'4 Z\\', \\' Zi\\', \\'Zip\\', \\' SW\\', \\'SWF\\', \\'WFS\\', \\'FSC\\', \\'SC \\', \\'C I\\', \\' ID\\', \\'ID \\', \\'D z\\', \\'Gan\\', \\'es_\\', \\'s_R\\', \\'_Ri\\', \\'Riv\\', \\'er_\\', \\'r_D\\', \\'_Do\\', \\'olp\\', \\'in-\\', \\'n-S\\', \\'-S1\\', \\'S1 \\', \\'Kog\\', \\'eal\\', \\'cet\\', \\'lib\\', \\' CY\\', \\'YTO\\', \\'TO \\', \\'O m\\', \\'ffa\\', \\'Waz\\', \\'kap\\', \\'19F\\', \\'9FC\\', \\'C01\\', \\'n y\\', \\'yak\\', \\'aku\\', \\'Dam\\', \\'Mun\\', \\'mun\\', \\'ntj\\', \\'jak\\', \\'ak \\', \\'k m\\', \\'eev\\', \\'Rus\\', \\'4.3\\', \\' sw\\', \\'swi\\', \\'nho\\', \\'gif\\', \\':38\\', \\'TR\\\\n\\', \\'R\\\\nC\\', \\'CRA\\', \\'Alc\\', \\'lce\\', \\'Kaz\\', \\'zak\\', \\'akh\\', \\'khs\\', \\'hst\\', \\'Mos\\', \\'rez\\', \\'ezo\\', \\'zov\\', \\'ovs\\', \\' PH\\', \\'PHC\\', \\'HC1\\', \\'C11\\', \\'caf\\', \\'Bis\\', \\'0.3\\', \\'3:6\\', \\'aze\\', \\' AW\\', \\'AWW\\', \\'WWP\\', \\'WP \\', \\'ubg\\', \\'bgu\\', \\'PhC\\', \\'hC1\\', \\'C1 \\', \\'oms\\', \\'Sai\\', \\' KO\\', \\'KOL\\', \\'OLN\\', \\'LN \\', \\'N m\\', \\'Mad\\', \\'doq\\', \\'oqu\\', \\'irk\\', \\' SU\\', \\'SUN\\', \\'UN \\', \\' CA\\', \\'AR3\\', \\'R35\\', \\'fil\\', \\'th \\', \\'Red\\', \\'dun\\', \\'lvo\\', \\'C12\\', \\'Aep\\', \\'pyc\\', \\'hC2\\', \\' Ov\\', \\'Ovi\\', \\'vib\\', \\'ibo\\', \\'e V\\', \\' V0\\', \\'V07\\', \\'bex\\', \\'e h\\', \\' h7\\', \\'h77\\', \\'spu\\', \\'eam\\', \\'Rup\\', \\'ACY\\', \\' B8\\', \\'B8-\\', \\'-6 \\', \\'e Z\\', \\' ZA\\', \\'ZA4\\', \\'A41\\', \\'Add\\', \\' VZ\\', \\'VZ \\', \\'Z m\\', \\' gn\\', \\'u i\\', \\'UN6\\', \\'N61\\', \\'UN7\\', \\'N70\\', \\'Fuk\\', \\'uko\\', \\'kom\\', \\'Cav\\', \\' UF\\', \\'UF:\\', \\'F:3\\', \\'oyp\\', \\'deg\\', \\'Eli\\', \\'Gli\\', \\' av\\', \\'M33\\', \\'NM5\\', \\'M57\\', \\'TCR\\', \\'Gla\\', \\'M56\\', \\'4 U\\', \\' Ts\\', \\'Tst\\', \\'ri.\\', \\'i.#\\', \\'.#2\\', \\'#2 \\', \\' DZ\\', \\'DZT\\', \\'ZTM\\', \\'TM.\\', \\'M.8\\', \\'.87\\', \\'7 v\\', \\'DMN\\', \\'NS:\\', \\'S:M\\', \\':Ma\\', \\'Mam\\', \\'mm:\\', \\'m:1\\', \\' L1\\', \\'L19\\', \\'ece\\', \\'eml\\', \\'mli\\', \\'fib\\', \\'bi \\', \\'i 1\\', \\'21\\\\n\\', \\'1\\\\nA\\', \\'on_\\', \\'n_R\\', \\'_Ro\\', \\'Rod\\', \\'odL\\', \\'dL1\\', \\'L1_\\', \\'1_2\\', \\'_29\\', \\'5 v\\', \\'NEO\\', \\'EON\\', \\'01I\\', \\'1IH\\', \\'IHV\\', \\'HV \\', \\'V m\\', \\'CB1\\', \\'B1 \\', \\'TMY\\', \\'MYT\\', \\'YTR\\', \\'TMC\\', \\'TYY\\', \\'YYT\\', \\'TRC\\', \\'RCT\\', \\'YTM\\', \\'foc\\', \\'Ond\\', \\'AM:\\', \\'M:M\\', \\'m:8\\', \\'Cri\\', \\'dL2\\', \\'L2_\\', \\'2_2\\', \\'IHT\\', \\'HT \\', \\'FCR\\', \\'CR1\\', \\'R17\\', \\'76_\\', \\'6_M\\', \\'_MZ\\', \\'ZFC\\', \\'n G\\', \\' GS\\', \\'GS1\\', \\'S16\\', \\'16A\\', \\'6A1\\', \\'A1 \\', \\'1 s\\', \\'ck \\', \\'n B\\', \\' BW\\', \\'BW \\', \\'W s\\', \\'gmo\\', \\'Aco\\', \\'cah\\', \\' E0\\', \\'E03\\', \\'uic\\', \\'iby\\', \\'byc\\', \\'mom\\', \\'syl\\', \\'r V\\', \\' VN\\', \\'VN1\\', \\'maq\\', \\'aqu\\', \\'USB\\', \\'SB_\\', \\'B_M\\', \\'_MO\\', \\'MOZ\\', \\'OZ0\\', \\'Z05\\', \\'Lem\\', \\'emn\\', \\'Z00\\', \\'ymy\\', \\'omt\\', \\'mtu\\', \\' MN\\', \\'NHN\\', \\'HN-\\', \\'N-Z\\', \\'-ZM\\', \\'ZM-\\', \\'M-2\\', \\'CBG\\', \\'BGP\\', \\'GPR\\', \\'PR4\\', \\'R49\\', \\' TZ\\', \\'TZ2\\', \\'Z23\\', \\'rro\\', \\'HNV\\', \\'NVV\\', \\'VV2\\', \\'V20\\', \\'cou\\', \\'Pra\\', \\'aom\\', \\'MSP\\', \\'SP5\\', \\'P5 \\', \\'Ban\\', \\'Rat\\', \\'exu\\', \\'xul\\', \\' BN\\', \\'BN/\\', \\'N/S\\', \\'/Ss\\', \\'SsN\\', \\'sNH\\', \\'NHs\\', \\'Hsd\\', \\'sdM\\', \\'dMC\\', \\'MCW\\', \\'CW \\', \\'W m\\', \\' RT\\', \\'RT1\\', \\'T1 \\', \\'e t\\', \\'tow\\', \\'own\\', \\'wns\\', \\'i h\\', \\'ow \\', \\'w m\\', \\'Och\\', \\'Tup\\', \\'aia\\', \\'ZF8\\', \\'F89\\', \\'Dau\\', \\'aub\\', \\' AN\\', \\'ANJ\\', \\'NJZ\\', \\'JZ5\\', \\'Z5 \\', \\' KI\\', \\'KIB\\', \\'IBO\\', \\'BO7\\', \\'O7.\\', \\'7.9\\', \\'.9 \\', \\'ceb\\', \\'e 9\\', \\' 92\\', \\'20F\\', \\'0FA\\', \\'FAG\\', \\'AG \\', \\' mL\\', \\'mLe\\', \\'emC\\', \\'mCa\\', \\'at1\\', \\'t1 \\', \\'Var\\', \\'ANO\\', \\'NOS\\', \\'OSI\\', \\'SIB\\', \\'IB7\\', \\'B7 \\', \\'Lor\\', \\'syr\\', \\'hta\\', \\'goe\\', \\' FE\\', \\'FES\\', \\'ES5\\', \\'S50\\', \\'IDS\\', \\'DSM\\', \\'SM0\\', \\'M03\\', \\'Sag\\', \\'Aot\\', \\' JP\\', \\'JPB\\', \\'PB1\\', \\'B13\\', \\'4 v\\', \\'INP\\', \\'NPA\\', \\'PA:\\', \\'A:5\\', \\'cup\\', \\'upr\\', \\'Ceb\\', \\'Sap\\', \\'paj\\', \\'aju\\', \\'jus\\', \\' RV\\', \\'RVR\\', \\'VR1\\', \\'R19\\', \\'Ate\\', \\'roy\\', \\' KS\\', \\'KST\\', \\'TR5\\', \\'R5A\\', \\'5A \\', \\' TR\\', \\'TRO\\', \\'RO6\\', \\'O68\\', \\'A:7\\', \\'lou\\', \\'TR1\\', \\'GKA\\', \\'KAG\\', \\'TGK\\', \\'KAA\\', \\': M\\', \\'MRA\\', \\'RAD\\', \\'AD2\\', \\'D2\\\\n\\', \\'2\\\\nA\\', \\'Pap\\', \\'nub\\', \\' ea\\', \\'st \\', \\'dry\\', \\'yas\\', \\' aw\\', \\'was\\', \\'h:B\\', \\':BE\\', \\'BE9\\', \\'E97\\', \\'inx\\', \\'ypi\\', \\'ynd\\', \\'Gor\\'] not in index'"
     ]
    }
   ],
   "source": [
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71d9bf-b884-43f5-ac04-bc3ee2ac0e27",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['blast_score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Prepare the data\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# Assuming 'Characteristic' is the column you want to predict\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Specify the columns you want to use for X\u001b[39;00m\n\u001b[0;32m     41\u001b[0m feature_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgc_content\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblast_score\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kmer_df\u001b[39m.\u001b[39mcolumns)  \u001b[39m# Add more features as needed\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m X \u001b[39m=\u001b[39m df[feature_columns]\n\u001b[0;32m     43\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mMod\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Replace with your target column\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['blast_score'] not in index\""
     ]
    }
   ],
   "source": [
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae7c811-3721-4e7d-ab8d-7c4cb30a0b2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['blast_score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Prepare the data\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# Assuming 'Characteristic' is the column you want to predict\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Specify the columns you want to use for X\u001b[39;00m\n\u001b[0;32m     41\u001b[0m feature_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgc_content\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblast_score\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kmer_df\u001b[39m.\u001b[39mcolumns)  \u001b[39m# Add more features as needed\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m X \u001b[39m=\u001b[39m df[feature_columns]\n\u001b[0;32m     43\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mMod\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Replace with your target column\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['blast_score'] not in index\""
     ]
    }
   ],
   "source": [
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "feature_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee51e04-7322-4a4a-9216-daaf9c9c1ef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['blast_score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Prepare the data\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# Assuming 'Characteristic' is the column you want to predict\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Specify the columns you want to use for X\u001b[39;00m\n\u001b[0;32m     41\u001b[0m feature_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgc_content\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblast_score\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kmer_df\u001b[39m.\u001b[39mcolumns)  \u001b[39m# Add more features as needed\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m X \u001b[39m=\u001b[39m df[feature_columns]\n\u001b[0;32m     43\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mMod\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Replace with your target column\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['blast_score'] not in index\""
     ]
    }
   ],
   "source": [
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91931fc6-b54d-416b-b8fd-cb25b7376d18",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['blast_score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:43\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m# Prepare the data\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Assuming 'Characteristic' is the column you want to predict\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m# Specify the columns you want to use for X\u001b[39;00m\n\u001b[0;32m     42\u001b[0m features_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgc_content\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblast_score\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kmer_df\u001b[39m.\u001b[39mcolumns)  \u001b[39m# Add more features as needed\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m X \u001b[39m=\u001b[39m df[features_columns]\n\u001b[0;32m     44\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mMod\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Replace with your target column\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['blast_score'] not in index\""
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "features_columns = ['length', 'gc_content', 'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[features_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0d235-144e-40f1-9f40-ccb0e4948567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8975\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.84      0.98      0.91       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.93      0.80      0.86       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.96      0.99      0.97        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.53      0.44      0.45       400\n",
      "weighted avg       0.89      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3a051-a948-4cae-95d8-9bbef25197a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.84      0.98      0.90       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.94      0.81      0.87       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.97      0.99      0.98        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.54      0.44      0.46       400\n",
      "weighted avg       0.90      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baddf70-9d70-4302-a7ba-3ecba58eb237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8925\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.84      0.98      0.90       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.94      0.79      0.85       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.94      0.99      0.96        97\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.53      0.43      0.45       400\n",
      "weighted avg       0.89      0.89      0.88       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = [ 'gc_content', 'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28413f-ad3a-467a-acc1-9ec2f077f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8875\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.83      0.98      0.90       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.94      0.77      0.85       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.93      0.99      0.96        97\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.53      0.43      0.45       400\n",
      "weighted avg       0.88      0.89      0.88       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length',  'blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be5aa34-36cb-49cd-84e7-ccfe99633310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.83      0.99      0.90       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.95      0.80      0.87       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.97      0.99      0.98        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.54      0.44      0.46       400\n",
      "weighted avg       0.90      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['blast_score']  + list(kmer_df.columns)  # Add more features as needed\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345505a-6385-457d-b096-4605036f5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6675\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.63      0.83      0.71       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.67      1.00      0.80         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.60      0.42      0.50       135\n",
      "         stf       0.00      0.00      0.00         7\n",
      "         stx       0.82      0.81      0.82        97\n",
      "\n",
      "    accuracy                           0.67       400\n",
      "   macro avg       0.39      0.44      0.40       400\n",
      "weighted avg       0.65      0.67      0.65       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['blast_score']    # Add more features as needed length and gc doen ni zo veel\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908fb38-e287-42b4-adf5-15d99e5ee2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9025\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.84      0.99      0.91       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.95      0.81      0.87       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.97      0.99      0.98        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.54      0.44      0.46       400\n",
      "weighted avg       0.90      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "#blast_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    # blast_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    # blast_scores.append(blast_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "#features_df['blast_score'] = blast_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = []  + list(kmer_df.columns)  # Add more features as needed length and gc doen ni zo veel\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87164b-ca2d-4f60-be55-96a8e1295b9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:93\u001b[0m\n\u001b[0;32m     91\u001b[0m     kmer_features\u001b[39m.\u001b[39mappend(kmer_feature)\n\u001b[0;32m     92\u001b[0m     blast_scores\u001b[39m.\u001b[39mappend(blast_score)\n\u001b[1;32m---> 93\u001b[0m     bit_scores\u001b[39m.\u001b[39mappend(bit_scores)\n\u001b[0;32m     95\u001b[0m \u001b[39m# Convert features to a DataFrame\u001b[39;00m\n\u001b[0;32m     96\u001b[0m features_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(features)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Use a unique filename for each thread\n",
    "    temp_fasta_filename = f'temp_query_{threading.get_ident()}.fasta'\n",
    "    \n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open(temp_fasta_filename, 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', temp_fasta_filename, '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Remove the temporary FASTA file\n",
    "    os.remove(temp_fasta_filename)\n",
    "    \n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_records = NCBIXML.parse(io.StringIO(result.stdout))\n",
    "        for blast_record in blast_records:\n",
    "            if blast_record.alignments:\n",
    "                hsp = blast_record.alignments[0].hsps[0]\n",
    "                return hsp.score, hsp.bits\n",
    "    return 0, 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "bit_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score, bit_scores = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "    bit_scores.append(bit_scores)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "# features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "features_df['bit_score'] = bit_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score','bit_score']  + list(kmer_df.columns)  # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a942a-c2bf-45a9-a47c-456b18ca2a42",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\Desktop\\test python\\wetransfer_bachelorproef_amp_2024-11-07_1055\\Bachelorproef_AMP\\model_training.py:93\u001b[0m\n\u001b[0;32m     91\u001b[0m     kmer_features\u001b[39m.\u001b[39mappend(kmer_feature)\n\u001b[0;32m     92\u001b[0m     blast_scores\u001b[39m.\u001b[39mappend(blast_score)\n\u001b[1;32m---> 93\u001b[0m     bit_scores\u001b[39m.\u001b[39mappend(bit_score)\n\u001b[0;32m     95\u001b[0m \u001b[39m# Convert features to a DataFrame\u001b[39;00m\n\u001b[0;32m     96\u001b[0m features_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(features)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Use a unique filename for each thread\n",
    "    temp_fasta_filename = f'temp_query_{threading.get_ident()}.fasta'\n",
    "    \n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open(temp_fasta_filename, 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', temp_fasta_filename, '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Remove the temporary FASTA file\n",
    "    os.remove(temp_fasta_filename)\n",
    "    \n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_records = NCBIXML.parse(io.StringIO(result.stdout))\n",
    "        for blast_record in blast_records:\n",
    "            if blast_record.alignments:\n",
    "                hsp = blast_record.alignments[0].hsps[0]\n",
    "                return hsp.score, hsp.bits\n",
    "    return 0, 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "bit_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score, bit_scores = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "    bit_scores.append(bit_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "# features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "features_df['bit_score'] = bit_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score','bit_score']  + list(kmer_df.columns)  # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa780f1-1a66-411e-b364-ed416bbbedd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.84      0.98      0.91       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.93      0.81      0.87       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.97      0.99      0.98        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.53      0.44      0.46       400\n",
      "weighted avg       0.89      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import io\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Step 1: Read the CSV file and write to a FASTA file\n",
    "csv_file = 'AMP_species_list_COX1.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "with open('COX1_sequences.fasta', 'w') as fasta_file:\n",
    "    for index, row in df.iterrows():\n",
    "        fasta_file.write(f\">{row['FASTA']}\\n\")\n",
    "\n",
    "# Step 2: Create the BLAST database\n",
    "subprocess.run(['makeblastdb', '-in', 'COX1_sequences.fasta', '-dbtype', 'nucl', '-out', 'COX1_blastdb'])\n",
    "\n",
    "# Function to extract features from a sequence\n",
    "def extract_features(sequence):\n",
    "    features = {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Function to extract k-mer counts from a sequence\n",
    "def get_kmers(sequence, k=3):\n",
    "    kmers = [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "    return Counter(kmers)\n",
    "\n",
    "# Function to perform local BLAST alignment and extract alignment score\n",
    "def get_blast_score(sequence, db='COX1_blastdb'):\n",
    "    # Use a unique filename for each thread\n",
    "    temp_fasta_filename = f'temp_query_{threading.get_ident()}.fasta'\n",
    "    \n",
    "    # Write the sequence to a temporary FASTA file\n",
    "    with open(temp_fasta_filename, 'w') as temp_fasta:\n",
    "        temp_fasta.write(f'>query\\n{sequence}\\n')\n",
    "    \n",
    "    # Run the local BLAST search\n",
    "    result = subprocess.run(\n",
    "        ['blastn', '-query', temp_fasta_filename, '-db', db, '-outfmt', '5'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    # Remove the temporary FASTA file\n",
    "    os.remove(temp_fasta_filename)\n",
    "    \n",
    "    # Check if the BLAST search produced valid output\n",
    "    if result.stdout.strip():\n",
    "        # Parse the BLAST XML output\n",
    "        blast_records = NCBIXML.parse(io.StringIO(result.stdout))\n",
    "        for blast_record in blast_records:\n",
    "            if blast_record.alignments:\n",
    "                hsp = blast_record.alignments[0].hsps[0]\n",
    "                return hsp.score, hsp.bits\n",
    "    return 0, 0\n",
    "\n",
    "# Load the CSV files\n",
    "sequences_df = pd.read_csv('gene_FASTA_COX1_final.csv')  # Contains sequence and ID\n",
    "animals_df = pd.read_csv('gene_IDS_COX1_retrial.csv')  # Contains ID and animal information\n",
    "characteristics_df = pd.read_csv('AMP_species_list.csv')  # Contains animal and characteristic\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(sequences_df, animals_df, on='gene_ID', how='inner')  # Merge on 'ID'\n",
    "merged_df = pd.merge(merged_df, characteristics_df, on='ID', how='inner')  # Merge on 'Animal'\n",
    "merged_df.to_csv('AMP_species_list_COX1.csv', index=False)\n",
    "\n",
    "# Extract features from the FASTA sequences\n",
    "features = []\n",
    "kmer_features = []\n",
    "blast_scores = []\n",
    "bit_scores = []\n",
    "\n",
    "# Process each sequence one by one\n",
    "for fasta in merged_df['FASTA']:\n",
    "    sequence = str(Seq(fasta))\n",
    "    feature = extract_features(sequence)\n",
    "    kmer_feature = get_kmers(sequence)\n",
    "    blast_score, bit_score = get_blast_score(sequence)\n",
    "    \n",
    "    features.append(feature)\n",
    "    kmer_features.append(kmer_feature)\n",
    "    blast_scores.append(blast_score)\n",
    "    bit_scores.append(bit_score)\n",
    "\n",
    "# Convert features to a DataFrame\n",
    "features_df = pd.DataFrame(features)\n",
    "# features_df= pd.read_csv(\"blast_scores.csv\")\n",
    "# Convert k-mer features to a DataFrame\n",
    "kmer_df = pd.DataFrame(kmer_features).fillna(0)\n",
    "\n",
    "# Add BLAST scores to the features DataFrame\n",
    "features_df['blast_score'] = blast_scores\n",
    "features_df['bit_score'] = bit_scores\n",
    "\n",
    "# Combine features with the merged DataFrame\n",
    "df = pd.concat([merged_df, features_df, kmer_df], axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "# Assuming 'Characteristic' is the column you want to predict\n",
    "# Specify the columns you want to use for X\n",
    "feature_columns = ['length', 'gc_content', 'blast_score','bit_score']  + list(kmer_df.columns)  # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0988997-ac0f-4d4c-8be7-c99cd6a8a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv('blast_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a673e4-90e8-47f7-bdb1-25d78e54e3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8975\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.84      0.98      0.90       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.94      0.80      0.86       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.96      0.99      0.97        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.53      0.44      0.46       400\n",
      "weighted avg       0.89      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_columns = ['blast_score','bit_score']  + list(kmer_df.columns)  # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de01ce-1814-42d2-9a5d-2754987aa59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.83      0.99      0.90       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.95      0.80      0.87       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.97      0.99      0.98        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.54      0.44      0.46       400\n",
      "weighted avg       0.90      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_columns = ['bit_score']  + list(kmer_df.columns)  # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172da26a-8e7e-45b4-ba28-fab2e74bbc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9025\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.84      0.99      0.91       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.95      0.81      0.87       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.97      0.99      0.98        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.54      0.44      0.46       400\n",
      "weighted avg       0.90      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []  + list(kmer_df.columns)  # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a0af5-cbff-4631-8938-39ebd6e84e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.63      0.83      0.72       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.67      1.00      0.80         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.61      0.42      0.50       135\n",
      "         stf       0.00      0.00      0.00         7\n",
      "         stx       0.82      0.81      0.82        97\n",
      "\n",
      "    accuracy                           0.67       400\n",
      "   macro avg       0.39      0.44      0.40       400\n",
      "weighted avg       0.65      0.67      0.65       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_columns = ['blast_score','bit_score']   # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb1f584-3659-4f50-8415-87a43c774c48",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-f5a1d6d03450>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[43], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    feature_columns = [,'bit_score']   # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [,'bit_score']   # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f147ace-a7e4-46b4-bd06-4e7fba8ae17b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-efed932c7aa0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[44], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    feature_columns = [,'bit_score']   # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [,'bit_score']   # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5476c62-a7b5-441a-b13c-d117eef7e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.63      0.83      0.72       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.67      1.00      0.80         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.61      0.42      0.50       135\n",
      "         stf       0.00      0.00      0.00         7\n",
      "         stx       0.82      0.81      0.82        97\n",
      "\n",
      "    accuracy                           0.67       400\n",
      "   macro avg       0.39      0.44      0.40       400\n",
      "weighted avg       0.65      0.67      0.65       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_columns = ['bit_score']   # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075a18f-280a-4733-9216-1ae3a3ba934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9025\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         abj       0.84      0.99      0.91       156\n",
      "         asj       0.00      0.00      0.00         1\n",
      "         hex       0.00      0.00      0.00         2\n",
      "         ssj       0.00      0.00      0.00         2\n",
      "         std       0.95      0.81      0.87       135\n",
      "         stf       1.00      0.29      0.44         7\n",
      "         stx       0.97      0.99      0.98        97\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.54      0.44      0.46       400\n",
      "weighted avg       0.90      0.90      0.89       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gebruiker\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []  + list(kmer_df.columns)  # Add more features as needed length and gc doen ni veel kmer wint zelf zonder blast score\n",
    "X = df[feature_columns]\n",
    "y = df['Mod']  # Replace with your target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=37)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dea742-c1f2-46af-836b-7136c23ddc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model_kmer.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'random_forest_model_kmer.pkl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
